defaults:
  - _self_

_target_: src.models.gflownet_module.GFlowNetModule
_recursive_: true

hidden_dim: 1024
emb_dim: 1024
backbone_finetune: true
vocabulary_path: ${dataset.paths.vocabulary}
edge_score_cfg:
  hidden_dim: ${model.hidden_dim}
  num_layers: 2
  dropout: 0.1
  bias_init: 0.0
state_cfg:
  state_dim: ${model.hidden_dim}
  dropout: 0.0

env:
  _target_: src.models.components.gflownet_env.GraphEnv
  max_steps: ${dataset.max_steps}
  stop_on_answer: false
  min_stop_steps: 0

policy:
  _target_: src.models.components.gflownet_policy.EnergyEdgePolicy
  hidden_dim: ${model.hidden_dim}

reward_fn:
  _target_: src.models.components.gflownet_reward.GraphFusionReward
  hard_target_bonus: 1.0
  min_log_reward: -10.0
  potential_weight: 1.0
  potential_gamma: 1.0
  potential_unreachable_offset: 1.0

reward_cfg:
  embedding_source: raw
  potential_weight_end: 0.0
  potential_weight_decay_epochs: ${trainer.min_epochs}

actor_cfg:
  policy_temperature: 1.0
  check_finite: false

training_cfg:
  num_train_rollouts: ${dataset.num_train_rollouts}

runtime_cfg:
  validate_edge_batch: true
  vectorized_rollouts: ${dataset.vectorized_rollouts}

evaluation_cfg:
  num_eval_rollouts: ${dataset.num_eval_rollouts}
  rollout_temperature: 0.0

optimizer_cfg:
  type: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-4

scheduler_cfg:
  type: cosine
  t_max: 200
  eta_min: 1.0e-6
  interval: epoch
