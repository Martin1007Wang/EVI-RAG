defaults:
  - _self_

_target_: src.models.gflownet_module.GFlowNetModule
_recursive_: false

hidden_dim: 1024
env_cfg:
  _target_: src.models.components.gflownet_env.GraphEnv
  max_steps: 2
  stop_on_answer: true

policy_cfg:
  _target_: src.models.components.gflownet_policy.GFlowNetEdgePolicy
  hidden_dim: ${model.hidden_dim}
  dropout: 0.1

reward_cfg:
  _target_: src.models.components.gflownet_rewards.GFlowNetReward
  success_reward: 1.0
  failure_reward: 1e-4
  semantic_coef: 1.0
  length_coef: 1.0

actor_cfg:
  _target_: src.models.components.gflownet_actor.GFlowNetActor
  policy_temperature: 1.0

embedder_cfg:
  _target_: src.models.components.gflownet_embedder.GraphEmbedder
  hidden_dim: ${model.hidden_dim}
  projector_checkpoint: ${ckpt.retriever}
  allow_deferred_init: false

state_encoder_cfg:
  _target_: src.models.components.state_encoder.StateEncoder
  hidden_dim: ${model.hidden_dim}
  max_steps: ${model.env_cfg.max_steps}
  use_state_dde: true
  state_dde_cfg:
    num_topics: ${dataset.num_topics}
    num_rounds: ${dataset.topic_pe.num_rounds}
    num_reverse_rounds: ${dataset.topic_pe.num_reverse_rounds}

estimator_cfg:
  _target_: src.models.components.gflownet_estimator.GFlowNetEstimator
  hidden_dim: ${model.hidden_dim}
  zero_init_last: true

training_cfg:
  num_train_rollouts: 1
  bc_weight: 0.0
  bc_weight_floor: 0.0
  bc_hold_ratio: 0.0
  bc_decay_ratio: 0.0

evaluation_cfg:
  num_eval_rollouts: 5
  rollout_temperature: 1.0

optimizer_cfg:
  type: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-4

scheduler_cfg:
  type: cosine
  t_max: 200
  eta_min: 1.0e-6
  interval: epoch
  monitor: val/answer_hit@1

logging_cfg:
  train_prog_bar: ["log_reward", "answer_hit"]
  eval_prog_bar: ["answer_hit@1"]
  log_on_step_train: false
