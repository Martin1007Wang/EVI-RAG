defaults:
  - _self_
  - env@env_cfg: graph
  - policy@policy_cfg: mixer
  - reward@reward_cfg: answer_fraction
  - actor@actor_cfg: gflownet_actor
  - embedder@embedder_cfg: default
  - estimator@estimator_cfg: gflownet_estimator

_target_: src.models.gflownet_module.GFlowNetModule
_recursive_: false

hidden_dim: 1024

training_cfg:
  debug_batches_to_log: 1
  debug_graphs_to_log: 2

evaluation_cfg:
  num_eval_rollouts: [10, 20]       # 采样窗口 K_s（Best-of-K_s）

optimizer_cfg:
  type: adamw
  lr: 1.0e-4
  weight_decay: 1.0e-4

scheduler_cfg:
  type: cosine
  t_max: 200
  eta_min: 1.0e-6
  interval: epoch
  monitor: val/rollout_reward

logging_cfg:
  # 指标进度条：训练阶段
  train_prog_bar: ["rollout_reward", "success_mean", "answer_coverage", "length_mean"]
  # 指标进度条：验证/测试阶段（会自动追加 success@K / path_hit_f1@K，如果配置中存在）
  eval_prog_bar: ["success_mean", "answer_f1"]
  auto_add_success_at_k: true
  auto_add_path_hit_f1: false
  log_on_step_train: false
