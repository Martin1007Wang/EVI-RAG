_target_: src.llm_generation.module.LLMGenerationModule

model_name: meta-llama/Meta-Llama-3.1-8B-Instruct
tensor_parallel_size: 1
temperature: 0.0
frequency_penalty: 0.16
max_seq_len: 16384
max_tokens: 4000
seed: ${seed}
output_dir: ${paths.output_dir}

dataset: ${data.dataset}
split: ${data.split}
prompt_tag: ${data.prompt_tag}
