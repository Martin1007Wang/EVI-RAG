defaults:
  - paths: default
  - dataset: webqsp
  - _self_

# Input directory, should match the output of build_retrieval_parquet.py
parquet_dir: ${dataset.out_dir}

# Output directory for LMDB and embeddings
output_dir: ${dataset.materialized_dir}

# Optional: also materialize a `${dataset.name}-${sub.suffix}` dataset if its normalized parquet exists.
sub:
  enabled: true
  suffix: sub
  parquet_dir: ${paths.data_dir}/${dataset.name}-${sub.suffix}/normalized
  output_dir: ${paths.data_dir}/${dataset.name}-${sub.suffix}/materialized
  share_vocab_and_embeddings: true

# HF model name or path for text encoding.
encoder: "Alibaba-NLP/gte-large-en-v1.5"

# Device for encoding (cuda or cpu).
device: "cuda"

# Batch size for text encoding.
batch_size: 64

# Show tqdm progress for long encoding phases (vocab encoding).
progress_bar: true

# Use FP16 for encoder forward pass.
fp16: True

# Number of topic feature channels used in preprocessing.
# SubgraphRAG parity: 2-class one-hot {non-topic, topic} built from query entities only.
num_topics: 2

# Which supervision mask to write into LMDB as `labels` (consumed by GRetrievalDataset/Retriever).
# - transition: (u->v) transitions on GT paths, lifted to all parallel edges (legacy behavior)
# - triple: exact (h,r,t) edges on GT paths (canonical edge ids / answer_subgraph edges)
# - hybrid: use `triple` when GT comes from answer_subgraph, else `transition`
labels:
  source: hybrid
  store_aux: true

# LMDB map size in GB.
map_size_gb: 32

# LMDB map size for vocabulary (GB).
vocab_map_size_gb: 4

# Rebuild semantics: LMDB writes are not "incremental". If an LMDB already exists, we must
# overwrite it to avoid stale keys leaking into the current dataset build.
overwrite_lmdb: true

# Number of samples per LMDB transaction commit.
txn_size: 512

# Optional reproducibility controls.
seed: 42
deterministic: false
