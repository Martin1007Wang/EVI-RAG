defaults:
  - _self_
  - paths: default
  - dataset: null
  - pipeline: default

# Explicitly provide `dataset=<name>` via CLI override (paths default to configs/paths/default.yaml).

# Shared encoder settings (used by both parquet + LMDB stages).
encoder: "Alibaba-NLP/gte-large-en-v1.5"
device: "cuda"
batch_size: 16
parquet_chunk_size: 2000
parquet_num_workers: 0
progress_bar: true
fp16: false
pipeline_log_path: null
dataset_source: hf
hf_dataset: ${dataset.hf_dataset}
hf_cache_dir: ${paths.hf_datasets_cache}
hf_offline: true

# === Stage 1: normalize raw parquet into retrieval parquet ===
dataset_name: ${dataset.name}
kb: ${dataset.kb}
out_dir: ${dataset.out_dir}
column_map: ${dataset.column_map}
entity_normalization: ${dataset.entity_normalization}
entity_text_mode: ${dataset.entity_text_mode}
text_prefixes: ${dataset.text_prefixes}
text_regex: ${dataset.text_regex}
cvt_entity_mode: ${dataset.cvt_entity_mode}
cvt_prefixes: ${dataset.cvt_prefixes}
cvt_regex: ${dataset.cvt_regex}
time_relation_mode: ${dataset.time_relation_mode}
time_relation_regex: ${dataset.time_relation_regex}
time_question_regex: ${dataset.time_question_regex}
