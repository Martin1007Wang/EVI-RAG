# @package _global_

# Optuna-based hyperparameter search for GFlowNet.
# Usage (example):
#   python src/train.py -m experiment=train_gflownet_default hparams_search=gflownet_optuna \
#     dataset=webqsp ckpt.retriever=/path/to/retriever.ckpt logger=none

defaults:
  - override /hydra/sweeper: optuna
  - override /hydra/sweeper/sampler: tpe

# Metric returned from src/train.py::main() via `get_metric_value(...)`.
optimized_metric: "val/answer_hit"

# Make sweeps practical: allow early stopping to trigger immediately.
trainer:
  min_epochs: 0
  check_val_every_n_epoch: 1

hydra:
  sweeper:
    sampler:
      seed: 42
    n_trials: 24
    n_jobs: 1
    direction: maximize
    study_name: gflownet_optuna
    params:
      # Branching factor (online): must be <= window.anchor_top_k (configs/window/default.yaml).
      model.actor_cfg.action_topk: choice(50, 100, 200, 400)
      # GT-SubTB anchor strength (teacher-forcing, flow objective).
      model.training_cfg.gt_flow_coef: choice(0.5, 1.0, 2.0)
      # Dense shaping strength (log-domain F1 bonus).
      model.reward_cfg.pos_f1_coef: choice(0.0, 1.0, 2.0, 4.0)
      # Optimizer LR (log-uniform).
      model.optimizer_cfg.lr: tag(log, interval(3e-5, 3e-4))

