# @package _global_
#
# Energy-based GFlowNet training (EB-GFN).

defaults:
  - override /data: g_retrieval
  - override /model: gflownet_module
  - override /callbacks: default
  - override /logger: wandb
  - override /trainer: gpu

task_name: "eb_gfn_train"
tags: ["gflownet", "energy"]
train: true
test: true
ckpt_path: null
seed: 42
optimized_metric: "val/terminal_hit@${model.evaluation_cfg.num_eval_rollouts}"

trainer:
  check_val_every_n_epoch: 5
  precision: 32

data:
  expand_multi_answer: false

model:
  env:
    max_steps: ${dataset.max_steps}

  optimizer_cfg:
    type: adamw
    lr: 1.0e-4
    weight_decay: 1.0e-4
    param_groups:
      - names: ["*log_f.*"]
        lr: 5.0e-4

  reward_fn:
    hard_target_bonus: 2.0
    min_log_reward: -5.0

  scheduler_cfg:
    type: cosine
    t_max: 10
    eta_min: 1.0e-6
    interval: epoch

  actor_cfg:
    policy_temperature: 1.2

  backward_cfg:
    share_state_encoder: false
    share_edge_scorer: false

  training_cfg:
    num_train_rollouts: 0
    num_miner_rollouts: 8
    num_forward_rollouts: 8
    mining_temperature: 1.2
    accumulate_grad_batches: 4
    allow_zero_hop: true
    tb:
      log_prob_min: -20.0
      delta_max: 20.0

callbacks:
  model_checkpoint:
    monitor: val/terminal_hit@${model.evaluation_cfg.num_eval_rollouts}
    mode: max
    filename: "epoch_{epoch:03d}"
    auto_insert_metric_name: False
    save_weights_only: True
  early_stopping:
    monitor: val/terminal_hit@${model.evaluation_cfg.num_eval_rollouts}
    mode: max
    patience: 50
