# @package _global_
#
# Energy-based GFlowNet training (EB-GFN).

defaults:
  - override /data: g_retrieval
  - override /model: gflownet_module
  - override /callbacks: default
  - override /logger: wandb
  - override /trainer: gpu

task_name: "eb_gfn_train"
tags: ["gflownet", "energy"]
train: true
test: true
ckpt_path: null
seed: 42
optimized_metric: "val/composite_score@${model.evaluation_cfg.num_eval_rollouts}"

trainer:
  check_val_every_n_epoch: 5

model:
  env:
    max_steps: ${dataset.max_steps}

  edge_score_cfg:
    activation_checkpointing: false

  optimizer_cfg:
    type: adamw
    lr: 1.0e-4
    weight_decay: 1.0e-4

  scheduler_cfg:
    type: cosine
    t_0: 10
    t_mult: 2
    eta_min: 1.0e-6
    interval: epoch

  actor_cfg:
    policy_temperature: 1.0

  training_cfg:
    num_train_rollouts: 3
    rollout_chunk_size: 3
    manual_gradient_clip_val: 1.0
    manual_gradient_clip_algorithm: norm
    manual_gradient_clip_norm_type: 2.0
    adaptive_gradient_clip: true
    grad_clip_ema_beta: null
    grad_clip_tail_prob: null
    grad_clip_log_eps: 1.0e-8
    grad_clip_tail_prob_eps: 1.0e-6
    grad_non_finite_max_params: 20
    start_backtrack:
      enabled: true
      min_dist: 1

  control_cfg:
    enabled: true
    target_mode: reachable_horizon_frac
    target_min: 0.0
    target_max: 1.0
    temperature_base: ${model.actor_cfg.policy_temperature}
    temperature_min: 0.2
    temperature_max: 2.0
    lambda_init: 0.0
    dual_lr: null

callbacks:
  model_checkpoint:
    monitor: val/composite_score@${model.evaluation_cfg.num_eval_rollouts}
    mode: max
    filename: "epoch_{epoch:03d}"
    auto_insert_metric_name: False
    save_weights_only: True
  early_stopping:
    monitor: val/composite_score@${model.evaluation_cfg.num_eval_rollouts}
    mode: max
    patience: 50
