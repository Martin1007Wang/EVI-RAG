_target_: lightning.pytorch.trainer.Trainer

default_root_dir: ${paths.output_dir}

min_epochs: 50 # prevents early stopping
max_epochs: 999

# let Lightning pick the right accelerator/devices unless overridden
accelerator: auto
devices: auto
profiler: null

# mixed precision for throughput; prefer bf16 on supported GPUs
precision: bf16-mixed

# gradient accumulation to trade throughput for memory
accumulate_grad_batches: 1

# cudnn autotune for stable input shapes (disable if shapes vary wildly)
benchmark: true

# disable automatic clipping for manual optimization (model handles it)
gradient_clip_val: null

# perform a validation loop every N training epochs
check_val_every_n_epoch: 10

# skip sanity validation to avoid cold-start stalls on large datasets
num_sanity_val_steps: 0

# optional batch limits for profiling/debugging
limit_train_batches: null
limit_val_batches: null
limit_test_batches: null

# log interval (steps); set small to avoid skipping logs when epoch has few batches
log_every_n_steps: 1

# set True to to ensure deterministic results
# makes training slower but gives more reproducibility than just setting seeds
deterministic: False
