[[36m2025-12-15 17:40:20,595[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-12-15 17:40:20,597[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] torch.set_float32_matmul_precision(high)[0m
[[36m2025-12-15 17:40:20,597[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.g_retrieval_datamodule.GRetrievalDataModule          
â”‚       dataset_cfg:                                                            
â”‚         name: webqsp-sub                                                      
â”‚         kb: freebase                                                          
â”‚         raw_root: /mnt/data/retrieval_dataset/webqsp/raw/data                 
â”‚         out_dir: /mnt/data/retrieval_dataset/webqsp-sub/normalized            
â”‚         materialized_dir: /mnt/data/retrieval_dataset/webqsp-sub/materialized 
â”‚         paths:                                                                
â”‚           vocabulary: /mnt/data/retrieval_dataset/webqsp-sub/materialized/voca
â”‚           embeddings: /mnt/data/retrieval_dataset/webqsp-sub/materialized/embe
â”‚           processed: /mnt/data/retrieval_dataset/webqsp-sub/materialized/proce
â”‚         entity_normalization: none                                            
â”‚         undirected_traversal: false                                           
â”‚         column_map:                                                           
â”‚           question_id_field: id                                               
â”‚           question_field: question                                            
â”‚           answer_text_field: answer                                           
â”‚           q_entity_field: q_entity                                            
â”‚           a_entity_field: a_entity                                            
â”‚           graph_field: graph                                                  
â”‚       batch_size: 32                                                          
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       drop_last: false                                                        
â”‚       persistent_workers: false                                               
â”‚       splits:                                                                 
â”‚         train: train                                                          
â”‚         validation: validation                                                
â”‚         test: test                                                            
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.retriever_module.RetrieverModule                   
â”‚       compile_model: false                                                    
â”‚       compile_dynamic: true                                                   
â”‚       retriever:                                                              
â”‚         _target_: src.models.components.retriever.Retriever                   
â”‚         emb_dim: 1024                                                         
â”‚         hidden_dim: 1024                                                      
â”‚         topic_pe: true                                                        
â”‚         num_topics: 2                                                         
â”‚         dde_cfg:                                                              
â”‚           num_rounds: 2                                                       
â”‚           num_reverse_rounds: 2                                               
â”‚         dropout_p: 0.1                                                        
â”‚       loss:                                                                   
â”‚         _target_: src.losses.retriever_loss.RetrieverListwiseHardNegLoss      
â”‚         temperature: 1.0                                                      
â”‚         listwise_weight: 1.0                                                  
â”‚         hard_neg_k: 64                                                        
â”‚         pairwise_margin: 1.0                                                  
â”‚         pairwise_weight: 1.0                                                  
â”‚       optimizer:                                                              
â”‚         _target_: torch.optim.Adam                                            
â”‚         _partial_: true                                                       
â”‚         lr: 0.001                                                             
â”‚         weight_decay: 0.0                                                     
â”‚         betas:                                                                
â”‚         - 0.9                                                                 
â”‚         - 0.999                                                               
â”‚       scheduler: null                                                         
â”‚       evaluation_cfg:                                                         
â”‚         ranking_k:                                                            
â”‚         - 1                                                                   
â”‚         - 5                                                                   
â”‚         - 10                                                                  
â”‚         - 25                                                                  
â”‚         - 50                                                                  
â”‚         - 100                                                                 
â”‚         - 200                                                                 
â”‚         - 300                                                                 
â”‚         - 400                                                                 
â”‚         answer_recall_k:                                                      
â”‚         - 1                                                                   
â”‚         - 5                                                                   
â”‚         - 10                                                                  
â”‚         - 25                                                                  
â”‚         - 50                                                                  
â”‚         - 100                                                                 
â”‚         - 200                                                                 
â”‚         - 300                                                                 
â”‚         - 400                                                                 
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/2
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/ranking/recall@100                                       
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 1                                                         
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/ranking/recall@100                                       
â”‚         min_delta: 0.0                                                        
â”‚         patience: 10                                                          
â”‚         verbose: false                                                        
â”‚         mode: max                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         name: train                                                           
â”‚         save_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: evi-rag                                                      
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         entity: null                                                          
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp
â”‚       min_epochs: 0                                                           
â”‚       max_epochs: 10000                                                       
â”‚       accelerator: gpu                                                        
â”‚       devices: 1                                                              
â”‚       gradient_clip_val: 1.0                                                  
â”‚       check_val_every_n_epoch: 1                                              
â”‚       log_every_n_steps: 1                                                    
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚       data_dir: /mnt/data/retrieval_dataset                                   
â”‚       log_dir: /mnt/wangjingxiong/EVI-RAG/logs/                               
â”‚       debug_log_path: /mnt/wangjingxiong/EVI-RAG/logs//debug.log              
â”‚       output_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/
â”‚       work_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚       torch_float32_matmul_precision: high                                    
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train                                                                   
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['webqsp', 'train_retriever']                                           
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ debug_data_loading
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ test_ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ allow_test_without_checkpoint
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 42                                                                      
â””â”€â”€ dataset
    â””â”€â”€ name: webqsp-sub                                                        
        kb: freebase                                                            
        raw_root: /mnt/data/retrieval_dataset/webqsp/raw/data                   
        out_dir: /mnt/data/retrieval_dataset/webqsp-sub/normalized              
        materialized_dir: /mnt/data/retrieval_dataset/webqsp-sub/materialized   
        paths:                                                                  
          vocabulary: /mnt/data/retrieval_dataset/webqsp-sub/materialized/vocabu
          embeddings: /mnt/data/retrieval_dataset/webqsp-sub/materialized/embedd
          processed: /mnt/data/retrieval_dataset/webqsp-sub/materialized/process
        entity_normalization: none                                              
        undirected_traversal: false                                             
        column_map:                                                             
          question_id_field: id                                                 
          question_field: question                                              
          answer_text_field: answer                                             
          q_entity_field: q_entity                                              
          a_entity_field: a_entity                                              
          graph_field: graph                                                    
                                                                                
Seed set to 42
[[36m2025-12-15 17:40:20,635[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resolved run name: train_retriever_webqsp[0m
[[36m2025-12-15 17:40:20,635[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.g_retrieval_datamodule.GRetrievalDataModule>[0m
[[36m2025-12-15 17:40:20,896[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.retriever_module.RetrieverModule>[0m
/anaconda3/envs/pog/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:210: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.
[[36m2025-12-15 17:40:20,955[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-12-15 17:40:20,956[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-12-15 17:40:20,957[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-12-15 17:40:20,958[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-12-15 17:40:20,958[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-12-15 17:40:20,958[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-12-15 17:40:20,958[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-12-15 17:40:20,961[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
[[36m2025-12-15 17:40:20,999[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: martin1007wang (martin1007wang-wuhan-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/2025-12-15_17-40-20/wandb/run-20251215_174022-sd5gljug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train_retriever_webqsp
wandb: â­ï¸ View project at https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: ğŸš€ View run at https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/sd5gljug
[[36m2025-12-15 17:40:24,519[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-12-15 17:40:25,119[0m][[34msrc.data.components.graph_store[0m][[32mINFO[0m] - Loaded vocabulary: 1316464 entities / 6094 relations[0m
[[36m2025-12-15 17:40:25,473[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp-sub/materialized/embeddings/entity_embeddings.pt...[0m
[[36m2025-12-15 17:40:26,387[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp-sub/materialized/embeddings/relation_embeddings.pt...[0m
[[36m2025-12-15 17:40:26,398[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Entity embedding rows: 539675 (vocab entities: 1316464). Non-text entities use embedding_id=0; textual entities occupy 1..max_id.[0m
[[36m2025-12-15 17:40:26,399[0m][[34msrc.data.g_retrieval_dataset[0m][[32mINFO[0m] - GRetrievalDataset[train] initialized: 2708 samples.[0m
[[36m2025-12-15 17:40:26,400[0m][[34msrc.data.g_retrieval_dataset[0m][[32mINFO[0m] - GRetrievalDataset[validation] initialized: 234 samples.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                                   â”ƒ Type          â”ƒ Params â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ model                                  â”‚ Retriever     â”‚  8.4 M â”‚ train â”‚
â”‚ 1  â”‚ model.entity_proj                      â”‚ EmbeddingProâ€¦ â”‚  1.0 M â”‚ train â”‚
â”‚ 2  â”‚ model.entity_proj.network              â”‚ Sequential    â”‚  1.0 M â”‚ train â”‚
â”‚ 3  â”‚ model.entity_proj.network.0            â”‚ Linear        â”‚  1.0 M â”‚ train â”‚
â”‚ 4  â”‚ model.entity_proj.network.1            â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 5  â”‚ model.relation_proj                    â”‚ EmbeddingProâ€¦ â”‚  1.0 M â”‚ train â”‚
â”‚ 6  â”‚ model.relation_proj.network            â”‚ Sequential    â”‚  1.0 M â”‚ train â”‚
â”‚ 7  â”‚ model.relation_proj.network.0          â”‚ Linear        â”‚  1.0 M â”‚ train â”‚
â”‚ 8  â”‚ model.relation_proj.network.1          â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 9  â”‚ model.query_proj                       â”‚ EmbeddingProâ€¦ â”‚  1.0 M â”‚ train â”‚
â”‚ 10 â”‚ model.query_proj.network               â”‚ Sequential    â”‚  1.0 M â”‚ train â”‚
â”‚ 11 â”‚ model.query_proj.network.0             â”‚ Linear        â”‚  1.0 M â”‚ train â”‚
â”‚ 12 â”‚ model.query_proj.network.1             â”‚ Tanh          â”‚      0 â”‚ train â”‚
â”‚ 13 â”‚ model.non_text_entity_emb              â”‚ Embedding     â”‚  1.0 K â”‚ train â”‚
â”‚ 14 â”‚ model.dde                              â”‚ DDE           â”‚      0 â”‚ train â”‚
â”‚ 15 â”‚ model.dde.layers                       â”‚ ModuleList    â”‚      0 â”‚ train â”‚
â”‚ 16 â”‚ model.dde.layers.0                     â”‚ PEConv        â”‚      0 â”‚ train â”‚
â”‚ 17 â”‚ model.dde.layers.0.aggr_module         â”‚ MeanAggregatâ€¦ â”‚      0 â”‚ train â”‚
â”‚ 18 â”‚ model.dde.layers.1                     â”‚ PEConv        â”‚      0 â”‚ train â”‚
â”‚ 19 â”‚ model.dde.layers.1.aggr_module         â”‚ MeanAggregatâ€¦ â”‚      0 â”‚ train â”‚
â”‚ 20 â”‚ model.dde.reverse_layers               â”‚ ModuleList    â”‚      0 â”‚ train â”‚
â”‚ 21 â”‚ model.dde.reverse_layers.0             â”‚ PEConv        â”‚      0 â”‚ train â”‚
â”‚ 22 â”‚ model.dde.reverse_layers.0.aggr_module â”‚ MeanAggregatâ€¦ â”‚      0 â”‚ train â”‚
â”‚ 23 â”‚ model.dde.reverse_layers.1             â”‚ PEConv        â”‚      0 â”‚ train â”‚
â”‚ 24 â”‚ model.dde.reverse_layers.1.aggr_module â”‚ MeanAggregatâ€¦ â”‚      0 â”‚ train â”‚
â”‚ 25 â”‚ model.feature_extractor                â”‚ DenseFeatureâ€¦ â”‚  5.3 M â”‚ train â”‚
â”‚ 26 â”‚ model.feature_extractor.network        â”‚ Sequential    â”‚  5.3 M â”‚ train â”‚
â”‚ 27 â”‚ model.feature_extractor.network.0      â”‚ Linear        â”‚  4.2 M â”‚ train â”‚
â”‚ 28 â”‚ model.feature_extractor.network.1      â”‚ ReLU          â”‚      0 â”‚ train â”‚
â”‚ 29 â”‚ model.feature_extractor.network.2      â”‚ Dropout       â”‚      0 â”‚ train â”‚
â”‚ 30 â”‚ model.feature_extractor.network.3      â”‚ Linear        â”‚  1.0 M â”‚ train â”‚
â”‚ 31 â”‚ model.feature_extractor.network.4      â”‚ ReLU          â”‚      0 â”‚ train â”‚
â”‚ 32 â”‚ model.feature_extractor.network.5      â”‚ Dropout       â”‚      0 â”‚ train â”‚
â”‚ 33 â”‚ model.head                             â”‚ Deterministiâ€¦ â”‚  1.0 K â”‚ train â”‚
â”‚ 34 â”‚ model.head.linear                      â”‚ Linear        â”‚  1.0 K â”‚ train â”‚
â”‚ 35 â”‚ model.dropout                          â”‚ Dropout       â”‚      0 â”‚ train â”‚
â”‚ 36 â”‚ loss                                   â”‚ RetrieverLisâ€¦ â”‚      0 â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 8.4 M                                                         
Non-trainable params: 0                                                         
Total params: 8.4 M                                                             
Total estimated model params size (MB): 33                                      
Modules in train mode: 37                                                       
Modules in eval mode: 0                                                         
[[36m2025-12-15 17:40:26,560[0m][[34msrc.data.components.loader[0m][[32mINFO[0m] - UnifiedDataLoader initialized: batch_size=32 shuffle=False[0m
[[36m2025-12-15 17:40:28,779[0m][[34msrc.data.components.loader[0m][[32mINFO[0m] - UnifiedDataLoader initialized: batch_size=32 shuffle=True[0m
Epoch 31/9999 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 85/85 0:00:39 â€¢        2.20it/s v_num: ljug      
                                     0:00:00                   val/loss: 2.683  
                                                               train/loss: 0.347
[[36m2025-12-15 18:03:51,479[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting testing![0m
[[36m2025-12-15 18:03:51,481[0m][[34msrc.data.g_retrieval_dataset[0m][[32mINFO[0m] - GRetrievalDataset[test] initialized: 1628 samples.[0m
Restoring states from the checkpoint path at /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/2025-12-15_17-40-20/checkpoints/epoch_021.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/2025-12-15_17-40-20/checkpoints/epoch_021.ckpt
[[36m2025-12-15 18:03:51,567[0m][[34msrc.data.components.loader[0m][[32mINFO[0m] - UnifiedDataLoader initialized: batch_size=32 shuffle=False[0m
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ          Test metric          â”ƒ         DataLoader 0          â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚  test/answer/answer_recall@1  â”‚      0.3445131778717041       â”‚
â”‚ test/answer/answer_recall@10  â”‚      0.6823616623878479       â”‚
â”‚ test/answer/answer_recall@100 â”‚       0.872272789478302       â”‚
â”‚ test/answer/answer_recall@200 â”‚      0.9036312699317932       â”‚
â”‚ test/answer/answer_recall@25  â”‚       0.772223949432373       â”‚
â”‚ test/answer/answer_recall@300 â”‚      0.9141727685928345       â”‚
â”‚ test/answer/answer_recall@400 â”‚      0.9203988313674927       â”‚
â”‚  test/answer/answer_recall@5  â”‚      0.5881935358047485       â”‚
â”‚ test/answer/answer_recall@50  â”‚       0.835922122001648       â”‚
â”‚           test/loss           â”‚      2.4047985076904297       â”‚
â”‚       test/ranking/f1@1       â”‚      0.2681293785572052       â”‚
â”‚      test/ranking/f1@10       â”‚      0.3531244695186615       â”‚
â”‚      test/ranking/f1@100      â”‚      0.16137531399726868      â”‚
â”‚      test/ranking/f1@200      â”‚      0.11557865142822266      â”‚
â”‚      test/ranking/f1@25       â”‚      0.2719324231147766       â”‚
â”‚      test/ranking/f1@300      â”‚      0.09173966199159622      â”‚
â”‚      test/ranking/f1@400      â”‚      0.07660181820392609      â”‚
â”‚       test/ranking/f1@5       â”‚      0.39084768295288086      â”‚
â”‚      test/ranking/f1@50       â”‚      0.2145523577928543       â”‚
â”‚       test/ranking/mrr        â”‚      0.7885057330131531       â”‚
â”‚      test/ranking/ndcg@1      â”‚      0.7042526006698608       â”‚
â”‚     test/ranking/ndcg@10      â”‚      0.7091875076293945       â”‚
â”‚     test/ranking/ndcg@100     â”‚       0.760725200176239       â”‚
â”‚     test/ranking/ndcg@200     â”‚      0.7734463214874268       â”‚
â”‚     test/ranking/ndcg@25      â”‚       0.729238748550415       â”‚
â”‚     test/ranking/ndcg@300     â”‚      0.7794814109802246       â”‚
â”‚     test/ranking/ndcg@400     â”‚      0.7833081483840942       â”‚
â”‚      test/ranking/ndcg@5      â”‚      0.6996493935585022       â”‚
â”‚     test/ranking/ndcg@50      â”‚      0.7461276650428772       â”‚
â”‚   test/ranking/precision@1    â”‚      0.7042526006698608       â”‚
â”‚   test/ranking/precision@10   â”‚      0.39555490016937256      â”‚
â”‚  test/ranking/precision@100   â”‚      0.12938755750656128      â”‚
â”‚  test/ranking/precision@200   â”‚      0.08410737663507462      â”‚
â”‚   test/ranking/precision@25   â”‚      0.26414909958839417      â”‚
â”‚  test/ranking/precision@300   â”‚      0.06272587925195694      â”‚
â”‚  test/ranking/precision@400   â”‚     0.050159357488155365      â”‚
â”‚   test/ranking/precision@5    â”‚      0.5190733671188354       â”‚
â”‚   test/ranking/precision@50   â”‚      0.1898706704378128       â”‚
â”‚     test/ranking/recall@1     â”‚      0.20296317338943481      â”‚
â”‚    test/ranking/recall@10     â”‚      0.6074238419532776       â”‚
â”‚    test/ranking/recall@100    â”‚      0.8660544157028198       â”‚
â”‚    test/ranking/recall@200    â”‚      0.9154476523399353       â”‚
â”‚    test/ranking/recall@25     â”‚      0.7249078750610352       â”‚
â”‚    test/ranking/recall@300    â”‚      0.9385174512863159       â”‚
â”‚    test/ranking/recall@400    â”‚      0.9510320425033569       â”‚
â”‚     test/ranking/recall@5     â”‚      0.4975273609161377       â”‚
â”‚    test/ranking/recall@50     â”‚      0.8012620806694031       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Testing â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 51/51 0:00:24 â€¢ 0:00:00 2.07it/s 
[[36m2025-12-15 18:04:17,012[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Best ckpt path: /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/2025-12-15_17-40-20/checkpoints/epoch_021.ckpt[0m
[[36m2025-12-15 18:04:17,013[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /mnt/wangjingxiong/EVI-RAG/logs/train_retriever_webqsp/runs/2025-12-15_17-40-20[0m
[[36m2025-12-15 18:04:17,014[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                            epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:      test/answer/answer_recall@1 â–
wandb:     test/answer/answer_recall@10 â–
wandb:    test/answer/answer_recall@100 â–
wandb:    test/answer/answer_recall@200 â–
wandb:     test/answer/answer_recall@25 â–
wandb:    test/answer/answer_recall@300 â–
wandb:    test/answer/answer_recall@400 â–
wandb:      test/answer/answer_recall@5 â–
wandb:     test/answer/answer_recall@50 â–
wandb:                        test/loss â–
wandb:                test/ranking/f1@1 â–
wandb:               test/ranking/f1@10 â–
wandb:              test/ranking/f1@100 â–
wandb:              test/ranking/f1@200 â–
wandb:               test/ranking/f1@25 â–
wandb:              test/ranking/f1@300 â–
wandb:              test/ranking/f1@400 â–
wandb:                test/ranking/f1@5 â–
wandb:               test/ranking/f1@50 â–
wandb:                 test/ranking/mrr â–
wandb:              test/ranking/ndcg@1 â–
wandb:             test/ranking/ndcg@10 â–
wandb:            test/ranking/ndcg@100 â–
wandb:            test/ranking/ndcg@200 â–
wandb:             test/ranking/ndcg@25 â–
wandb:            test/ranking/ndcg@300 â–
wandb:            test/ranking/ndcg@400 â–
wandb:              test/ranking/ndcg@5 â–
wandb:             test/ranking/ndcg@50 â–
wandb:         test/ranking/precision@1 â–
wandb:        test/ranking/precision@10 â–
wandb:       test/ranking/precision@100 â–
wandb:       test/ranking/precision@200 â–
wandb:        test/ranking/precision@25 â–
wandb:       test/ranking/precision@300 â–
wandb:       test/ranking/precision@400 â–
wandb:         test/ranking/precision@5 â–
wandb:        test/ranking/precision@50 â–
wandb:            test/ranking/recall@1 â–
wandb:           test/ranking/recall@10 â–
wandb:          test/ranking/recall@100 â–
wandb:          test/ranking/recall@200 â–
wandb:           test/ranking/recall@25 â–
wandb:          test/ranking/recall@300 â–
wandb:          test/ranking/recall@400 â–
wandb:            test/ranking/recall@5 â–
wandb:           test/ranking/recall@50 â–
wandb:                       train/loss â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              train/loss/listwise â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              train/loss/pairwise â–ˆâ–†â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:            train/metric/neg_prob â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train/metric/num_pairwise_graphs â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/metric/num_pos_graphs â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:            train/metric/pos_prob â–ˆâ–ˆâ–„â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–
wandb:          train/metric/separation â–â–ˆâ–†â–…â–†â–‡â–†â–†â–†â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:              trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:       val/answer/answer_recall@1 â–â–…â–„â–†â–…â–†â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆ
wandb:      val/answer/answer_recall@10 â–â–…â–†â–†â–…â–†â–†â–…â–†â–ˆâ–‡â–ˆâ–†â–‡â–†â–‡â–†â–ˆâ–ˆâ–†â–†â–‡â–†â–‡â–ˆâ–‡â–…â–†â–‡â–†â–‡â–‡
wandb:     val/answer/answer_recall@100 â–â–„â–†â–†â–…â–…â–‡â–‡â–†â–†â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–ˆâ–ˆâ–†â–‡
wandb:     val/answer/answer_recall@200 â–â–…â–…â–…â–„â–„â–…â–†â–†â–…â–…â–…â–…â–†â–†â–…â–…â–†â–†â–„â–‡â–…â–†â–‡â–…â–†â–ƒâ–„â–ˆâ–†â–…â–…
wandb:      val/answer/answer_recall@25 â–â–†â–†â–‡â–†â–†â–†â–‡â–†â–ˆâ–ˆâ–‡â–†â–‡â–†â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–†â–ˆâ–‡â–‡â–‡
wandb:     val/answer/answer_recall@300 â–ƒâ–…â–†â–†â–…â–‚â–„â–‡â–…â–…â–…â–„â–…â–„â–…â–…â–ƒâ–„â–„â–‚â–†â–†â–…â–…â–ƒâ–…â–â–ƒâ–ˆâ–…â–†â–ˆ
wandb:     val/answer/answer_recall@400 â–„â–„â–„â–…â–„â–ƒâ–†â–†â–†â–‡â–„â–…â–…â–„â–„â–†â–…â–â–‡â–ƒâ–…â–…â–†â–†â–‚â–„â–‚â–†â–‡â–†â–‡â–ˆ
wandb:       val/answer/answer_recall@5 â–â–…â–…â–‡â–†â–†â–‡â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–ˆ
wandb:      val/answer/answer_recall@50 â–â–…â–†â–†â–…â–…â–†â–ˆâ–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–†â–†â–‡â–ˆâ–‡â–ˆ
wandb:                         val/loss â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–â–â–â–â–â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–„â–ƒâ–‚â–‚â–ƒâ–ƒ
wandb:                 val/ranking/f1@1 â–â–†â–…â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–…â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡
wandb:                val/ranking/f1@10 â–â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               val/ranking/f1@100 â–â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡
wandb:               val/ranking/f1@200 â–â–„â–…â–…â–…â–†â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:                val/ranking/f1@25 â–â–†â–…â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               val/ranking/f1@300 â–â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:               val/ranking/f1@400 â–â–„â–„â–…â–…â–‡â–†â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆ
wandb:                 val/ranking/f1@5 â–â–†â–„â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆ
wandb:                val/ranking/f1@50 â–â–…â–†â–†â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                  val/ranking/mrr â–â–†â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:               val/ranking/ndcg@1 â–â–†â–…â–‡â–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:              val/ranking/ndcg@10 â–â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:             val/ranking/ndcg@100 â–â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:             val/ranking/ndcg@200 â–â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:              val/ranking/ndcg@25 â–â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:             val/ranking/ndcg@300 â–â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:             val/ranking/ndcg@400 â–â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:               val/ranking/ndcg@5 â–â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:              val/ranking/ndcg@50 â–â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:          val/ranking/precision@1 â–â–†â–…â–‡â–†â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:         val/ranking/precision@10 â–â–†â–…â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:        val/ranking/precision@100 â–â–…â–„â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:        val/ranking/precision@200 â–â–„â–„â–†â–…â–‡â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         val/ranking/precision@25 â–â–…â–…â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        val/ranking/precision@300 â–â–„â–„â–…â–…â–‡â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:        val/ranking/precision@400 â–â–„â–„â–†â–…â–‡â–†â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡
wandb:          val/ranking/precision@5 â–â–…â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:         val/ranking/precision@50 â–â–…â–…â–†â–†â–‡â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             val/ranking/recall@1 â–â–†â–…â–†â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–…â–‡
wandb:            val/ranking/recall@10 â–â–†â–…â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:           val/ranking/recall@100 â–â–†â–…â–†â–†â–†â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:           val/ranking/recall@200 â–â–…â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:            val/ranking/recall@25 â–â–†â–…â–‡â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:           val/ranking/recall@300 â–â–„â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:           val/ranking/recall@400 â–â–„â–„â–„â–…â–†â–…â–†â–†â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:             val/ranking/recall@5 â–â–†â–„â–†â–‡â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:            val/ranking/recall@50 â–â–†â–†â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:                            epoch 32
wandb:      test/answer/answer_recall@1 0.34451
wandb:     test/answer/answer_recall@10 0.68236
wandb:    test/answer/answer_recall@100 0.87227
wandb:    test/answer/answer_recall@200 0.90363
wandb:     test/answer/answer_recall@25 0.77222
wandb:    test/answer/answer_recall@300 0.91417
wandb:    test/answer/answer_recall@400 0.9204
wandb:      test/answer/answer_recall@5 0.58819
wandb:     test/answer/answer_recall@50 0.83592
wandb:                        test/loss 2.4048
wandb:                test/ranking/f1@1 0.26813
wandb:               test/ranking/f1@10 0.35312
wandb:              test/ranking/f1@100 0.16138
wandb:              test/ranking/f1@200 0.11558
wandb:               test/ranking/f1@25 0.27193
wandb:              test/ranking/f1@300 0.09174
wandb:              test/ranking/f1@400 0.0766
wandb:                test/ranking/f1@5 0.39085
wandb:               test/ranking/f1@50 0.21455
wandb:                 test/ranking/mrr 0.78851
wandb:              test/ranking/ndcg@1 0.70425
wandb:             test/ranking/ndcg@10 0.70919
wandb:            test/ranking/ndcg@100 0.76073
wandb:            test/ranking/ndcg@200 0.77345
wandb:             test/ranking/ndcg@25 0.72924
wandb:            test/ranking/ndcg@300 0.77948
wandb:            test/ranking/ndcg@400 0.78331
wandb:              test/ranking/ndcg@5 0.69965
wandb:             test/ranking/ndcg@50 0.74613
wandb:         test/ranking/precision@1 0.70425
wandb:        test/ranking/precision@10 0.39555
wandb:       test/ranking/precision@100 0.12939
wandb:       test/ranking/precision@200 0.08411
wandb:        test/ranking/precision@25 0.26415
wandb:       test/ranking/precision@300 0.06273
wandb:       test/ranking/precision@400 0.05016
wandb:         test/ranking/precision@5 0.51907
wandb:        test/ranking/precision@50 0.18987
wandb:            test/ranking/recall@1 0.20296
wandb:           test/ranking/recall@10 0.60742
wandb:          test/ranking/recall@100 0.86605
wandb:          test/ranking/recall@200 0.91545
wandb:           test/ranking/recall@25 0.72491
wandb:          test/ranking/recall@300 0.93852
wandb:          test/ranking/recall@400 0.95103
wandb:            test/ranking/recall@5 0.49753
wandb:           test/ranking/recall@50 0.80126
wandb:                       train/loss 0.34716
wandb:              train/loss/listwise 0.08212
wandb:              train/loss/pairwise 0.26504
wandb:            train/metric/neg_prob 0.0085
wandb: train/metric/num_pairwise_graphs 31.91137
wandb:      train/metric/num_pos_graphs 31.91137
wandb:            train/metric/pos_prob 0.50492
wandb:          train/metric/separation 0.49642
wandb:              trainer/global_step 2720
wandb:       val/answer/answer_recall@1 0.36641
wandb:      val/answer/answer_recall@10 0.69005
wandb:     val/answer/answer_recall@100 0.9006
wandb:     val/answer/answer_recall@200 0.92796
wandb:      val/answer/answer_recall@25 0.80069
wandb:     val/answer/answer_recall@300 0.96342
wandb:     val/answer/answer_recall@400 0.97383
wandb:       val/answer/answer_recall@5 0.60339
wandb:      val/answer/answer_recall@50 0.86565
wandb:                         val/loss 2.68338
wandb:                 val/ranking/f1@1 0.24737
wandb:                val/ranking/f1@10 0.3528
wandb:               val/ranking/f1@100 0.153
wandb:               val/ranking/f1@200 0.10892
wandb:                val/ranking/f1@25 0.28
wandb:               val/ranking/f1@300 0.08898
wandb:               val/ranking/f1@400 0.07509
wandb:                 val/ranking/f1@5 0.39286
wandb:                val/ranking/f1@50 0.21456
wandb:                  val/ranking/mrr 0.77547
wandb:               val/ranking/ndcg@1 0.69658
wandb:              val/ranking/ndcg@10 0.70534
wandb:             val/ranking/ndcg@100 0.74378
wandb:             val/ranking/ndcg@200 0.76026
wandb:              val/ranking/ndcg@25 0.71401
wandb:             val/ranking/ndcg@300 0.76958
wandb:             val/ranking/ndcg@400 0.77361
wandb:               val/ranking/ndcg@5 0.70318
wandb:              val/ranking/ndcg@50 0.72908
wandb:          val/ranking/precision@1 0.69658
wandb:         val/ranking/precision@10 0.40855
wandb:        val/ranking/precision@100 0.12316
wandb:        val/ranking/precision@200 0.08248
wandb:         val/ranking/precision@25 0.27111
wandb:        val/ranking/precision@300 0.06467
wandb:        val/ranking/precision@400 0.05281
wandb:          val/ranking/precision@5 0.5359
wandb:         val/ranking/precision@50 0.18718
wandb:             val/ranking/recall@1 0.17866
wandb:            val/ranking/recall@10 0.58483
wandb:           val/ranking/recall@100 0.84014
wandb:           val/ranking/recall@200 0.89445
wandb:            val/ranking/recall@25 0.69696
wandb:           val/ranking/recall@300 0.93062
wandb:           val/ranking/recall@400 0.94718
wandb:             val/ranking/recall@5 0.48477
wandb:            val/ranking/recall@50 0.77616
wandb: 
wandb: ğŸš€ View run train_retriever_webqsp at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/sd5gljug
wandb: â­ï¸ View project at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/train_retriever_webqsp/runs/2025-12-15_17-40-20/wandb/run-20251215_174022-sd5gljug/logs
[[36m2025-12-15 18:04:18,834[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Metric name is None! Skipping metric value retrieval...[0m
