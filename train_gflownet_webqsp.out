[[36m2025-12-05 14:32:37,050[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-12-05 14:32:37,053[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] torch.set_float32_matmul_precision(high)[0m
[[36m2025-12-05 14:32:37,053[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.g_agent_datamodule.GAgentDataModule                  
â”‚       cache_paths:                                                            
â”‚         train: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g
â”‚         validation: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/va
â”‚         test: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_a
â”‚       batch_size: 64                                                          
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       drop_last: false                                                        
â”‚       persistent_workers: true                                                
â”‚       shuffle_train: true                                                     
â”‚       resources:                                                              
â”‚         vocabulary_path: /mnt/data/retrieval_dataset/webqsp/materialized/vocab
â”‚         embeddings_dir: /mnt/data/retrieval_dataset/webqsp/materialized/embedd
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.gflownet_module.GFlowNetModule                     
â”‚       _recursive_: false                                                      
â”‚       hidden_dim: 1024                                                        
â”‚       training_cfg:                                                           
â”‚         normalize_log_reward: true                                            
â”‚         gt_replay_ratio: 0.3                                                  
â”‚         learn_pb: true                                                        
â”‚         debug_batches_to_log: 1                                               
â”‚         debug_graphs_to_log: 2                                                
â”‚         retriever_prior_alpha: 2.0                                            
â”‚         retriever_prior_anneal:                                               
â”‚           start: 2.0                                                          
â”‚           end: 0.0                                                            
â”‚           steps: 10000                                                        
â”‚         pb_loss_weight: 1.0                                                   
â”‚         pb_loss_anneal:                                                       
â”‚           start: 1.0                                                          
â”‚           end: 0.0                                                            
â”‚           steps: 5000                                                         
â”‚         gt_loss_weight: 0.15                                                  
â”‚       evaluation_cfg:                                                         
â”‚         num_eval_rollouts:                                                    
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚         path_hit_k:                                                           
â”‚         - 1                                                                   
â”‚         - 5                                                                   
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚       optimizer_cfg:                                                          
â”‚         type: adamw                                                           
â”‚         lr: 0.0001                                                            
â”‚         weight_decay: 0.0001                                                  
â”‚         param_groups:                                                         
â”‚         - params:                                                             
â”‚           - estimator.log_z_head                                              
â”‚           - estimator.log_z_condition                                         
â”‚           lr: 0.001                                                           
â”‚       scheduler_cfg:                                                          
â”‚         type: cosine                                                          
â”‚         t_max: 200                                                            
â”‚         eta_min: 1.0e-06                                                      
â”‚         interval: epoch                                                       
â”‚         monitor: val/reward                                                   
â”‚       logging_cfg:                                                            
â”‚         train_prog_bar:                                                       
â”‚         - rollout_reward                                                      
â”‚         - success_mean                                                        
â”‚         - answer_coverage                                                     
â”‚         - length_mean                                                         
â”‚         eval_prog_bar:                                                        
â”‚         - success_mean                                                        
â”‚         - answer_f1                                                           
â”‚         auto_add_success_at_k: true                                           
â”‚         auto_add_path_hit_f1: true                                            
â”‚         log_on_step_train: false                                              
â”‚       env_cfg:                                                                
â”‚         _target_: src.models.components.gflownet_env.GraphEnv                 
â”‚         mode: path                                                            
â”‚         max_steps: 6                                                          
â”‚         forbid_backtrack: true                                                
â”‚         forbid_revisit: true                                                  
â”‚         bidir_token: false                                                    
â”‚         debug: true                                                           
â”‚         debug_max_resets: 2                                                   
â”‚         debug_max_graphs: 2                                                   
â”‚         debug_max_hits: 4                                                     
â”‚       policy_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_policies.EdgeMLPMixerPolicy  
â”‚         hidden_dim: 1024                                                      
â”‚         dropout: 0.5                                                          
â”‚         num_layers: 2                                                         
â”‚       reward_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_rewards.AnswerOnlyReward     
â”‚         success_reward: 10.0                                                  
â”‚         failure_reward: 0.01                                                  
â”‚         lambda_reach: 0.0                                                     
â”‚         gamma_len: 0.0                                                        
â”‚         gamma_score: 0.0                                                      
â”‚         score_clip_max: 1.0                                                   
â”‚         score_eps: 1.0e-08                                                    
â”‚         gamma_gt: 0.0                                                         
â”‚         gamma_answer_div: 0.0                                                 
â”‚       actor_cfg:                                                              
â”‚         _target_: src.models.components.gflownet_actor.GFlowNetActor          
â”‚         policy_temperature: 1.0                                               
â”‚         eval_policy_temperature: 0.7                                          
â”‚         stop_logit_bias: -1.0                                                 
â”‚         random_action_prob: 0.1                                               
â”‚         debug_actions: false                                                  
â”‚         debug_actions_steps: 0                                                
â”‚       embedder_cfg:                                                           
â”‚         _target_: src.models.components.gflownet_embedder.GraphEmbedder       
â”‚         hidden_dim: 1024                                                      
â”‚         proj_dropout: 0.0                                                     
â”‚         projector_checkpoint: logs/train_retriever_webqsp/runs/2025-12-02_19-2
â”‚         freeze_projectors: true                                               
â”‚         kge_interaction: concat                                               
â”‚         projector_key_prefixes:                                               
â”‚         - retriever.model._orig_mod                                           
â”‚         - retriever.model                                                     
â”‚         - retriever                                                           
â”‚         - model._orig_mod                                                     
â”‚         - model                                                               
â”‚         - ''                                                                  
â”‚         use_gfn_projectors: true                                              
â”‚       estimator_cfg:                                                          
â”‚         _target_: src.models.components.gflownet_estimator.GFlowNetEstimator  
â”‚         hidden_dim: 1024                                                      
â”‚         log_pb_mode: learned                                                  
â”‚         learn_pb: true                                                        
â”‚         pb_entropy_coef: 0.0                                                  
â”‚         pb_l2_reg: 0.0                                                        
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/20
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/rollout_reward                                           
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 1                                                         
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/rollout_reward                                           
â”‚         min_delta: 0.0                                                        
â”‚         patience: 50                                                          
â”‚         verbose: false                                                        
â”‚         mode: max                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         name: train_gflownet_webqsp_rpa=0.0                                   
â”‚         save_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: evi-rag                                                      
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         entity: null                                                          
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/
â”‚       min_epochs: 50                                                          
â”‚       max_epochs: 200                                                         
â”‚       accelerator: gpu                                                        
â”‚       devices: 1                                                              
â”‚       gradient_clip_val: 1.0                                                  
â”‚       check_val_every_n_epoch: 1                                              
â”‚       log_every_n_steps: 1                                                    
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚       data_dir: /mnt/data/retrieval_dataset                                   
â”‚       log_dir: /mnt/wangjingxiong/EVI-RAG/logs/                               
â”‚       debug_log_path: /mnt/wangjingxiong/EVI-RAG/logs//debug.log              
â”‚       output_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2
â”‚       work_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚       torch_float32_matmul_precision: high                                    
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train_gflownet_webqsp_rpa=0.0                                           
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['webqsp', 'gflownet']                                                  
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ debug_data_loading
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ test_ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ allow_test_without_checkpoint
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 42                                                                      
â”œâ”€â”€ dataset
â”‚   â””â”€â”€ name: webqsp                                                            
â”‚       kb: freebase                                                            
â”‚       raw_root: /mnt/data/retrieval_dataset/webqsp/raw/data                   
â”‚       out_dir: /mnt/data/retrieval_dataset/webqsp/normalized                  
â”‚       materialized_dir: /mnt/data/retrieval_dataset/webqsp/materialized       
â”‚       paths:                                                                  
â”‚         vocabulary: /mnt/data/retrieval_dataset/webqsp/materialized/vocabulary
â”‚         embeddings: /mnt/data/retrieval_dataset/webqsp/materialized/embeddings
â”‚         processed: /mnt/data/retrieval_dataset/webqsp/materialized/processed  
â”‚       entity_normalization: none                                              
â”‚       undirected_traversal: false                                             
â”‚       hard_negative_k: 4                                                      
â”‚       hard_negative_similarity: cosine                                        
â”‚       column_map:                                                             
â”‚         question_id_field: id                                                 
â”‚         question_field: question                                              
â”‚         answer_text_field: answer                                             
â”‚         q_entity_field: q_entity                                              
â”‚         a_entity_field: a_entity                                              
â”‚         graph_field: graph                                                    
â”‚                                                                               
â”œâ”€â”€ optimized_metric
â”‚   â””â”€â”€ val/rollout_reward                                                      
â”œâ”€â”€ gflownet_debug
â”‚   â””â”€â”€ True                                                                    
â””â”€â”€ env_debug
    â””â”€â”€ True                                                                    
Seed set to 42
[[36m2025-12-05 14:32:37,100[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resolved run name: train_gflownet_webqsp[0m
[[36m2025-12-05 14:32:37,100[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.g_agent_datamodule.GAgentDataModule>[0m
[[36m2025-12-05 14:32:37,592[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.gflownet_module.GFlowNetModule>[0m
[[36m2025-12-05 14:32:37,660[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-12-05 14:32:37,660[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-12-05 14:32:37,662[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-12-05 14:32:37,662[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-12-05 14:32:37,662[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-12-05 14:32:37,663[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-12-05 14:32:37,663[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-12-05 14:32:37,665[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
[[36m2025-12-05 14:32:37,699[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: martin1007wang (martin1007wang-wuhan-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2025-12-05_14-32-36/wandb/run-20251205_143238-9piqs307
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train_gflownet_webqsp
wandb: â­ï¸ View project at https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: ğŸš€ View run at https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/9piqs307
[[36m2025-12-05 14:32:40,576[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-12-05 14:32:41,754[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g_agent.pt: 1956 samples.[0m
[[36m2025-12-05 14:32:41,824[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/validation_g_agent.pt: 170 samples.[0m
[[36m2025-12-05 14:32:42,142[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/entity_embeddings.pt...[0m
[[36m2025-12-05 14:32:42,931[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/relation_embeddings.pt...[0m
[[36m2025-12-05 14:32:42,940[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Entity embedding rows: 524643 (vocab entities: 1281202). Non-text entities use embedding_id=0; textual entities occupy 1..max_id.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                                            â”ƒ Type  â”ƒ Paraâ€¦ â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ policy                                          â”‚ Edgeâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 1  â”‚ policy.type_embeddings                          â”‚ Embeâ€¦ â”‚ 5.1 K â”‚ train â”‚
â”‚ 2  â”‚ policy.graph_norm                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 3  â”‚ policy.q_film                                   â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 4  â”‚ policy.q_film.0                                 â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 5  â”‚ policy.q_film.1                                 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 6  â”‚ policy.q_film.2                                 â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 7  â”‚ policy.edge_mlp                                 â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 8  â”‚ policy.edge_mlp.0                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 9  â”‚ policy.edge_mlp.1                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 10 â”‚ policy.edge_mlp.2                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 11 â”‚ policy.edge_mlp.3                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 12 â”‚ policy.edge_mlp.4                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 13 â”‚ policy.edge_mlp.5                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 14 â”‚ policy.edge_mlp.6                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 15 â”‚ policy.edge_mlp.7                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 16 â”‚ policy.lookahead_head                           â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 17 â”‚ policy.lookahead_head.0                         â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 18 â”‚ policy.lookahead_head.1                         â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 19 â”‚ policy.lookahead_head.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 20 â”‚ policy.lookahead_head.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 21 â”‚ policy.lookahead_head.4                         â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 22 â”‚ policy.stop_proj                                â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 23 â”‚ policy.stop_proj.0                              â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 24 â”‚ policy.stop_proj.1                              â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 25 â”‚ policy.stop_proj.2                              â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 26 â”‚ policy.stop_proj.3                              â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 27 â”‚ reward_fn                                       â”‚ Answâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 28 â”‚ env                                             â”‚ Grapâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 29 â”‚ embedder                                        â”‚ Grapâ€¦ â”‚  12.6 â”‚ train â”‚
â”‚    â”‚                                                 â”‚       â”‚     M â”‚       â”‚
â”‚ 30 â”‚ embedder.entity_projector                       â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 31 â”‚ embedder.entity_projector.0                     â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 32 â”‚ embedder.entity_projector.1                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 33 â”‚ embedder.entity_projector.2                     â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 34 â”‚ embedder.entity_projector.3                     â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 35 â”‚ embedder.entity_projector.4                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 36 â”‚ embedder.relation_projector                     â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 37 â”‚ embedder.relation_projector.0                   â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 38 â”‚ embedder.relation_projector.1                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 39 â”‚ embedder.relation_projector.2                   â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 40 â”‚ embedder.relation_projector.3                   â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 41 â”‚ embedder.relation_projector.4                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 42 â”‚ embedder.edge_adapter                           â”‚ Sequâ€¦ â”‚ 5.3 M â”‚ train â”‚
â”‚ 43 â”‚ embedder.edge_adapter.0                         â”‚ Layeâ€¦ â”‚ 8.2 K â”‚ train â”‚
â”‚ 44 â”‚ embedder.edge_adapter.1                         â”‚ Lineâ€¦ â”‚ 4.2 M â”‚ train â”‚
â”‚ 45 â”‚ embedder.edge_adapter.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 46 â”‚ embedder.edge_adapter.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 47 â”‚ embedder.edge_adapter.4                         â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 48 â”‚ embedder.retriever_entity_projector             â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 49 â”‚ embedder.retriever_entity_projector.network     â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 50 â”‚ embedder.retriever_entity_projector.network.0   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 51 â”‚ embedder.retriever_entity_projector.network.1   â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 52 â”‚ embedder.retriever_relation_projector           â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 53 â”‚ embedder.retriever_relation_projector.network   â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 54 â”‚ embedder.retriever_relation_projector.network.0 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 55 â”‚ embedder.retriever_relation_projector.network.1 â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 56 â”‚ embedder.retriever_query_projector              â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 57 â”‚ embedder.retriever_query_projector.network      â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 58 â”‚ embedder.retriever_query_projector.network.0    â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 59 â”‚ embedder.retriever_query_projector.network.1    â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 60 â”‚ estimator                                       â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 61 â”‚ estimator.log_z_head                            â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 62 â”‚ estimator.log_z_head.0                          â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 63 â”‚ estimator.log_z_head.1                          â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 64 â”‚ estimator.log_z_head.2                          â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 65 â”‚ estimator.log_z_head.3                          â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 66 â”‚ estimator.ctx_projector                         â”‚ Sequâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 67 â”‚ estimator.ctx_projector.0                       â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 68 â”‚ estimator.ctx_projector.1                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 69 â”‚ estimator.ctx_projector.2                       â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 70 â”‚ estimator.backward_head                         â”‚ Sequâ€¦ â”‚ 3.2 M â”‚ train â”‚
â”‚ 71 â”‚ estimator.backward_head.0                       â”‚ Layeâ€¦ â”‚ 6.1 K â”‚ train â”‚
â”‚ 72 â”‚ estimator.backward_head.1                       â”‚ Lineâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 73 â”‚ estimator.backward_head.2                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 74 â”‚ estimator.backward_head.3                       â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 75 â”‚ estimator.backward_head.4                       â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 76 â”‚ actor                                           â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 24.2 M                                                        
Non-trainable params: 3.1 M                                                     
Total params: 27.3 M                                                            
Total estimated model params size (MB): 109                                     
Modules in train mode: 65                                                       
Modules in eval mode: 12                                                        
/anaconda3/envs/pog/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 12 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Epoch 56/199 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 31/31 0:00:09 â€¢ 0:00:00 3.40it/s v_num: s307      
                                                               val/answer_f1:   
                                                               0.436            
                                                               val/path_hit_f1@â€¦
                                                               0.532            
                                                               val/success_mean:
                                                               0.918            
                                                               val/success@20:  
                                                               0.929 train/loss:
                                                               2.046            
                                                               train/rollout_reâ€¦
                                                               0.870            
                                                               train/success_meâ€¦
                                                               0.870            
                                                               train/answer_covâ€¦
                                                               0.552            
                                                               train/length_meaâ€¦
                                                               1.011            
[[36m2025-12-05 14:46:24,905[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting testing![0m
[[36m2025-12-05 14:46:25,577[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_agent.pt: 1113 samples.[0m
Restoring states from the checkpoint path at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2025-12-05_14-32-36/checkpoints/epoch_006.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2025-12-05_14-32-36/checkpoints/epoch_006.ckpt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ         Test metric         â”ƒ        DataLoader 0         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚    test/answer_coverage     â”‚     0.5657452344894409      â”‚
â”‚       test/answer_f1        â”‚     0.44670534133911133     â”‚
â”‚   test/answer_hit_any@10    â”‚      0.942497730255127      â”‚
â”‚   test/answer_hit_any@20    â”‚     0.9451931715011597      â”‚
â”‚    test/answer_precision    â”‚     0.4616464376449585      â”‚
â”‚     test/answer_recall      â”‚     0.5657452344894409      â”‚
â”‚ test/answer_recall_union@10 â”‚     0.7484290599822998      â”‚
â”‚ test/answer_recall_union@20 â”‚     0.7860714197158813      â”‚
â”‚    test/avg_step_entropy    â”‚     1.1739481687545776      â”‚
â”‚  test/fallback_to_system1   â”‚             0.0             â”‚
â”‚     test/gt_path_exists     â”‚             1.0             â”‚
â”‚    test/gt_path_full_hit    â”‚     0.5378257036209106      â”‚
â”‚      test/length_mean       â”‚     1.0043576955795288      â”‚
â”‚       test/log_reward       â”‚     -0.5232019424438477     â”‚
â”‚   test/log_reward_struct    â”‚     1.7793833017349243      â”‚
â”‚    test/logpf_logr_corr     â”‚     0.6379684209823608      â”‚
â”‚  test/logpf_logr_spearman   â”‚     0.1701546460390091      â”‚
â”‚      test/modes_found       â”‚     2.3171608448028564      â”‚
â”‚      test/modes_recall      â”‚     0.7860714197158813      â”‚
â”‚      test/path_exists       â”‚             1.0             â”‚
â”‚   test/path_exists_ratio    â”‚             1.0             â”‚
â”‚    test/path_hit_any@10     â”‚     0.7789757251739502      â”‚
â”‚    test/path_hit_any@20     â”‚     0.8274932503700256      â”‚
â”‚      test/path_hit_f1       â”‚     0.5373539328575134      â”‚
â”‚     test/path_hit_f1@1      â”‚     0.5376459956169128      â”‚
â”‚     test/path_hit_f1@10     â”‚     0.5373539328575134      â”‚
â”‚     test/path_hit_f1@20     â”‚     0.5373539328575134      â”‚
â”‚     test/path_hit_f1@5      â”‚     0.5373539328575134      â”‚
â”‚   test/path_hit_precision   â”‚     0.5371218919754028      â”‚
â”‚  test/path_hit_precision@1  â”‚     0.5376459956169128      â”‚
â”‚ test/path_hit_precision@10  â”‚     0.5371218919754028      â”‚
â”‚ test/path_hit_precision@20  â”‚     0.5371218919754028      â”‚
â”‚  test/path_hit_precision@5  â”‚     0.5371218919754028      â”‚
â”‚    test/path_hit_recall     â”‚     0.5378257036209106      â”‚
â”‚   test/path_hit_recall@1    â”‚     0.5376459956169128      â”‚
â”‚   test/path_hit_recall@10   â”‚     0.5378257036209106      â”‚
â”‚   test/path_hit_recall@20   â”‚     0.5378257036209106      â”‚
â”‚   test/path_hit_recall@5    â”‚     0.5378257036209106      â”‚
â”‚         test/pb_nll         â”‚     0.3736157715320587      â”‚
â”‚         test/pos_f1         â”‚     0.5373539328575134      â”‚
â”‚     test/pos_precision      â”‚     0.5371218919754028      â”‚
â”‚       test/pos_recall       â”‚     0.5378257036209106      â”‚
â”‚         test/recall         â”‚     0.5657452344894409      â”‚
â”‚  test/reward_connectivity   â”‚     0.5657452344894409      â”‚
â”‚    test/reward_path_term    â”‚             1.0             â”‚
â”‚     test/rollout_reward     â”‚     0.9243345260620117      â”‚
â”‚ test/semantic_only_success  â”‚             0.0             â”‚
â”‚     test/semantic_score     â”‚             1.0             â”‚
â”‚ test/struct_phi_answer_div  â”‚     0.9243935346603394      â”‚
â”‚     test/struct_phi_gt      â”‚     0.5373539328575134      â”‚
â”‚     test/struct_phi_len     â”‚             0.0             â”‚
â”‚    test/struct_phi_score    â”‚             0.0             â”‚
â”‚       test/success@10       â”‚      0.942497730255127      â”‚
â”‚       test/success@20       â”‚     0.9451931715011597      â”‚
â”‚      test/success_mean      â”‚     0.9242587089538574      â”‚
â”‚        test/tb_loss         â”‚     2.4294395446777344      â”‚
â”‚      test/unique_paths      â”‚      3.29469895362854       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Testing â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18/18 0:00:29 â€¢ 0:00:00 0.63it/s 
[[36m2025-12-05 14:46:55,280[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Best ckpt path: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2025-12-05_14-32-36/checkpoints/epoch_006.ckpt[0m
[[36m2025-12-05 14:46:55,281[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_webqsp/runs/2025-12-05_14-32-36[0m
[[36m2025-12-05 14:46:55,281[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: uploading history steps 38-47, summary; updating run metadata
wandb: uploading history steps 48-114, summary, console lines 96-183; uploading output.log; uploading wandb-summary.json
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading data
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading data
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading data
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading data
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading data
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml; uploading data
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: uploading data
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:        test/answer_coverage â–
wandb:              test/answer_f1 â–
wandb:      test/answer_hit_any@10 â–
wandb:      test/answer_hit_any@20 â–
wandb:       test/answer_precision â–
wandb:          test/answer_recall â–
wandb: test/answer_recall_union@10 â–
wandb: test/answer_recall_union@20 â–
wandb:       test/avg_step_entropy â–
wandb:    test/fallback_to_system1 â–
wandb:         test/gt_path_exists â–
wandb:       test/gt_path_full_hit â–
wandb:            test/length_mean â–
wandb:             test/log_reward â–
wandb:      test/log_reward_struct â–
wandb:        test/logpf_logr_corr â–
wandb:    test/logpf_logr_spearman â–
wandb:            test/modes_found â–
wandb:           test/modes_recall â–
wandb:            test/path_exists â–
wandb:      test/path_exists_ratio â–
wandb:        test/path_hit_any@10 â–
wandb:        test/path_hit_any@20 â–
wandb:            test/path_hit_f1 â–
wandb:          test/path_hit_f1@1 â–
wandb:         test/path_hit_f1@10 â–
wandb:         test/path_hit_f1@20 â–
wandb:          test/path_hit_f1@5 â–
wandb:     test/path_hit_precision â–
wandb:   test/path_hit_precision@1 â–
wandb:  test/path_hit_precision@10 â–
wandb:  test/path_hit_precision@20 â–
wandb:   test/path_hit_precision@5 â–
wandb:        test/path_hit_recall â–
wandb:      test/path_hit_recall@1 â–
wandb:     test/path_hit_recall@10 â–
wandb:     test/path_hit_recall@20 â–
wandb:      test/path_hit_recall@5 â–
wandb:                 test/pb_nll â–
wandb:                 test/pos_f1 â–
wandb:          test/pos_precision â–
wandb:             test/pos_recall â–
wandb:                 test/recall â–
wandb:    test/reward_connectivity â–
wandb:       test/reward_path_term â–
wandb:         test/rollout_reward â–
wandb:  test/semantic_only_success â–
wandb:         test/semantic_score â–
wandb:  test/struct_phi_answer_div â–
wandb:          test/struct_phi_gt â–
wandb:         test/struct_phi_len â–
wandb:       test/struct_phi_score â–
wandb:             test/success@10 â–
wandb:             test/success@20 â–
wandb:           test/success_mean â–
wandb:                test/tb_loss â–
wandb:           test/unique_paths â–
wandb:       train/answer_coverage â–ƒâ–â–ƒâ–…â–‚â–…â–…â–„â–„â–…â–…â–…â–„â–„â–…â–ƒâ–…â–„â–…â–…â–ˆâ–„â–…â–ƒâ–…â–„â–ˆâ–„â–„â–…â–„â–„â–†â–ƒâ–…â–„â–„â–ƒâ–†â–„
wandb:             train/answer_f1 â–ƒâ–â–‚â–…â–‚â–…â–ƒâ–ƒâ–…â–ƒâ–„â–…â–„â–„â–…â–ƒâ–…â–…â–…â–„â–„â–…â–ƒâ–‚â–ƒâ–…â–„â–ˆâ–„â–…â–†â–„â–…â–„â–ƒâ–†â–…â–…â–„â–„
wandb:      train/answer_precision â–ƒâ–â–‚â–„â–‚â–„â–…â–ƒâ–†â–‚â–„â–„â–„â–„â–…â–…â–…â–„â–ˆâ–„â–„â–‚â–ƒâ–…â–„â–‡â–…â–…â–†â–ƒâ–ƒâ–†â–…â–…â–„â–„â–†â–…â–„â–…
wandb:         train/answer_recall â–â–ƒâ–…â–‚â–„â–…â–„â–ƒâ–„â–ƒâ–„â–…â–…â–„â–„â–„â–ƒâ–…â–„â–…â–ˆâ–ƒâ–ƒâ–…â–„â–ˆâ–„â–„â–…â–†â–„â–ƒâ–…â–„â–„â–ƒâ–†â–„â–„â–„
wandb:      train/avg_step_entropy â–â–„â–†â–…â–†â–‡â–…â–ˆâ–…â–‡â–†â–†â–‡â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–ˆâ–…â–‡â–†â–‡â–†â–‡â–†â–‡â–†â–‡
wandb:   train/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             train/gt_log_pf â–â–‡â–…â–‚â–†â–‚â–ƒâ–‡â–ˆâ–„â–â–†â–‚â–ˆâ–ƒâ–…â–„â–ƒâ–ƒâ–„â–â–…â–†â–‡â–„â–„â–…â–„â–…â–†â–‡â–†â–…â–ƒâ–‡â–†â–ˆâ–„â–‡â–ƒ
wandb:               train/gt_loss â–…â–„â–ƒâ–…â–†â–…â–‡â–†â–ƒâ–„â–†â–…â–‡â–†â–†â–‚â–ˆâ–‡â–…â–…â–„â–‡â–ƒâ–‚â–†â–†â–„â–…â–…â–„â–„â–ƒâ–ƒâ–…â–ƒâ–„â–â–„â–‚â–„
wandb:        train/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/gt_path_full_hit â–ˆâ–‚â–„â–„â–ƒâ–„â–„â–ƒâ–‚â–…â–„â–„â–„â–ƒâ–‚â–â–„â–„â–‚â–†â–…â–„â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–„â–†â–ƒâ–‚â–…â–„â–ƒâ–‚â–‚â–ƒâ–‚â–„
wandb:           train/length_mean â–…â–ƒâ–…â–…â–„â–…â–ƒâ–†â–„â–„â–…â–…â–ƒâ–„â–ƒâ–…â–„â–‚â–†â–„â–ƒâ–ƒâ–„â–‡â–ƒâ–„â–…â–ƒâ–â–‚â–„â–ƒâ–„â–ˆâ–ƒâ–…â–„â–…â–…â–„
wandb:            train/log_reward â–„â–â–‚â–…â–‚â–†â–ƒâ–†â–‚â–…â–…â–…â–„â–…â–…â–…â–†â–…â–†â–…â–„â–†â–„â–…â–†â–ˆâ–…â–…â–†â–„â–‡â–ƒâ–‡â–…â–†â–ƒâ–„â–‡â–†â–†
wandb:     train/log_reward_struct â–„â–â–…â–ƒâ–…â–ƒâ–„â–‡â–ƒâ–…â–‡â–†â–†â–…â–…â–†â–‡â–†â–†â–…â–‡â–„â–„â–‡â–…â–†â–…â–‡â–„â–ˆâ–ˆâ–…â–†â–…â–ƒâ–ˆâ–†â–‡â–…â–†
wandb:                  train/loss â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–
wandb:           train/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           train/path_hit_f1 â–ˆâ–„â–ƒâ–„â–â–‚â–ƒâ–â–„â–ƒâ–„â–ƒâ–ƒâ–â–„â–„â–ƒâ–„â–â–†â–„â–â–‚â–â–‚â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–ƒâ–â–„â–„â–‚â–‚â–‚â–‚â–„
wandb:    train/path_hit_precision â–‚â–…â–…â–„â–…â–ƒâ–ƒâ–â–†â–„â–†â–…â–„â–â–…â–„â–…â–…â–ˆâ–„â–â–‚â–‚â–ƒâ–„â–ƒâ–†â–ˆâ–„â–ƒâ–†â–†â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–…
wandb:       train/path_hit_recall â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–â–„â–ƒâ–„â–ƒâ–ƒâ–â–„â–„â–ƒâ–„â–â–ƒâ–„â–â–‚â–â–‚â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–„â–‚â–‚â–‚â–‚â–‚â–„
wandb:                train/pb_nll â–‡â–‡â–…â–…â–‚â–„â–‡â–†â–‡â–†â–ƒâ–„â–†â–„â–ˆâ–†â–ˆâ–…â–…â–‚â–…â–†â–„â–†â–†â–†â–‚â–ƒâ–†â–„â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–
wandb:                train/pos_f1 â–ˆâ–ƒâ–…â–…â–…â–„â–„â–ƒâ–…â–…â–ƒâ–…â–‚â–„â–…â–…â–ƒâ–„â–…â–…â–ƒâ–„â–„â–„â–„â–…â–†â–â–„â–„â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…
wandb:         train/pos_precision â–ˆâ–ƒâ–…â–…â–„â–…â–„â–„â–…â–„â–…â–ƒâ–…â–‚â–„â–„â–…â–ƒâ–„â–†â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–…â–†â–â–ƒâ–…â–…â–„â–ƒâ–ƒâ–„â–„â–ƒâ–…
wandb:            train/pos_recall â–ˆâ–ƒâ–„â–„â–…â–„â–„â–„â–„â–ƒâ–„â–…â–„â–ƒâ–…â–…â–„â–ƒâ–†â–„â–…â–ƒâ–ƒâ–ƒâ–„â–…â–„â–†â–â–„â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–…
wandb:                train/recall â–ƒâ–â–ƒâ–…â–„â–„â–ƒâ–„â–…â–„â–…â–„â–„â–…â–„â–…â–„â–…â–ƒâ–ˆâ–ƒâ–ƒâ–„â–…â–„â–„â–ˆâ–„â–„â–…â–„â–†â–…â–„â–„â–ƒâ–ƒâ–…â–„â–„
wandb:   train/reward_connectivity â–ƒâ–â–ƒâ–‚â–„â–…â–„â–ƒâ–„â–ƒâ–„â–…â–…â–„â–„â–…â–„â–…â–…â–ƒâ–„â–…â–ƒâ–ƒâ–„â–„â–„â–ˆâ–„â–„â–†â–„â–„â–†â–…â–ƒâ–ƒâ–†â–…â–„
wandb:      train/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/rollout_reward â–â–‚â–„â–‚â–„â–…â–ƒâ–†â–‚â–„â–†â–…â–…â–„â–„â–ƒâ–…â–†â–…â–…â–ˆâ–†â–„â–ƒâ–ƒâ–…â–„â–…â–…â–„â–†â–„â–…â–†â–ƒâ–„â–ƒâ–…â–†â–…
wandb: train/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train/struct_phi_answer_div â–„â–â–‚â–„â–‚â–„â–…â–ƒâ–ƒâ–†â–„â–„â–†â–…â–…â–…â–ƒâ–…â–…â–…â–ˆâ–„â–†â–„â–ƒâ–…â–…â–…â–‡â–…â–†â–„â–…â–†â–ƒâ–ƒâ–„â–†â–†â–…
wandb:         train/struct_phi_gt â–ˆâ–„â–…â–„â–…â–…â–ƒâ–…â–…â–…â–ƒâ–…â–‚â–„â–…â–…â–ƒâ–†â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–„â–†â–â–„â–…â–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–…
wandb:        train/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/success_mean â–„â–â–‚â–„â–‚â–ƒâ–ƒâ–†â–‚â–„â–…â–…â–„â–„â–…â–†â–…â–…â–„â–ˆâ–„â–ƒâ–ƒâ–…â–…â–‡â–…â–„â–„â–†â–…â–†â–ƒâ–„â–…â–„â–…â–†â–„â–…
wandb:               train/tb_loss â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–â–â–
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         val/answer_coverage â–‚â–â–…â–†â–‡â–‡â–†â–‡â–†â–†â–†â–ˆâ–†â–…â–…â–…â–†â–†â–†â–…â–…â–†â–†â–†â–…â–†â–†â–†â–†â–†â–…â–…â–†â–†â–†â–ˆâ–†â–ˆâ–‡â–‡
wandb:               val/answer_f1 â–‚â–â–…â–‡â–‡â–†â–†â–†â–†â–‡â–†â–†â–…â–…â–†â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–…â–…â–…â–†â–†â–†â–†â–†â–ˆâ–‡â–ˆâ–‡
wandb:       val/answer_hit_any@10 â–…â–â–…â–…â–…â–…â–…â–â–…â–…â–…â–…â–â–…â–â–â–…â–ˆâ–ˆâ–â–â–ˆâ–â–ˆâ–ˆâ–â–…â–ˆâ–…â–â–â–â–â–…â–…â–ˆâ–â–…â–…â–…
wandb:       val/answer_hit_any@20 â–…â–â–…â–…â–…â–ˆâ–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–ˆâ–…â–ˆâ–â–ˆâ–…â–ˆâ–…â–ˆâ–ˆâ–…â–ˆâ–â–â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–…
wandb:        val/answer_precision â–â–…â–†â–‡â–ˆâ–†â–…â–†â–†â–‡â–†â–†â–†â–†â–…â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–‡â–ˆâ–†â–‡â–ˆ
wandb:           val/answer_recall â–‚â–â–…â–‡â–ˆâ–‡â–‡â–‡â–†â–†â–ˆâ–…â–†â–…â–…â–†â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–†â–†â–†â–†â–‡â–ˆâ–†â–‡â–‡
wandb:  val/answer_recall_union@10 â–‚â–â–„â–…â–ƒâ–ƒâ–ˆâ–…â–†â–†â–…â–…â–â–‡â–â–„â–…â–†â–…â–…â–…â–‡â–ˆâ–†â–„â–‡â–‚â–†â–‡â–†â–†â–†â–‡â–…â–†â–†â–†â–‡â–ˆâ–ˆ
wandb:  val/answer_recall_union@20 â–‚â–â–ƒâ–‚â–„â–…â–„â–ƒâ–†â–…â–†â–…â–„â–‚â–‡â–…â–†â–â–…â–‡â–ˆâ–…â–‡â–‡â–‡â–‡â–…â–†â–‡â–„â–ˆâ–†â–‡â–†â–†â–†â–…â–†â–„â–ˆ
wandb:        val/avg_step_entropy â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–„â–ƒâ–…â–„â–„â–ƒâ–„â–„â–ƒâ–„â–„â–ˆâ–„â–„â–„â–ƒâ–ƒâ–„â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb:     val/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/gt_path_full_hit â–…â–…â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–†â–…â–„â–†â–‡â–ƒâ–†â–„â–…â–â–†â–„â–†â–†â–„â–„â–†â–…â–…â–…â–†â–†â–…â–…â–†â–†â–„â–„â–†â–†â–†
wandb:             val/length_mean â–â–â–â–‚â–‚â–„â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–â–‚
wandb:              val/log_reward â–â–â–†â–‡â–ˆâ–‡â–†â–†â–†â–‡â–‡â–†â–†â–‡â–†â–…â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–‡â–ˆâ–†â–ˆâ–‡â–‡
wandb:       val/log_reward_struct â–â–â–‡â–ˆâ–ˆâ–‡â–†â–†â–†â–‡â–‡â–†â–†â–…â–†â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡â–†â–‡â–†â–†â–‡â–ˆâ–†â–‡â–‡
wandb:         val/logpf_logr_corr â–â–„â–„â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–‡â–ˆ
wandb:     val/logpf_logr_spearman â–â–„â–„â–„â–…â–ˆâ–‡â–†â–…â–†â–†â–…â–†â–„â–‡â–…â–…â–‚â–„â–„â–‡â–…â–‡â–†â–‡â–…â–†â–…â–‡â–„â–†â–…â–†â–…â–„â–…â–…â–…â–ƒâ–‡
wandb:             val/modes_found â–â–â–‚â–„â–„â–ƒâ–‚â–„â–…â–„â–†â–„â–ƒâ–‚â–…â–ƒâ–†â–‚â–…â–…â–…â–‡â–…â–†â–†â–†â–„â–…â–„â–†â–†â–†â–†â–†â–†â–…â–…â–…â–„â–ˆ
wandb:            val/modes_recall â–‚â–â–ƒâ–‚â–„â–ƒâ–„â–†â–…â–†â–†â–…â–†â–‡â–…â–‡â–†â–â–…â–…â–ˆâ–…â–‡â–‡â–†â–…â–†â–‡â–‡â–ˆâ–‡â–†â–†â–‡â–†â–†â–„â–ˆâ–ˆâ–ˆ
wandb:             val/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       val/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         val/path_hit_any@10 â–‚â–‚â–„â–„â–„â–„â–ƒâ–…â–†â–‡â–„â–„â–„â–„â–â–ƒâ–‡â–„â–…â–†â–ƒâ–…â–‚â–„â–ˆâ–ƒâ–…â–‡â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–…â–„â–„â–„
wandb:         val/path_hit_any@20 â–„â–„â–†â–…â–„â–…â–†â–„â–…â–…â–…â–†â–†â–…â–‚â–„â–…â–‡â–†â–â–†â–…â–‚â–…â–…â–‡â–…â–†â–ˆâ–…â–†â–†â–„â–…â–„â–†â–…â–…â–…â–‡
wandb:             val/path_hit_f1 â–…â–…â–ˆâ–‡â–†â–†â–‡â–†â–†â–†â–…â–„â–†â–ƒâ–†â–…â–â–†â–†â–„â–„â–„â–†â–†â–…â–…â–†â–…â–ƒâ–†â–…â–…â–†â–†â–†â–„â–„â–†â–†â–„
wandb:           val/path_hit_f1@1 â–…â–…â–ˆâ–‡â–‡â–‡â–†â–†â–‡â–†â–†â–†â–…â–„â–†â–ƒâ–†â–„â–â–†â–†â–„â–†â–†â–…â–…â–†â–…â–ƒâ–†â–…â–…â–†â–†â–†â–„â–†â–†â–‡â–†
wandb:          val/path_hit_f1@10 â–„â–„â–ˆâ–‡â–†â–…â–†â–…â–†â–†â–†â–„â–ƒâ–…â–‡â–â–…â–ƒâ–…â–„â–…â–ƒâ–‚â–†â–…â–…â–ƒâ–†â–„â–…â–„â–†â–…â–…â–†â–ƒâ–†â–…â–‡â–†
wandb:          val/path_hit_f1@20 â–…â–…â–ˆâ–‡â–‡â–†â–†â–‡â–†â–†â–„â–†â–‡â–ƒâ–ƒâ–„â–†â–…â–â–†â–„â–†â–„â–„â–†â–…â–…â–†â–…â–ƒâ–†â–…â–…â–†â–‡â–†â–†â–„â–‡â–†
wandb:           val/path_hit_f1@5 â–…â–ˆâ–‡â–‡â–…â–‡â–†â–†â–†â–†â–„â–†â–‡â–ƒâ–†â–†â–…â–â–†â–„â–†â–„â–„â–†â–†â–…â–†â–…â–†â–†â–…â–†â–†â–†â–‡â–„â–†â–„â–‡â–†
wandb:      val/path_hit_precision â–…â–…â–ˆâ–‡â–‡â–†â–…â–†â–‡â–†â–…â–„â–†â–‡â–ƒâ–†â–„â–†â–…â–â–†â–„â–†â–†â–„â–†â–†â–„â–…â–…â–…â–…â–†â–…â–†â–„â–†â–†â–‡â–†
wandb:    val/path_hit_precision@1 â–…â–…â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–†â–†â–…â–„â–†â–‡â–ƒâ–†â–…â–â–†â–†â–†â–„â–„â–†â–…â–…â–†â–…â–ƒâ–†â–…â–†â–†â–†â–„â–†â–†â–‡â–†
wandb:   val/path_hit_precision@10 â–…â–…â–ˆâ–‡â–†â–…â–‡â–†â–†â–†â–…â–„â–†â–ƒâ–ƒâ–„â–†â–…â–â–†â–„â–†â–†â–„â–„â–†â–„â–†â–…â–ƒâ–†â–…â–…â–…â–†â–„â–„â–†â–†â–†
wandb:   val/path_hit_precision@20 â–…â–†â–ˆâ–‡â–ˆâ–‡â–†â–‡â–†â–‡â–‡â–…â–‡â–ˆâ–ƒâ–‡â–…â–†â–†â–â–…â–†â–‡â–„â–…â–‡â–†â–…â–‡â–…â–†â–…â–†â–†â–ˆâ–…â–‡â–‡â–…â–‡
wandb:    val/path_hit_precision@5 â–…â–†â–‡â–ˆâ–†â–‡â–ˆâ–†â–‡â–‡â–†â–…â–‡â–ˆâ–ƒâ–‡â–†â–â–‡â–‡â–†â–‡â–‡â–†â–…â–…â–ƒâ–†â–‡â–†â–‡â–†â–†â–ˆâ–…â–‡â–‡â–…â–ˆâ–‡
wandb:         val/path_hit_recall â–…â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–…â–‡â–ˆâ–ƒâ–ƒâ–…â–†â–†â–â–‡â–†â–‡â–…â–‡â–…â–‡â–…â–„â–†â–‡â–…â–‡â–†â–†â–ˆâ–…â–‡â–…â–ˆâ–‡
wandb:       val/path_hit_recall@1 â–†â–ˆâ–‡â–ˆâ–†â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–ˆâ–‡â–…â–†â–â–†â–‡â–†â–„â–…â–‡â–‡â–…â–…â–‡â–…â–„â–†â–†â–…â–‡â–†â–†â–…â–‡â–…â–ˆâ–‡
wandb:      val/path_hit_recall@10 â–…â–…â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–„â–†â–‡â–ƒâ–„â–†â–…â–â–†â–„â–†â–„â–†â–…â–…â–†â–…â–†â–…â–†â–†â–†â–‡â–†â–†â–„â–‡â–†
wandb:      val/path_hit_recall@20 â–…â–ˆâ–‡â–‡â–‡â–‡â–†â–†â–‡â–†â–†â–…â–„â–†â–‡â–ƒâ–†â–„â–â–†â–„â–†â–†â–„â–„â–†â–…â–…â–…â–ƒâ–…â–…â–†â–†â–†â–„â–†â–†â–„â–†
wandb:       val/path_hit_recall@5 â–„â–ˆâ–‡â–†â–†â–†â–…â–†â–†â–…â–†â–…â–„â–ƒâ–…â–â–â–…â–ƒâ–…â–…â–†â–…â–†â–ƒâ–…â–ƒâ–ƒâ–†â–‚â–…â–…â–„â–†â–…â–†â–ƒâ–ƒâ–ƒâ–†
wandb:                  val/pb_nll â–ƒâ–ˆâ–‚â–‚â–‚â–ƒâ–…â–„â–…â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–ƒâ–„â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–ƒâ–â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb:                  val/pos_f1 â–…â–†â–ˆâ–‡â–†â–†â–‡â–ˆâ–‡â–‡â–†â–…â–ˆâ–ƒâ–ƒâ–…â–†â–†â–â–†â–…â–†â–‡â–„â–‡â–…â–†â–…â–‡â–…â–†â–…â–†â–ˆâ–…â–‡â–‡â–…â–ˆâ–‡
wandb:           val/pos_precision â–…â–…â–ˆâ–‡â–‡â–†â–†â–…â–†â–‡â–†â–†â–†â–…â–„â–‡â–ƒâ–ƒâ–„â–†â–â–†â–„â–†â–†â–…â–…â–†â–ƒâ–†â–…â–…â–†â–…â–†â–„â–†â–†â–„â–†
wandb:              val/pos_recall â–„â–„â–ˆâ–‡â–†â–…â–†â–†â–†â–…â–…â–„â–ƒâ–…â–‡â–â–…â–ƒâ–…â–„â–…â–†â–ƒâ–…â–†â–†â–…â–ƒâ–…â–„â–…â–…â–„â–…â–…â–ƒâ–ƒâ–†â–…â–†
wandb:                  val/recall â–‚â–â–†â–‡â–‡â–†â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–†â–†â–†â–†â–†â–…â–†â–†â–†â–†â–†â–†â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–†â–‡â–ˆâ–‡
wandb:     val/reward_connectivity â–‚â–â–…â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–†â–ˆâ–†â–…â–†â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–†â–†â–‡â–ˆâ–†â–‡â–‡
wandb:        val/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/rollout_reward â–â–â–…â–†â–‡â–‡â–‡â–†â–†â–†â–ˆâ–†â–†â–†â–‡â–†â–†â–…â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–‡â–†â–‡â–†â–†â–†â–‡â–ˆâ–ˆâ–‡â–‡
wandb:   val/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val/struct_phi_answer_div â–â–â–…â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–†â–…â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–‡â–‡â–†â–†â–†â–‡â–†â–‡â–‡â–ˆâ–‡
wandb:           val/struct_phi_gt â–…â–…â–ˆâ–‡â–‡â–†â–…â–†â–‡â–†â–†â–†â–…â–„â–†â–ƒâ–ƒâ–†â–„â–†â–â–†â–„â–†â–„â–†â–…â–…â–…â–†â–ƒâ–…â–…â–†â–‡â–„â–†â–„â–‡â–†
wandb:          val/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val/success@10 â–…â–…â–…â–…â–ˆâ–…â–â–…â–ˆâ–…â–â–…â–…â–â–…â–…â–…â–…â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–…â–ˆâ–…â–â–â–â–â–â–…â–…â–…â–â–…â–…â–…â–…
wandb:              val/success@20 â–…â–â–…â–…â–…â–ˆâ–…â–â–…â–ˆâ–…â–ˆâ–…â–…â–…â–…â–…â–…â–ˆâ–…â–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–ˆâ–…â–…â–ˆâ–…â–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…
wandb:            val/success_mean â–â–â–…â–†â–‡â–ˆâ–‡â–‡â–†â–†â–‡â–†â–†â–†â–‡â–†â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–‡â–†â–‡â–†â–‡â–ˆâ–†â–‡â–‡â–ˆ
wandb:                 val/tb_loss â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:            val/unique_paths â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–‡â–…â–…â–„â–‡â–…â–†â–†â–†â–†â–…â–†â–ˆâ–ˆâ–†â–†â–†â–†â–†â–†â–†â–†â–‡â–†â–‡â–…â–…â–„â–ˆ
wandb: 
wandb: Run summary:
wandb:                       epoch 57
wandb:        test/answer_coverage 0.56575
wandb:              test/answer_f1 0.44671
wandb:      test/answer_hit_any@10 0.9425
wandb:      test/answer_hit_any@20 0.94519
wandb:       test/answer_precision 0.46165
wandb:          test/answer_recall 0.56575
wandb: test/answer_recall_union@10 0.74843
wandb: test/answer_recall_union@20 0.78607
wandb:       test/avg_step_entropy 1.17395
wandb:    test/fallback_to_system1 0
wandb:         test/gt_path_exists 1
wandb:       test/gt_path_full_hit 0.53783
wandb:            test/length_mean 1.00436
wandb:             test/log_reward -0.5232
wandb:      test/log_reward_struct 1.77938
wandb:        test/logpf_logr_corr 0.63797
wandb:    test/logpf_logr_spearman 0.17015
wandb:            test/modes_found 2.31716
wandb:           test/modes_recall 0.78607
wandb:            test/path_exists 1
wandb:      test/path_exists_ratio 1
wandb:        test/path_hit_any@10 0.77898
wandb:        test/path_hit_any@20 0.82749
wandb:            test/path_hit_f1 0.53735
wandb:          test/path_hit_f1@1 0.53765
wandb:         test/path_hit_f1@10 0.53735
wandb:         test/path_hit_f1@20 0.53735
wandb:          test/path_hit_f1@5 0.53735
wandb:     test/path_hit_precision 0.53712
wandb:   test/path_hit_precision@1 0.53765
wandb:  test/path_hit_precision@10 0.53712
wandb:  test/path_hit_precision@20 0.53712
wandb:   test/path_hit_precision@5 0.53712
wandb:        test/path_hit_recall 0.53783
wandb:      test/path_hit_recall@1 0.53765
wandb:     test/path_hit_recall@10 0.53783
wandb:     test/path_hit_recall@20 0.53783
wandb:      test/path_hit_recall@5 0.53783
wandb:                 test/pb_nll 0.37362
wandb:                 test/pos_f1 0.53735
wandb:          test/pos_precision 0.53712
wandb:             test/pos_recall 0.53783
wandb:                 test/recall 0.56575
wandb:    test/reward_connectivity 0.56575
wandb:       test/reward_path_term 1
wandb:         test/rollout_reward 0.92433
wandb:  test/semantic_only_success 0
wandb:         test/semantic_score 1
wandb:  test/struct_phi_answer_div 0.92439
wandb:          test/struct_phi_gt 0.53735
wandb:         test/struct_phi_len 0
wandb:       test/struct_phi_score 0
wandb:             test/success@10 0.9425
wandb:             test/success@20 0.94519
wandb:           test/success_mean 0.92426
wandb:                test/tb_loss 2.42944
wandb:           test/unique_paths 3.2947
wandb:       train/answer_coverage 0.55215
wandb:             train/answer_f1 0.42859
wandb:      train/answer_precision 0.43358
wandb:         train/answer_recall 0.55215
wandb:      train/avg_step_entropy 1.78759
wandb:   train/fallback_to_system1 0
wandb:             train/gt_log_pf -0.40213
wandb:               train/gt_loss 0.20148
wandb:        train/gt_path_exists 1
wandb:      train/gt_path_full_hit 0.68967
wandb:           train/length_mean 1.01125
wandb:            train/log_reward -0.90055
wandb:     train/log_reward_struct 1.40203
wandb:                  train/loss 2.04644
wandb:           train/path_exists 1
wandb:     train/path_exists_ratio 1
wandb:           train/path_hit_f1 0.68857
wandb:    train/path_hit_precision 0.68805
wandb:       train/path_hit_recall 0.68967
wandb:                train/pb_nll 0.45269
wandb:                train/pos_f1 0.68857
wandb:         train/pos_precision 0.68805
wandb:            train/pos_recall 0.68967
wandb:                train/recall 0.55215
wandb:   train/reward_connectivity 0.55215
wandb:      train/reward_path_term 1
wandb:        train/rollout_reward 0.86976
wandb: train/semantic_only_success 0
wandb:        train/semantic_score 1
wandb: train/struct_phi_answer_div 0.86963
wandb:         train/struct_phi_gt 0.68857
wandb:        train/struct_phi_len 0
wandb:      train/struct_phi_score 0
wandb:          train/success_mean 0.86963
wandb:               train/tb_loss 1.5508
wandb:         trainer/global_step 1767
wandb:         val/answer_coverage 0.54415
wandb:               val/answer_f1 0.43576
wandb:       val/answer_hit_any@10 0.92941
wandb:       val/answer_hit_any@20 0.92941
wandb:        val/answer_precision 0.45863
wandb:           val/answer_recall 0.54415
wandb:  val/answer_recall_union@10 0.75757
wandb:  val/answer_recall_union@20 0.79819
wandb:        val/avg_step_entropy 1.43778
wandb:     val/fallback_to_system1 0
wandb:          val/gt_path_exists 1
wandb:        val/gt_path_full_hit 0.53265
wandb:             val/length_mean 1.00294
wandb:              val/log_reward -0.56481
wandb:       val/log_reward_struct 1.73777
wandb:         val/logpf_logr_corr 0.73463
wandb:     val/logpf_logr_spearman 0.20583
wandb:             val/modes_found 2.5
wandb:            val/modes_recall 0.79819
wandb:             val/path_exists 1
wandb:       val/path_exists_ratio 1
wandb:         val/path_hit_any@10 0.79412
wandb:         val/path_hit_any@20 0.85882
wandb:             val/path_hit_f1 0.53216
wandb:           val/path_hit_f1@1 0.53265
wandb:          val/path_hit_f1@10 0.53216
wandb:          val/path_hit_f1@20 0.53216
wandb:           val/path_hit_f1@5 0.53216
wandb:      val/path_hit_precision 0.53191
wandb:    val/path_hit_precision@1 0.53265
wandb:   val/path_hit_precision@10 0.53191
wandb:   val/path_hit_precision@20 0.53191
wandb:    val/path_hit_precision@5 0.53191
wandb:         val/path_hit_recall 0.53265
wandb:       val/path_hit_recall@1 0.53265
wandb:      val/path_hit_recall@10 0.53265
wandb:      val/path_hit_recall@20 0.53265
wandb:       val/path_hit_recall@5 0.53265
wandb:                  val/pb_nll 0.30778
wandb:                  val/pos_f1 0.53216
wandb:           val/pos_precision 0.53191
wandb:              val/pos_recall 0.53265
wandb:                  val/recall 0.54415
wandb:     val/reward_connectivity 0.54415
wandb:        val/reward_path_term 1
wandb:          val/rollout_reward 0.91832
wandb:   val/semantic_only_success 0
wandb:          val/semantic_score 1
wandb:   val/struct_phi_answer_div 0.91824
wandb:           val/struct_phi_gt 0.53216
wandb:          val/struct_phi_len 0
wandb:        val/struct_phi_score 0
wandb:              val/success@10 0.92941
wandb:              val/success@20 0.92941
wandb:            val/success_mean 0.91824
wandb:                 val/tb_loss 2.67239
wandb:            val/unique_paths 3.42353
wandb: 
wandb: ğŸš€ View run train_gflownet_webqsp at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/9piqs307
wandb: â­ï¸ View project at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/train_gflownet_webqsp/runs/2025-12-05_14-32-36/wandb/run-20251205_143238-9piqs307/logs
[[36m2025-12-05 15:02:28,694[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Retrieved metric value! <val/rollout_reward=0.9183170199394226>[0m
