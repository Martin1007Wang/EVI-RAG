==> Running train_gflownet_prior_alpha0, logging to logs/prior_ablation/train_gflownet_prior_alpha0_20251204_113111.log
[[36m2025-12-04 11:31:15,576[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-12-04 11:31:15,578[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] torch.set_float32_matmul_precision(high)[0m
[[36m2025-12-04 11:31:15,579[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.g_agent_datamodule.GAgentDataModule                  
â”‚       cache_paths:                                                            
â”‚         train: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g
â”‚         validation: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/va
â”‚         test: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_a
â”‚       batch_size: 64                                                          
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       drop_last: false                                                        
â”‚       persistent_workers: true                                                
â”‚       shuffle_train: true                                                     
â”‚       resources:                                                              
â”‚         vocabulary_path: /mnt/data/retrieval_dataset/webqsp/materialized/vocab
â”‚         embeddings_dir: /mnt/data/retrieval_dataset/webqsp/materialized/embedd
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.gflownet_module.GFlowNetModule                     
â”‚       _recursive_: false                                                      
â”‚       hidden_dim: 1024                                                        
â”‚       training_cfg:                                                           
â”‚         normalize_log_reward: true                                            
â”‚         gt_replay_ratio: 0.3                                                  
â”‚         learn_pb: true                                                        
â”‚         debug_batches_to_log: 1                                               
â”‚         debug_graphs_to_log: 2                                                
â”‚         retriever_prior_alpha: 0.0                                            
â”‚         retriever_prior_anneal: null                                          
â”‚         pb_loss_weight: 1.0                                                   
â”‚         pb_loss_anneal:                                                       
â”‚           start: 1.0                                                          
â”‚           end: 0.0                                                            
â”‚           steps: 5000                                                         
â”‚         gt_loss_weight: 0.15                                                  
â”‚       evaluation_cfg:                                                         
â”‚         num_eval_rollouts:                                                    
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚         path_hit_k:                                                           
â”‚         - 1                                                                   
â”‚         - 5                                                                   
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚       optimizer_cfg:                                                          
â”‚         type: adamw                                                           
â”‚         lr: 0.0001                                                            
â”‚         weight_decay: 0.0001                                                  
â”‚         param_groups:                                                         
â”‚         - params:                                                             
â”‚           - estimator.log_z_head                                              
â”‚           - estimator.log_z_condition                                         
â”‚           lr: 0.001                                                           
â”‚       scheduler_cfg:                                                          
â”‚         type: cosine                                                          
â”‚         t_max: 200                                                            
â”‚         eta_min: 1.0e-06                                                      
â”‚         interval: epoch                                                       
â”‚         monitor: val/reward                                                   
â”‚       logging_cfg:                                                            
â”‚         train_prog_bar:                                                       
â”‚         - rollout_reward                                                      
â”‚         - success_mean                                                        
â”‚         - answer_coverage                                                     
â”‚         - length_mean                                                         
â”‚         eval_prog_bar:                                                        
â”‚         - success_mean                                                        
â”‚         - answer_f1                                                           
â”‚         auto_add_success_at_k: true                                           
â”‚         auto_add_path_hit_f1: true                                            
â”‚         log_on_step_train: false                                              
â”‚       env_cfg:                                                                
â”‚         _target_: src.models.components.gflownet_env.GraphEnv                 
â”‚         mode: subgraph                                                        
â”‚         max_steps: 6                                                          
â”‚         forbid_backtrack: true                                                
â”‚         forbid_revisit: true                                                  
â”‚         bidir_token: false                                                    
â”‚         debug: true                                                           
â”‚         debug_max_resets: 2                                                   
â”‚         debug_max_graphs: 2                                                   
â”‚         debug_max_hits: 4                                                     
â”‚       policy_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_policies.EdgeMLPMixerPolicy  
â”‚         hidden_dim: 1024                                                      
â”‚         dropout: 0.5                                                          
â”‚         num_layers: 2                                                         
â”‚       reward_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_rewards.AnswerOnlyReward     
â”‚         success_reward: 10.0                                                  
â”‚         failure_reward: 0.01                                                  
â”‚         lambda_reach: 0.0                                                     
â”‚         gamma_len: 0.0                                                        
â”‚         gamma_score: 0.0                                                      
â”‚         score_clip_max: 1.0                                                   
â”‚         score_eps: 1.0e-08                                                    
â”‚         gamma_gt: 0.0                                                         
â”‚         gamma_answer_div: 0.0                                                 
â”‚       actor_cfg:                                                              
â”‚         _target_: src.models.components.gflownet_actor.GFlowNetActor          
â”‚         policy_temperature: 1.0                                               
â”‚         eval_policy_temperature: 0.7                                          
â”‚         stop_logit_bias: -1.0                                                 
â”‚         random_action_prob: 0.1                                               
â”‚         debug_actions: false                                                  
â”‚         debug_actions_steps: 0                                                
â”‚       embedder_cfg:                                                           
â”‚         _target_: src.models.components.gflownet_embedder.GraphEmbedder       
â”‚         hidden_dim: 1024                                                      
â”‚         proj_dropout: 0.0                                                     
â”‚         projector_checkpoint: logs/train_retriever_webqsp/runs/2025-12-02_19-2
â”‚         freeze_projectors: true                                               
â”‚         kge_interaction: concat                                               
â”‚         projector_key_prefixes:                                               
â”‚         - retriever.model._orig_mod                                           
â”‚         - retriever.model                                                     
â”‚         - retriever                                                           
â”‚         - model._orig_mod                                                     
â”‚         - model                                                               
â”‚         - ''                                                                  
â”‚         use_gfn_projectors: true                                              
â”‚       estimator_cfg:                                                          
â”‚         _target_: src.models.components.gflownet_estimator.GFlowNetEstimator  
â”‚         hidden_dim: 1024                                                      
â”‚         log_pb_mode: learned                                                  
â”‚         learn_pb: true                                                        
â”‚         pb_entropy_coef: 0.0                                                  
â”‚         pb_l2_reg: 0.0                                                        
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/r
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/rollout_reward                                           
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 1                                                         
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/rollout_reward                                           
â”‚         min_delta: 0.0                                                        
â”‚         patience: 50                                                          
â”‚         verbose: false                                                        
â”‚         mode: max                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         name: train_gflownet_prior_alpha0                                     
â”‚         save_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: evi-rag                                                      
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         entity: null                                                          
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_a
â”‚       min_epochs: 50                                                          
â”‚       max_epochs: 200                                                         
â”‚       accelerator: gpu                                                        
â”‚       devices: 1                                                              
â”‚       gradient_clip_val: 1.0                                                  
â”‚       check_val_every_n_epoch: 1                                              
â”‚       log_every_n_steps: 1                                                    
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚       data_dir: /mnt/data/retrieval_dataset                                   
â”‚       log_dir: /mnt/wangjingxiong/EVI-RAG/logs/                               
â”‚       debug_log_path: /mnt/wangjingxiong/EVI-RAG/logs//debug.log              
â”‚       output_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/
â”‚       work_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚       torch_float32_matmul_precision: high                                    
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train_gflownet_prior_alpha0                                             
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['ablation', 'prior=0']                                                 
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ debug_data_loading
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ test_ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ allow_test_without_checkpoint
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 42                                                                      
â”œâ”€â”€ dataset
â”‚   â””â”€â”€ name: webqsp                                                            
â”‚       kb: freebase                                                            
â”‚       raw_root: /mnt/data/retrieval_dataset/webqsp/raw/data                   
â”‚       out_dir: /mnt/data/retrieval_dataset/webqsp/normalized                  
â”‚       materialized_dir: /mnt/data/retrieval_dataset/webqsp/materialized       
â”‚       paths:                                                                  
â”‚         vocabulary: /mnt/data/retrieval_dataset/webqsp/materialized/vocabulary
â”‚         embeddings: /mnt/data/retrieval_dataset/webqsp/materialized/embeddings
â”‚         processed: /mnt/data/retrieval_dataset/webqsp/materialized/processed  
â”‚       entity_normalization: none                                              
â”‚       undirected_traversal: false                                             
â”‚       hard_negative_k: 4                                                      
â”‚       hard_negative_similarity: cosine                                        
â”‚       column_map:                                                             
â”‚         question_id_field: id                                                 
â”‚         question_field: question                                              
â”‚         answer_text_field: answer                                             
â”‚         q_entity_field: q_entity                                              
â”‚         a_entity_field: a_entity                                              
â”‚         graph_field: graph                                                    
â”‚                                                                               
â”œâ”€â”€ optimized_metric
â”‚   â””â”€â”€ val/rollout_reward                                                      
â”œâ”€â”€ gflownet_debug
â”‚   â””â”€â”€ True                                                                    
â””â”€â”€ env_debug
    â””â”€â”€ True                                                                    
Seed set to 42
[[36m2025-12-04 11:31:15,624[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resolved run name: train_gflownet_prior_alpha0[0m
[[36m2025-12-04 11:31:15,624[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.g_agent_datamodule.GAgentDataModule>[0m
[[36m2025-12-04 11:31:15,951[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.gflownet_module.GFlowNetModule>[0m
[[36m2025-12-04 11:31:16,171[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-12-04 11:31:16,171[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-12-04 11:31:16,173[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-12-04 11:31:16,173[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-12-04 11:31:16,173[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-12-04 11:31:16,174[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-12-04 11:31:16,174[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-12-04 11:31:16,176[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
[[36m2025-12-04 11:31:16,213[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: martin1007wang (martin1007wang-wuhan-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/runs/2025-12-04_11-31-15/wandb/run-20251204_113117-ywwzloz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train_gflownet_prior_alpha0
wandb: â­ï¸ View project at https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: ğŸš€ View run at https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/ywwzloz6
[[36m2025-12-04 11:31:18,966[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-12-04 11:31:20,127[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g_agent.pt: 1956 samples.[0m
[[36m2025-12-04 11:31:20,196[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/validation_g_agent.pt: 170 samples.[0m
[[36m2025-12-04 11:31:20,512[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/entity_embeddings.pt...[0m
[[36m2025-12-04 11:31:21,292[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/relation_embeddings.pt...[0m
[[36m2025-12-04 11:31:21,299[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Entity embedding rows: 524643 (vocab entities: 1281202). Non-text entities use embedding_id=0; textual entities occupy 1..max_id.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                                            â”ƒ Type  â”ƒ Paraâ€¦ â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ policy                                          â”‚ Edgeâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 1  â”‚ policy.type_embeddings                          â”‚ Embeâ€¦ â”‚ 5.1 K â”‚ train â”‚
â”‚ 2  â”‚ policy.graph_norm                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 3  â”‚ policy.q_film                                   â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 4  â”‚ policy.q_film.0                                 â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 5  â”‚ policy.q_film.1                                 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 6  â”‚ policy.q_film.2                                 â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 7  â”‚ policy.edge_mlp                                 â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 8  â”‚ policy.edge_mlp.0                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 9  â”‚ policy.edge_mlp.1                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 10 â”‚ policy.edge_mlp.2                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 11 â”‚ policy.edge_mlp.3                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 12 â”‚ policy.edge_mlp.4                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 13 â”‚ policy.edge_mlp.5                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 14 â”‚ policy.edge_mlp.6                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 15 â”‚ policy.edge_mlp.7                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 16 â”‚ policy.lookahead_head                           â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 17 â”‚ policy.lookahead_head.0                         â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 18 â”‚ policy.lookahead_head.1                         â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 19 â”‚ policy.lookahead_head.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 20 â”‚ policy.lookahead_head.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 21 â”‚ policy.lookahead_head.4                         â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 22 â”‚ policy.stop_proj                                â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 23 â”‚ policy.stop_proj.0                              â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 24 â”‚ policy.stop_proj.1                              â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 25 â”‚ policy.stop_proj.2                              â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 26 â”‚ policy.stop_proj.3                              â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 27 â”‚ reward_fn                                       â”‚ Answâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 28 â”‚ env                                             â”‚ Grapâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 29 â”‚ embedder                                        â”‚ Grapâ€¦ â”‚  12.6 â”‚ train â”‚
â”‚    â”‚                                                 â”‚       â”‚     M â”‚       â”‚
â”‚ 30 â”‚ embedder.entity_projector                       â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 31 â”‚ embedder.entity_projector.0                     â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 32 â”‚ embedder.entity_projector.1                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 33 â”‚ embedder.entity_projector.2                     â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 34 â”‚ embedder.entity_projector.3                     â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 35 â”‚ embedder.entity_projector.4                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 36 â”‚ embedder.relation_projector                     â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 37 â”‚ embedder.relation_projector.0                   â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 38 â”‚ embedder.relation_projector.1                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 39 â”‚ embedder.relation_projector.2                   â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 40 â”‚ embedder.relation_projector.3                   â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 41 â”‚ embedder.relation_projector.4                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 42 â”‚ embedder.edge_adapter                           â”‚ Sequâ€¦ â”‚ 5.3 M â”‚ train â”‚
â”‚ 43 â”‚ embedder.edge_adapter.0                         â”‚ Layeâ€¦ â”‚ 8.2 K â”‚ train â”‚
â”‚ 44 â”‚ embedder.edge_adapter.1                         â”‚ Lineâ€¦ â”‚ 4.2 M â”‚ train â”‚
â”‚ 45 â”‚ embedder.edge_adapter.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 46 â”‚ embedder.edge_adapter.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 47 â”‚ embedder.edge_adapter.4                         â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 48 â”‚ embedder.retriever_entity_projector             â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 49 â”‚ embedder.retriever_entity_projector.network     â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 50 â”‚ embedder.retriever_entity_projector.network.0   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 51 â”‚ embedder.retriever_entity_projector.network.1   â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 52 â”‚ embedder.retriever_relation_projector           â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 53 â”‚ embedder.retriever_relation_projector.network   â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 54 â”‚ embedder.retriever_relation_projector.network.0 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 55 â”‚ embedder.retriever_relation_projector.network.1 â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 56 â”‚ embedder.retriever_query_projector              â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 57 â”‚ embedder.retriever_query_projector.network      â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 58 â”‚ embedder.retriever_query_projector.network.0    â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 59 â”‚ embedder.retriever_query_projector.network.1    â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 60 â”‚ estimator                                       â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 61 â”‚ estimator.log_z_head                            â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 62 â”‚ estimator.log_z_head.0                          â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 63 â”‚ estimator.log_z_head.1                          â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 64 â”‚ estimator.log_z_head.2                          â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 65 â”‚ estimator.log_z_head.3                          â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 66 â”‚ estimator.ctx_projector                         â”‚ Sequâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 67 â”‚ estimator.ctx_projector.0                       â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 68 â”‚ estimator.ctx_projector.1                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 69 â”‚ estimator.ctx_projector.2                       â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 70 â”‚ estimator.backward_head                         â”‚ Sequâ€¦ â”‚ 3.2 M â”‚ train â”‚
â”‚ 71 â”‚ estimator.backward_head.0                       â”‚ Layeâ€¦ â”‚ 6.1 K â”‚ train â”‚
â”‚ 72 â”‚ estimator.backward_head.1                       â”‚ Lineâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 73 â”‚ estimator.backward_head.2                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 74 â”‚ estimator.backward_head.3                       â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 75 â”‚ estimator.backward_head.4                       â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 76 â”‚ actor                                           â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 24.2 M                                                        
Non-trainable params: 3.1 M                                                     
Total params: 27.3 M                                                            
Total estimated model params size (MB): 109                                     
Modules in train mode: 65                                                       
Modules in eval mode: 12                                                        
/anaconda3/envs/pog/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 12 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
`Trainer.fit` stopped: `max_epochs=200` reached.
Epoch 199/199 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 31/31 0:00:17 â€¢        1.76it/s v_num: loz6      
                                     0:00:00                   val/answer_f1:   
                                                               0.070            
                                                               val/path_hit_f1@â€¦
                                                               0.041            
                                                               val/success_mean:
                                                               0.356            
                                                               val/success@20:  
                                                               0.765 train/loss:
                                                               46.419           
                                                               train/rollout_reâ€¦
                                                               0.483            
                                                               train/success_meâ€¦
                                                               0.482            
                                                               train/answer_covâ€¦
                                                               0.287            
                                                               train/length_meaâ€¦
                                                               5.123            
[[36m2025-12-04 13:03:54,164[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting testing![0m
[[36m2025-12-04 13:03:54,927[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_agent.pt: 1113 samples.[0m
Restoring states from the checkpoint path at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/runs/2025-12-04_11-31-15/checkpoints/epoch_159.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/runs/2025-12-04_11-31-15/checkpoints/epoch_159.ckpt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ         Test metric         â”ƒ        DataLoader 0         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚    test/answer_coverage     â”‚     0.20167000591754913     â”‚
â”‚       test/answer_f1        â”‚     0.07934903353452682     â”‚
â”‚   test/answer_hit_any@10    â”‚     0.7520215511322021      â”‚
â”‚   test/answer_hit_any@20    â”‚     0.8283917307853699      â”‚
â”‚    test/answer_precision    â”‚     0.06793885678052902     â”‚
â”‚     test/answer_recall      â”‚     0.20167000591754913     â”‚
â”‚ test/answer_recall_union@10 â”‚     0.5970429182052612      â”‚
â”‚ test/answer_recall_union@20 â”‚     0.7097596526145935      â”‚
â”‚    test/avg_step_entropy    â”‚     4.6922478675842285      â”‚
â”‚  test/fallback_to_system1   â”‚             0.0             â”‚
â”‚     test/gt_path_exists     â”‚             1.0             â”‚
â”‚    test/gt_path_full_hit    â”‚     0.1871967762708664      â”‚
â”‚      test/length_mean       â”‚      6.968778133392334      â”‚
â”‚       test/log_reward       â”‚     -4.2762298583984375     â”‚
â”‚   test/log_reward_struct    â”‚     -1.973644495010376      â”‚
â”‚    test/logpf_logr_corr     â”‚     0.3506167531013489      â”‚
â”‚  test/logpf_logr_spearman   â”‚     0.2903536260128021      â”‚
â”‚      test/modes_found       â”‚      3.193171501159668      â”‚
â”‚      test/modes_recall      â”‚     0.7097596526145935      â”‚
â”‚      test/path_exists       â”‚             1.0             â”‚
â”‚   test/path_exists_ratio    â”‚             1.0             â”‚
â”‚    test/path_hit_any@10     â”‚     0.5956873297691345      â”‚
â”‚    test/path_hit_any@20     â”‚     0.7304581999778748      â”‚
â”‚      test/path_hit_f1       â”‚     0.04854872450232506     â”‚
â”‚     test/path_hit_f1@1      â”‚    0.0015873017255216837    â”‚
â”‚     test/path_hit_f1@10     â”‚     0.04854871705174446     â”‚
â”‚     test/path_hit_f1@20     â”‚     0.04854871705174446     â”‚
â”‚     test/path_hit_f1@5      â”‚     0.05306977778673172     â”‚
â”‚   test/path_hit_precision   â”‚     0.02829333022236824     â”‚
â”‚  test/path_hit_precision@1  â”‚    0.0016621744725853205    â”‚
â”‚ test/path_hit_precision@10  â”‚     0.02829333208501339     â”‚
â”‚ test/path_hit_precision@20  â”‚     0.02829333208501339     â”‚
â”‚  test/path_hit_precision@5  â”‚     0.03231057524681091     â”‚
â”‚    test/path_hit_recall     â”‚     0.1876460164785385      â”‚
â”‚   test/path_hit_recall@1    â”‚    0.0015498653519898653    â”‚
â”‚   test/path_hit_recall@10   â”‚     0.1876460164785385      â”‚
â”‚   test/path_hit_recall@20   â”‚     0.1876460164785385      â”‚
â”‚   test/path_hit_recall@5    â”‚     0.1558849811553955      â”‚
â”‚         test/pb_nll         â”‚     1.5827268362045288      â”‚
â”‚         test/pos_f1         â”‚     0.04854872450232506     â”‚
â”‚     test/pos_precision      â”‚     0.02829333022236824     â”‚
â”‚       test/pos_recall       â”‚     0.1876460164785385      â”‚
â”‚         test/recall         â”‚     0.20167000591754913     â”‚
â”‚  test/reward_connectivity   â”‚     0.20167000591754913     â”‚
â”‚    test/reward_path_term    â”‚             1.0             â”‚
â”‚     test/rollout_reward     â”‚     0.3815714418888092      â”‚
â”‚ test/semantic_only_success  â”‚             0.0             â”‚
â”‚     test/semantic_score     â”‚             1.0             â”‚
â”‚ test/struct_phi_answer_div  â”‚     0.5375112891197205      â”‚
â”‚     test/struct_phi_gt      â”‚     0.04854872450232506     â”‚
â”‚     test/struct_phi_len     â”‚             0.0             â”‚
â”‚    test/struct_phi_score    â”‚             0.0             â”‚
â”‚       test/success@10       â”‚     0.7520215511322021      â”‚
â”‚       test/success@20       â”‚     0.8283917307853699      â”‚
â”‚      test/success_mean      â”‚     0.3809523582458496      â”‚
â”‚        test/tb_loss         â”‚     39.930259704589844      â”‚
â”‚      test/unique_paths      â”‚      19.8778076171875       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Testing â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18/18 0:01:04 â€¢ 0:00:00 0.30it/s 
[[36m2025-12-04 13:04:59,963[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Best ckpt path: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/runs/2025-12-04_11-31-15/checkpoints/epoch_159.ckpt[0m
[[36m2025-12-04 13:04:59,964[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha0/runs/2025-12-04_11-31-15[0m
[[36m2025-12-04 13:04:59,964[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:        test/answer_coverage â–
wandb:              test/answer_f1 â–
wandb:      test/answer_hit_any@10 â–
wandb:      test/answer_hit_any@20 â–
wandb:       test/answer_precision â–
wandb:          test/answer_recall â–
wandb: test/answer_recall_union@10 â–
wandb: test/answer_recall_union@20 â–
wandb:       test/avg_step_entropy â–
wandb:    test/fallback_to_system1 â–
wandb:         test/gt_path_exists â–
wandb:       test/gt_path_full_hit â–
wandb:            test/length_mean â–
wandb:             test/log_reward â–
wandb:      test/log_reward_struct â–
wandb:        test/logpf_logr_corr â–
wandb:    test/logpf_logr_spearman â–
wandb:            test/modes_found â–
wandb:           test/modes_recall â–
wandb:            test/path_exists â–
wandb:      test/path_exists_ratio â–
wandb:        test/path_hit_any@10 â–
wandb:        test/path_hit_any@20 â–
wandb:            test/path_hit_f1 â–
wandb:          test/path_hit_f1@1 â–
wandb:         test/path_hit_f1@10 â–
wandb:         test/path_hit_f1@20 â–
wandb:          test/path_hit_f1@5 â–
wandb:     test/path_hit_precision â–
wandb:   test/path_hit_precision@1 â–
wandb:  test/path_hit_precision@10 â–
wandb:  test/path_hit_precision@20 â–
wandb:   test/path_hit_precision@5 â–
wandb:        test/path_hit_recall â–
wandb:      test/path_hit_recall@1 â–
wandb:     test/path_hit_recall@10 â–
wandb:     test/path_hit_recall@20 â–
wandb:      test/path_hit_recall@5 â–
wandb:                 test/pb_nll â–
wandb:                 test/pos_f1 â–
wandb:          test/pos_precision â–
wandb:             test/pos_recall â–
wandb:                 test/recall â–
wandb:    test/reward_connectivity â–
wandb:       test/reward_path_term â–
wandb:         test/rollout_reward â–
wandb:  test/semantic_only_success â–
wandb:         test/semantic_score â–
wandb:  test/struct_phi_answer_div â–
wandb:          test/struct_phi_gt â–
wandb:         test/struct_phi_len â–
wandb:       test/struct_phi_score â–
wandb:             test/success@10 â–
wandb:             test/success@20 â–
wandb:           test/success_mean â–
wandb:                test/tb_loss â–
wandb:           test/unique_paths â–
wandb:       train/answer_coverage â–â–ƒâ–‚â–‚â–‚â–„â–„â–„â–„â–„â–…â–„â–„â–…â–†â–†â–…â–…â–„â–…â–„â–†â–†â–†â–…â–‡â–†â–‡â–‡â–†â–‡â–†â–ˆâ–ˆâ–‡â–‡â–†â–‡â–‡â–†
wandb:             train/answer_f1 â–ƒâ–ƒâ–â–‚â–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–†â–„â–„â–„â–ƒâ–…â–…â–‡â–…â–†â–„â–†â–…â–…â–…â–…â–…â–…â–†â–‡â–†â–‡â–ˆâ–‡â–†â–ˆâ–‡â–ˆ
wandb:      train/answer_precision â–‚â–…â–„â–…â–â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–…â–„â–†â–†â–„â–†â–ƒâ–ƒâ–ƒâ–…â–‡â–„â–„â–†â–†â–„â–ƒâ–…â–‡â–…â–…â–‡â–ˆâ–‡â–†â–‡â–†â–ˆ
wandb:         train/answer_recall â–ƒâ–â–â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–„â–…â–„â–…â–„â–†â–„â–…â–ƒâ–…â–…â–…â–„â–†â–…â–†â–‡â–‡â–†â–†â–…â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–†â–ˆ
wandb:      train/avg_step_entropy â–â–„â–ƒâ–„â–ƒâ–‡â–„â–„â–…â–„â–†â–‡â–…â–†â–†â–…â–„â–„â–…â–„â–„â–†â–‡â–†â–„â–†â–„â–„â–ˆâ–ƒâ–†â–†â–…â–†â–†â–‡â–„â–†â–†â–…
wandb:   train/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             train/gt_log_pf â–†â–…â–‡â–„â–‚â–†â–†â–„â–…â–‡â–†â–†â–ƒâ–„â–ƒâ–…â–â–„â–…â–„â–‡â–„â–‡â–…â–…â–†â–‡â–†â–†â–ˆâ–†â–„â–‡â–‚â–…â–…â–ƒâ–…â–ˆâ–ƒ
wandb:               train/gt_loss â–â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡
wandb:        train/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/gt_path_full_hit â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–ƒâ–…â–„â–ƒâ–…â–„â–…â–…â–†â–„â–‡â–…â–†â–…â–†â–„â–„â–„â–…â–†â–†â–…â–‡â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:           train/length_mean â–…â–„â–‡â–ˆâ–„â–†â–…â–‚â–ƒâ–‡â–„â–‡â–‡â–†â–…â–„â–ˆâ–„â–â–‡â–…â–ƒâ–‡â–†â–„â–‡â–…â–ƒâ–†â–†â–„â–‚â–†â–‡â–„â–†â–ƒâ–„â–„â–†
wandb:            train/log_reward â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–…â–„â–†â–…â–†â–…â–…â–†â–…â–†â–…â–…â–†â–‡â–†â–†â–‡â–†â–ˆâ–†â–†â–†â–‡â–‡â–‡â–†â–ˆâ–ˆâ–‡
wandb:     train/log_reward_struct â–‚â–â–‚â–â–‚â–„â–ƒâ–„â–ƒâ–…â–…â–†â–…â–†â–†â–†â–†â–…â–†â–…â–†â–†â–…â–…â–†â–‡â–‡â–†â–†â–‡â–†â–†â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡
wandb:                  train/loss â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           train/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           train/path_hit_f1 â–…â–…â–ƒâ–‚â–â–†â–â–‡â–ƒâ–‚â–‚â–„â–ƒâ–‚â–…â–†â–†â–‚â–„â–…â–„â–ˆâ–„â–†â–„â–†â–„â–‡â–‡â–„â–„â–ƒâ–…â–†â–„â–†â–‡â–ˆâ–ƒâ–ˆ
wandb:    train/path_hit_precision â–‚â–„â–…â–â–ƒâ–„â–â–…â–…â–ƒâ–‚â–ƒâ–‚â–†â–…â–ˆâ–‚â–ƒâ–‚â–„â–†â–‚â–…â–‚â–„â–ƒâ–„â–ƒâ–…â–‡â–ƒâ–‡â–ƒâ–„â–‚â–„â–‡â–ƒâ–ƒâ–‡
wandb:       train/path_hit_recall â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–…â–„â–ƒâ–†â–‚â–„â–…â–…â–†â–ƒâ–†â–…â–…â–†â–†â–…â–†â–…â–„â–†â–…â–„â–„â–†â–‡â–†â–†â–„â–…â–‡â–‡â–ˆâ–…â–…
wandb:                train/pb_nll â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–‚â–
wandb:                train/pos_f1 â–…â–…â–ƒâ–â–‡â–ƒâ–„â–‡â–†â–„â–‡â–…â–…â–ˆâ–‡â–†â–‡â–†â–†â–ˆâ–…â–„â–„â–†â–„â–„â–ˆâ–…â–‡â–‡â–ˆâ–‡â–ƒâ–„â–‡â–†â–ˆâ–†â–…â–…
wandb:         train/pos_precision â–ƒâ–…â–…â–†â–†â–…â–…â–‡â–â–„â–†â–„â–ƒâ–ƒâ–…â–‡â–…â–‡â–…â–â–‚â–„â–…â–ƒâ–†â–†â–†â–‡â–…â–…â–…â–‡â–ƒâ–„â–…â–ˆâ–†â–†â–„â–„
wandb:            train/pos_recall â–â–‚â–â–‚â–…â–ƒâ–„â–…â–„â–ƒâ–†â–…â–†â–…â–†â–…â–†â–…â–…â–„â–…â–„â–‡â–‡â–†â–…â–‡â–…â–†â–†â–‡â–ˆâ–‡â–‡â–†â–ˆâ–‡â–…â–†â–ˆ
wandb:                train/recall â–ƒâ–â–ƒâ–â–ƒâ–„â–„â–„â–„â–†â–…â–„â–ƒâ–†â–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–…â–‡â–†â–†â–†â–…â–‡â–‡â–‡â–ˆâ–‡â–†â–ˆâ–‡â–†â–ˆ
wandb:   train/reward_connectivity â–ƒâ–â–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–…â–…â–„â–†â–†â–ƒâ–†â–†â–„â–„â–…â–…â–†â–†â–…â–…â–‡â–†â–†â–‡â–‡â–ˆâ–†â–†â–†â–‡
wandb:      train/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/rollout_reward â–â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–†â–…â–„â–ƒâ–„â–„â–…â–…â–†â–‡â–…â–…â–…â–…â–‡â–†â–†â–†â–†â–†â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb: train/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train/struct_phi_answer_div â–‚â–â–â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–„â–„â–†â–„â–…â–…â–„â–…â–†â–…â–†â–†â–…â–‡â–†â–‡â–†â–†â–…â–…â–†â–†â–†â–‡â–†â–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:         train/struct_phi_gt â–„â–„â–…â–ƒâ–„â–…â–â–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–…â–„â–„â–â–…â–„â–…â–…â–‡â–‚â–„â–ˆâ–â–‚â–…â–‡â–†â–…â–ƒâ–ƒâ–…â–ˆâ–…â–‡â–„
wandb:        train/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/success_mean â–â–‚â–‚â–‚â–„â–ƒâ–…â–„â–…â–…â–…â–…â–„â–…â–„â–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–…â–‡â–‡â–†â–…â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–‡â–ˆ
wandb:               train/tb_loss â–ˆâ–„â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–
wandb:         trainer/global_step â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         val/answer_coverage â–â–â–â–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–…â–…â–…â–…â–„â–…â–„â–„â–†â–…â–…â–…â–†â–†â–„â–†â–†â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:               val/answer_f1 â–â–â–‚â–ƒâ–…â–„â–„â–…â–…â–…â–…â–‡â–†â–…â–†â–†â–†â–‡â–†â–…â–†â–†â–†â–†â–†â–‡â–†â–†â–†â–‡â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:       val/answer_hit_any@10 â–â–â–â–ƒâ–…â–†â–†â–†â–„â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡
wandb:       val/answer_hit_any@20 â–ƒâ–â–„â–„â–…â–…â–‡â–†â–…â–…â–‡â–†â–ˆâ–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–†â–‡â–‡â–ˆâ–‡â–†â–‡â–‡â–‡
wandb:        val/answer_precision â–â–â–ƒâ–…â–„â–…â–…â–†â–…â–‡â–…â–…â–†â–…â–†â–†â–†â–†â–„â–†â–†â–‡â–†â–†â–‡â–†â–‡â–‡â–‡â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:           val/answer_recall â–â–„â–ƒâ–…â–„â–„â–„â–…â–…â–…â–„â–…â–†â–„â–„â–…â–…â–†â–…â–†â–†â–…â–†â–†â–‡â–†â–†â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:  val/answer_recall_union@10 â–‚â–â–â–â–‚â–„â–„â–„â–…â–‡â–…â–‡â–†â–‡â–†â–…â–†â–ˆâ–ˆâ–†â–ˆâ–‡â–†â–†â–‡â–ˆâ–‡â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:  val/answer_recall_union@20 â–â–â–â–„â–†â–‡â–ˆâ–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:        val/avg_step_entropy â–…â–ˆâ–‡â–ƒâ–‡â–†â–†â–‚â–†â–†â–…â–‡â–…â–â–…â–„â–â–…â–…â–†â–„â–„â–…â–„â–…â–‡â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:     val/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/gt_path_full_hit â–‚â–â–‚â–ƒâ–‚â–„â–ƒâ–„â–„â–ƒâ–„â–…â–…â–…â–…â–…â–†â–„â–†â–…â–…â–†â–‡â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–ˆ
wandb:             val/length_mean â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val/log_reward â–‚â–â–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–…â–…â–‡â–†â–…â–†â–‡â–†â–†â–†â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb:       val/log_reward_struct â–â–â–ƒâ–ƒâ–„â–…â–…â–…â–„â–…â–„â–…â–†â–†â–…â–…â–…â–‡â–†â–„â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:         val/logpf_logr_corr â–ˆâ–†â–†â–†â–ˆâ–†â–†â–‡â–ˆâ–…â–…â–…â–‡â–‡â–…â–„â–ƒâ–‚â–†â–„â–„â–†â–„â–†â–„â–„â–†â–„â–„â–†â–ƒâ–ƒâ–ƒâ–…â–ƒâ–â–„â–‚â–â–…
wandb:     val/logpf_logr_spearman â–â–‚â–…â–†â–…â–‡â–†â–…â–†â–†â–†â–‡â–†â–†â–†â–‡â–†â–†â–†â–†â–†â–‡â–‡â–†â–‡â–ˆâ–‡â–†â–†â–ˆâ–†â–‡â–‡â–†â–†â–‡â–†â–‡â–‡â–‡
wandb:             val/modes_found â–‚â–â–â–‚â–‚â–…â–…â–…â–†â–†â–‡â–‡â–‡â–†â–†â–‡â–ˆâ–‡â–ˆâ–‡â–„â–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:            val/modes_recall â–â–â–ƒâ–ƒâ–†â–†â–‡â–†â–…â–‡â–‡â–†â–‡â–‡â–†â–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:             val/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       val/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         val/path_hit_any@10 â–‚â–â–ƒâ–ƒâ–…â–ƒâ–…â–…â–…â–†â–ˆâ–†â–†â–…â–‡â–‡â–†â–†â–‡â–‡â–†â–‡â–‡â–ˆâ–†â–‡â–†â–‡â–†â–‡â–†â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:         val/path_hit_any@20 â–â–â–„â–…â–…â–†â–…â–†â–†â–ˆâ–†â–†â–†â–‡â–†â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–‡â–†â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆ
wandb:             val/path_hit_f1 â–â–â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–…â–…â–„â–…â–„â–…â–…â–…â–†â–„â–‡â–…â–†â–†â–…â–…â–†â–†â–‡â–…â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:           val/path_hit_f1@1 â–‚â–‚â–‚â–â–â–â–„â–‚â–â–„â–â–ˆâ–„â–…â–‚â–„â–‚â–„â–â–‡â–‚â–…â–â–„â–„â–„â–…â–†â–„â–ˆâ–â–ˆâ–ˆâ–…â–„â–‚â–‚â–„â–â–‡
wandb:          val/path_hit_f1@10 â–â–â–â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–…â–„â–„â–„â–…â–„â–…â–†â–…â–†â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–…â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:          val/path_hit_f1@20 â–â–â–â–‚â–„â–„â–ƒâ–„â–„â–„â–„â–†â–…â–†â–„â–†â–„â–„â–†â–„â–…â–…â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡
wandb:           val/path_hit_f1@5 â–â–â–â–‚â–‚â–„â–„â–„â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–†â–†â–…â–…â–…â–…â–†â–…â–…â–†â–†â–†â–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–†â–ˆ
wandb:      val/path_hit_precision â–â–„â–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–…â–†â–†â–…â–…â–…â–…â–…â–†â–†â–…â–†â–†â–†â–†â–ˆâ–ˆâ–†â–‡â–‡â–‡â–‡â–‡â–‡
wandb:    val/path_hit_precision@1 â–ˆâ–…â–‚â–‚â–â–„â–‚â–‚â–ƒâ–ƒâ–â–†â–„â–‚â–â–â–‚â–‚â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–â–…â–ƒâ–„â–„â–†â–†â–…â–„â–†â–†â–„â–…â–ˆâ–ƒâ–‚â–„
wandb:   val/path_hit_precision@10 â–â–â–‚â–ƒâ–ƒâ–ƒâ–…â–„â–…â–…â–…â–†â–…â–„â–…â–…â–…â–†â–„â–†â–†â–†â–†â–…â–†â–†â–†â–‡â–†â–†â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val/path_hit_precision@20 â–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–†â–…â–„â–„â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡
wandb:    val/path_hit_precision@5 â–â–â–â–‚â–ƒâ–„â–„â–ƒâ–„â–…â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–…â–…â–…â–…â–…â–†â–†â–†â–…â–†â–†â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–ˆ
wandb:         val/path_hit_recall â–‚â–â–â–â–‚â–„â–„â–„â–…â–…â–„â–†â–…â–…â–†â–…â–„â–‡â–…â–…â–…â–†â–†â–†â–†â–†â–†â–…â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆ
wandb:       val/path_hit_recall@1 â–‚â–‚â–„â–‚â–ƒâ–ƒâ–…â–â–â–‚â–‚â–ƒâ–â–‚â–â–ƒâ–„â–ƒâ–ƒâ–…â–…â–‡â–ƒâ–ƒâ–„â–…â–‚â–‡â–†â–‚â–â–ˆâ–†â–…â–ƒâ–ˆâ–†â–‡â–„â–…
wandb:      val/path_hit_recall@10 â–‚â–â–â–â–‚â–„â–ƒâ–„â–…â–…â–„â–†â–ƒâ–…â–†â–†â–†â–…â–…â–…â–†â–…â–†â–…â–†â–†â–†â–†â–‡â–†â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡
wandb:      val/path_hit_recall@20 â–â–â–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–…â–„â–†â–†â–…â–…â–†â–†â–‡â–…â–†â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡
wandb:       val/path_hit_recall@5 â–â–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–…â–„â–…â–„â–…â–…â–†â–†â–…â–…â–†â–…â–…â–†â–…â–…â–†â–…â–…â–…â–†â–†â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:                  val/pb_nll â–ˆâ–â–â–â–â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚â–â–
wandb:                  val/pos_f1 â–â–â–â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–„â–„â–†â–†â–†â–†â–†â–…â–†â–…â–†â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆ
wandb:           val/pos_precision â–â–â–â–â–ƒâ–…â–„â–…â–…â–…â–†â–†â–†â–…â–…â–†â–„â–…â–†â–…â–…â–…â–†â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡
wandb:              val/pos_recall â–â–â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–…â–…â–„â–†â–†â–…â–†â–†â–…â–†â–†â–†â–…â–†â–†â–‡â–†â–†â–‡â–‡â–†â–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–‡
wandb:                  val/recall â–â–â–â–‚â–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–…â–†â–†â–…â–†â–†â–…â–…â–†â–…â–†â–†â–…â–†â–†â–‡â–‡â–†â–†â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–‡
wandb:     val/reward_connectivity â–â–‚â–‚â–â–‚â–„â–…â–„â–…â–…â–…â–†â–…â–…â–†â–…â–†â–…â–†â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:        val/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/rollout_reward â–‚â–â–â–â–‚â–„â–…â–†â–†â–†â–…â–…â–…â–†â–‡â–‡â–…â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–†â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:   val/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val/struct_phi_answer_div â–â–ƒâ–…â–„â–„â–„â–„â–„â–…â–‡â–…â–…â–‡â–†â–†â–†â–‡â–„â–…â–‡â–‡â–†â–†â–†â–‡â–‡â–†â–†â–†â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:           val/struct_phi_gt â–â–â–â–â–ƒâ–ƒâ–ƒâ–„â–…â–…â–„â–…â–…â–†â–†â–„â–…â–…â–…â–…â–†â–†â–†â–…â–†â–…â–†â–†â–†â–†â–†â–‡â–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–‡â–‡
wandb:          val/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val/success@10 â–‚â–â–…â–…â–…â–…â–…â–‡â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:              val/success@20 â–â–â–„â–„â–…â–…â–†â–…â–…â–†â–‡â–‡â–‡â–…â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–†â–‡â–‡â–‡â–‡
wandb:            val/success_mean â–â–â–„â–…â–…â–…â–†â–…â–†â–†â–†â–†â–…â–†â–†â–…â–‡â–…â–‡â–†â–…â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:                 val/tb_loss â–„â–…â–ƒâ–ˆâ–…â–‚â–†â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–â–‚â–…â–ƒâ–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:            val/unique_paths â–ˆâ–†â–„â–…â–ˆâ–„â–‚â–…â–„â–‚â–…â–…â–â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–„â–â–‡â–‡â–‚â–‚â–‚â–‚â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:                       epoch 200
wandb:        test/answer_coverage 0.20167
wandb:              test/answer_f1 0.07935
wandb:      test/answer_hit_any@10 0.75202
wandb:      test/answer_hit_any@20 0.82839
wandb:       test/answer_precision 0.06794
wandb:          test/answer_recall 0.20167
wandb: test/answer_recall_union@10 0.59704
wandb: test/answer_recall_union@20 0.70976
wandb:       test/avg_step_entropy 4.69225
wandb:    test/fallback_to_system1 0
wandb:         test/gt_path_exists 1
wandb:       test/gt_path_full_hit 0.1872
wandb:            test/length_mean 6.96878
wandb:             test/log_reward -4.27623
wandb:      test/log_reward_struct -1.97364
wandb:        test/logpf_logr_corr 0.35062
wandb:    test/logpf_logr_spearman 0.29035
wandb:            test/modes_found 3.19317
wandb:           test/modes_recall 0.70976
wandb:            test/path_exists 1
wandb:      test/path_exists_ratio 1
wandb:        test/path_hit_any@10 0.59569
wandb:        test/path_hit_any@20 0.73046
wandb:            test/path_hit_f1 0.04855
wandb:          test/path_hit_f1@1 0.00159
wandb:         test/path_hit_f1@10 0.04855
wandb:         test/path_hit_f1@20 0.04855
wandb:          test/path_hit_f1@5 0.05307
wandb:     test/path_hit_precision 0.02829
wandb:   test/path_hit_precision@1 0.00166
wandb:  test/path_hit_precision@10 0.02829
wandb:  test/path_hit_precision@20 0.02829
wandb:   test/path_hit_precision@5 0.03231
wandb:        test/path_hit_recall 0.18765
wandb:      test/path_hit_recall@1 0.00155
wandb:     test/path_hit_recall@10 0.18765
wandb:     test/path_hit_recall@20 0.18765
wandb:      test/path_hit_recall@5 0.15588
wandb:                 test/pb_nll 1.58273
wandb:                 test/pos_f1 0.04855
wandb:          test/pos_precision 0.02829
wandb:             test/pos_recall 0.18765
wandb:                 test/recall 0.20167
wandb:    test/reward_connectivity 0.20167
wandb:       test/reward_path_term 1
wandb:         test/rollout_reward 0.38157
wandb:  test/semantic_only_success 0
wandb:         test/semantic_score 1
wandb:  test/struct_phi_answer_div 0.53751
wandb:          test/struct_phi_gt 0.04855
wandb:         test/struct_phi_len 0
wandb:       test/struct_phi_score 0
wandb:             test/success@10 0.75202
wandb:             test/success@20 0.82839
wandb:           test/success_mean 0.38095
wandb:                test/tb_loss 39.93026
wandb:           test/unique_paths 19.87781
wandb:       train/answer_coverage 0.2871
wandb:             train/answer_f1 0.18333
wandb:      train/answer_precision 0.18136
wandb:         train/answer_recall 0.2871
wandb:      train/avg_step_entropy 8.35254
wandb:   train/fallback_to_system1 0
wandb:             train/gt_log_pf -4.89454
wandb:               train/gt_loss 2.37131
wandb:        train/gt_path_exists 1
wandb:      train/gt_path_full_hit 0.40286
wandb:           train/length_mean 5.12321
wandb:            train/log_reward -3.57748
wandb:     train/log_reward_struct -1.2749
wandb:                  train/loss 46.41916
wandb:           train/path_exists 1
wandb:     train/path_exists_ratio 1
wandb:           train/path_hit_f1 0.3335
wandb:    train/path_hit_precision 0.32344
wandb:       train/path_hit_recall 0.40286
wandb:                train/pb_nll 1.97971
wandb:                train/pos_f1 0.3335
wandb:         train/pos_precision 0.32344
wandb:            train/pos_recall 0.40286
wandb:                train/recall 0.2871
wandb:   train/reward_connectivity 0.2871
wandb:      train/reward_path_term 1
wandb:        train/rollout_reward 0.48262
wandb: train/semantic_only_success 0
wandb:        train/semantic_score 1
wandb: train/struct_phi_answer_div 0.56288
wandb:         train/struct_phi_gt 0.3335
wandb:        train/struct_phi_len 0
wandb:      train/struct_phi_score 0
wandb:          train/success_mean 0.48211
wandb:               train/tb_loss 44.04786
wandb:         trainer/global_step 6200
wandb:         val/answer_coverage 0.17569
wandb:               val/answer_f1 0.07026
wandb:       val/answer_hit_any@10 0.71765
wandb:       val/answer_hit_any@20 0.76471
wandb:        val/answer_precision 0.06113
wandb:           val/answer_recall 0.17569
wandb:  val/answer_recall_union@10 0.55832
wandb:  val/answer_recall_union@20 0.64203
wandb:        val/avg_step_entropy 4.7164
wandb:     val/fallback_to_system1 0
wandb:          val/gt_path_exists 1
wandb:        val/gt_path_full_hit 0.16324
wandb:             val/length_mean 6.98824
wandb:              val/log_reward -4.44738
wandb:       val/log_reward_struct -2.14479
wandb:         val/logpf_logr_corr 0.32807
wandb:     val/logpf_logr_spearman 0.25187
wandb:             val/modes_found 3.02941
wandb:            val/modes_recall 0.64203
wandb:             val/path_exists 1
wandb:       val/path_exists_ratio 1
wandb:         val/path_hit_any@10 0.57647
wandb:         val/path_hit_any@20 0.69412
wandb:             val/path_hit_f1 0.04136
wandb:           val/path_hit_f1@1 0.00108
wandb:          val/path_hit_f1@10 0.04136
wandb:          val/path_hit_f1@20 0.04136
wandb:           val/path_hit_f1@5 0.04566
wandb:      val/path_hit_precision 0.02368
wandb:    val/path_hit_precision@1 0.00118
wandb:   val/path_hit_precision@10 0.02368
wandb:   val/path_hit_precision@20 0.02368
wandb:    val/path_hit_precision@5 0.02741
wandb:         val/path_hit_recall 0.16353
wandb:       val/path_hit_recall@1 0.00103
wandb:      val/path_hit_recall@10 0.16353
wandb:      val/path_hit_recall@20 0.16353
wandb:       val/path_hit_recall@5 0.13676
wandb:                  val/pb_nll 1.2542
wandb:                  val/pos_f1 0.04136
wandb:           val/pos_precision 0.02368
wandb:              val/pos_recall 0.16353
wandb:                  val/recall 0.17569
wandb:     val/reward_connectivity 0.17569
wandb:        val/reward_path_term 1
wandb:          val/rollout_reward 0.35682
wandb:   val/semantic_only_success 0
wandb:          val/semantic_score 1
wandb:   val/struct_phi_answer_div 0.48735
wandb:           val/struct_phi_gt 0.04136
wandb:          val/struct_phi_len 0
wandb:        val/struct_phi_score 0
wandb:              val/success@10 0.71765
wandb:              val/success@20 0.76471
wandb:            val/success_mean 0.35618
wandb:                 val/tb_loss 45.89576
wandb:            val/unique_paths 19.87647
wandb: 
wandb: ğŸš€ View run train_gflownet_prior_alpha0 at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/ywwzloz6
wandb: â­ï¸ View project at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/train_gflownet_prior_alpha0/runs/2025-12-04_11-31-15/wandb/run-20251204_113117-ywwzloz6/logs
[[36m2025-12-04 13:05:01,777[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Retrieved metric value! <val/rollout_reward=0.356820285320282>[0m
==> Running train_gflownet_prior_alpha2_to0, logging to logs/prior_ablation/train_gflownet_prior_alpha2_to0_20251204_113111.log
[[36m2025-12-04 13:05:07,608[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-12-04 13:05:07,610[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] torch.set_float32_matmul_precision(high)[0m
[[36m2025-12-04 13:05:07,611[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.g_agent_datamodule.GAgentDataModule                  
â”‚       cache_paths:                                                            
â”‚         train: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g
â”‚         validation: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/va
â”‚         test: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_a
â”‚       batch_size: 64                                                          
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       drop_last: false                                                        
â”‚       persistent_workers: true                                                
â”‚       shuffle_train: true                                                     
â”‚       resources:                                                              
â”‚         vocabulary_path: /mnt/data/retrieval_dataset/webqsp/materialized/vocab
â”‚         embeddings_dir: /mnt/data/retrieval_dataset/webqsp/materialized/embedd
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.gflownet_module.GFlowNetModule                     
â”‚       _recursive_: false                                                      
â”‚       hidden_dim: 1024                                                        
â”‚       training_cfg:                                                           
â”‚         normalize_log_reward: true                                            
â”‚         gt_replay_ratio: 0.3                                                  
â”‚         learn_pb: true                                                        
â”‚         debug_batches_to_log: 1                                               
â”‚         debug_graphs_to_log: 2                                                
â”‚         retriever_prior_alpha: 2.0                                            
â”‚         retriever_prior_anneal:                                               
â”‚           start: 2.0                                                          
â”‚           end: 0.0                                                            
â”‚           steps: 10000                                                        
â”‚         pb_loss_weight: 1.0                                                   
â”‚         pb_loss_anneal:                                                       
â”‚           start: 1.0                                                          
â”‚           end: 0.0                                                            
â”‚           steps: 5000                                                         
â”‚         gt_loss_weight: 0.15                                                  
â”‚       evaluation_cfg:                                                         
â”‚         num_eval_rollouts:                                                    
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚         path_hit_k:                                                           
â”‚         - 1                                                                   
â”‚         - 5                                                                   
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚       optimizer_cfg:                                                          
â”‚         type: adamw                                                           
â”‚         lr: 0.0001                                                            
â”‚         weight_decay: 0.0001                                                  
â”‚         param_groups:                                                         
â”‚         - params:                                                             
â”‚           - estimator.log_z_head                                              
â”‚           - estimator.log_z_condition                                         
â”‚           lr: 0.001                                                           
â”‚       scheduler_cfg:                                                          
â”‚         type: cosine                                                          
â”‚         t_max: 200                                                            
â”‚         eta_min: 1.0e-06                                                      
â”‚         interval: epoch                                                       
â”‚         monitor: val/reward                                                   
â”‚       logging_cfg:                                                            
â”‚         train_prog_bar:                                                       
â”‚         - rollout_reward                                                      
â”‚         - success_mean                                                        
â”‚         - answer_coverage                                                     
â”‚         - length_mean                                                         
â”‚         eval_prog_bar:                                                        
â”‚         - success_mean                                                        
â”‚         - answer_f1                                                           
â”‚         auto_add_success_at_k: true                                           
â”‚         auto_add_path_hit_f1: true                                            
â”‚         log_on_step_train: false                                              
â”‚       env_cfg:                                                                
â”‚         _target_: src.models.components.gflownet_env.GraphEnv                 
â”‚         mode: subgraph                                                        
â”‚         max_steps: 6                                                          
â”‚         forbid_backtrack: true                                                
â”‚         forbid_revisit: true                                                  
â”‚         bidir_token: false                                                    
â”‚         debug: true                                                           
â”‚         debug_max_resets: 2                                                   
â”‚         debug_max_graphs: 2                                                   
â”‚         debug_max_hits: 4                                                     
â”‚       policy_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_policies.EdgeMLPMixerPolicy  
â”‚         hidden_dim: 1024                                                      
â”‚         dropout: 0.5                                                          
â”‚         num_layers: 2                                                         
â”‚       reward_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_rewards.AnswerOnlyReward     
â”‚         success_reward: 10.0                                                  
â”‚         failure_reward: 0.01                                                  
â”‚         lambda_reach: 0.0                                                     
â”‚         gamma_len: 0.0                                                        
â”‚         gamma_score: 0.0                                                      
â”‚         score_clip_max: 1.0                                                   
â”‚         score_eps: 1.0e-08                                                    
â”‚         gamma_gt: 0.0                                                         
â”‚         gamma_answer_div: 0.0                                                 
â”‚       actor_cfg:                                                              
â”‚         _target_: src.models.components.gflownet_actor.GFlowNetActor          
â”‚         policy_temperature: 1.0                                               
â”‚         eval_policy_temperature: 0.7                                          
â”‚         stop_logit_bias: -1.0                                                 
â”‚         random_action_prob: 0.1                                               
â”‚         debug_actions: false                                                  
â”‚         debug_actions_steps: 0                                                
â”‚       embedder_cfg:                                                           
â”‚         _target_: src.models.components.gflownet_embedder.GraphEmbedder       
â”‚         hidden_dim: 1024                                                      
â”‚         proj_dropout: 0.0                                                     
â”‚         projector_checkpoint: logs/train_retriever_webqsp/runs/2025-12-02_19-2
â”‚         freeze_projectors: true                                               
â”‚         kge_interaction: concat                                               
â”‚         projector_key_prefixes:                                               
â”‚         - retriever.model._orig_mod                                           
â”‚         - retriever.model                                                     
â”‚         - retriever                                                           
â”‚         - model._orig_mod                                                     
â”‚         - model                                                               
â”‚         - ''                                                                  
â”‚         use_gfn_projectors: true                                              
â”‚       estimator_cfg:                                                          
â”‚         _target_: src.models.components.gflownet_estimator.GFlowNetEstimator  
â”‚         hidden_dim: 1024                                                      
â”‚         log_pb_mode: learned                                                  
â”‚         learn_pb: true                                                        
â”‚         pb_entropy_coef: 0.0                                                  
â”‚         pb_l2_reg: 0.0                                                        
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_t
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/rollout_reward                                           
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 1                                                         
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/rollout_reward                                           
â”‚         min_delta: 0.0                                                        
â”‚         patience: 50                                                          
â”‚         verbose: false                                                        
â”‚         mode: max                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         name: train_gflownet_prior_alpha2_to0                                 
â”‚         save_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: evi-rag                                                      
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         entity: null                                                          
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_a
â”‚       min_epochs: 50                                                          
â”‚       max_epochs: 200                                                         
â”‚       accelerator: gpu                                                        
â”‚       devices: 1                                                              
â”‚       gradient_clip_val: 1.0                                                  
â”‚       check_val_every_n_epoch: 1                                              
â”‚       log_every_n_steps: 1                                                    
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚       data_dir: /mnt/data/retrieval_dataset                                   
â”‚       log_dir: /mnt/wangjingxiong/EVI-RAG/logs/                               
â”‚       debug_log_path: /mnt/wangjingxiong/EVI-RAG/logs//debug.log              
â”‚       output_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_
â”‚       work_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚       torch_float32_matmul_precision: high                                    
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train_gflownet_prior_alpha2_to0                                         
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['ablation', 'prior=2->0']                                              
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ debug_data_loading
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ test_ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ allow_test_without_checkpoint
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 42                                                                      
â”œâ”€â”€ dataset
â”‚   â””â”€â”€ name: webqsp                                                            
â”‚       kb: freebase                                                            
â”‚       raw_root: /mnt/data/retrieval_dataset/webqsp/raw/data                   
â”‚       out_dir: /mnt/data/retrieval_dataset/webqsp/normalized                  
â”‚       materialized_dir: /mnt/data/retrieval_dataset/webqsp/materialized       
â”‚       paths:                                                                  
â”‚         vocabulary: /mnt/data/retrieval_dataset/webqsp/materialized/vocabulary
â”‚         embeddings: /mnt/data/retrieval_dataset/webqsp/materialized/embeddings
â”‚         processed: /mnt/data/retrieval_dataset/webqsp/materialized/processed  
â”‚       entity_normalization: none                                              
â”‚       undirected_traversal: false                                             
â”‚       hard_negative_k: 4                                                      
â”‚       hard_negative_similarity: cosine                                        
â”‚       column_map:                                                             
â”‚         question_id_field: id                                                 
â”‚         question_field: question                                              
â”‚         answer_text_field: answer                                             
â”‚         q_entity_field: q_entity                                              
â”‚         a_entity_field: a_entity                                              
â”‚         graph_field: graph                                                    
â”‚                                                                               
â”œâ”€â”€ optimized_metric
â”‚   â””â”€â”€ val/rollout_reward                                                      
â”œâ”€â”€ gflownet_debug
â”‚   â””â”€â”€ True                                                                    
â””â”€â”€ env_debug
    â””â”€â”€ True                                                                    
Seed set to 42
[[36m2025-12-04 13:05:07,656[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resolved run name: train_gflownet_prior_alpha2_to0[0m
[[36m2025-12-04 13:05:07,657[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.g_agent_datamodule.GAgentDataModule>[0m
[[36m2025-12-04 13:05:08,155[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.gflownet_module.GFlowNetModule>[0m
[[36m2025-12-04 13:05:08,222[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-12-04 13:05:08,222[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-12-04 13:05:08,223[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-12-04 13:05:08,224[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-12-04 13:05:08,224[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-12-04 13:05:08,224[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-12-04 13:05:08,224[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-12-04 13:05:08,226[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
[[36m2025-12-04 13:05:08,263[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: martin1007wang (martin1007wang-wuhan-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0/runs/2025-12-04_13-05-07/wandb/run-20251204_130509-k7o8uqah
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train_gflownet_prior_alpha2_to0
wandb: â­ï¸ View project at https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: ğŸš€ View run at https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/k7o8uqah
[[36m2025-12-04 13:05:11,101[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-12-04 13:05:12,298[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g_agent.pt: 1956 samples.[0m
[[36m2025-12-04 13:05:12,370[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/validation_g_agent.pt: 170 samples.[0m
[[36m2025-12-04 13:05:12,684[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/entity_embeddings.pt...[0m
[[36m2025-12-04 13:05:13,458[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/relation_embeddings.pt...[0m
[[36m2025-12-04 13:05:13,467[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Entity embedding rows: 524643 (vocab entities: 1281202). Non-text entities use embedding_id=0; textual entities occupy 1..max_id.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                                            â”ƒ Type  â”ƒ Paraâ€¦ â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ policy                                          â”‚ Edgeâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 1  â”‚ policy.type_embeddings                          â”‚ Embeâ€¦ â”‚ 5.1 K â”‚ train â”‚
â”‚ 2  â”‚ policy.graph_norm                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 3  â”‚ policy.q_film                                   â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 4  â”‚ policy.q_film.0                                 â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 5  â”‚ policy.q_film.1                                 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 6  â”‚ policy.q_film.2                                 â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 7  â”‚ policy.edge_mlp                                 â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 8  â”‚ policy.edge_mlp.0                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 9  â”‚ policy.edge_mlp.1                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 10 â”‚ policy.edge_mlp.2                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 11 â”‚ policy.edge_mlp.3                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 12 â”‚ policy.edge_mlp.4                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 13 â”‚ policy.edge_mlp.5                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 14 â”‚ policy.edge_mlp.6                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 15 â”‚ policy.edge_mlp.7                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 16 â”‚ policy.lookahead_head                           â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 17 â”‚ policy.lookahead_head.0                         â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 18 â”‚ policy.lookahead_head.1                         â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 19 â”‚ policy.lookahead_head.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 20 â”‚ policy.lookahead_head.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 21 â”‚ policy.lookahead_head.4                         â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 22 â”‚ policy.stop_proj                                â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 23 â”‚ policy.stop_proj.0                              â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 24 â”‚ policy.stop_proj.1                              â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 25 â”‚ policy.stop_proj.2                              â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 26 â”‚ policy.stop_proj.3                              â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 27 â”‚ reward_fn                                       â”‚ Answâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 28 â”‚ env                                             â”‚ Grapâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 29 â”‚ embedder                                        â”‚ Grapâ€¦ â”‚  12.6 â”‚ train â”‚
â”‚    â”‚                                                 â”‚       â”‚     M â”‚       â”‚
â”‚ 30 â”‚ embedder.entity_projector                       â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 31 â”‚ embedder.entity_projector.0                     â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 32 â”‚ embedder.entity_projector.1                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 33 â”‚ embedder.entity_projector.2                     â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 34 â”‚ embedder.entity_projector.3                     â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 35 â”‚ embedder.entity_projector.4                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 36 â”‚ embedder.relation_projector                     â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 37 â”‚ embedder.relation_projector.0                   â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 38 â”‚ embedder.relation_projector.1                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 39 â”‚ embedder.relation_projector.2                   â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 40 â”‚ embedder.relation_projector.3                   â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 41 â”‚ embedder.relation_projector.4                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 42 â”‚ embedder.edge_adapter                           â”‚ Sequâ€¦ â”‚ 5.3 M â”‚ train â”‚
â”‚ 43 â”‚ embedder.edge_adapter.0                         â”‚ Layeâ€¦ â”‚ 8.2 K â”‚ train â”‚
â”‚ 44 â”‚ embedder.edge_adapter.1                         â”‚ Lineâ€¦ â”‚ 4.2 M â”‚ train â”‚
â”‚ 45 â”‚ embedder.edge_adapter.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 46 â”‚ embedder.edge_adapter.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 47 â”‚ embedder.edge_adapter.4                         â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 48 â”‚ embedder.retriever_entity_projector             â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 49 â”‚ embedder.retriever_entity_projector.network     â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 50 â”‚ embedder.retriever_entity_projector.network.0   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 51 â”‚ embedder.retriever_entity_projector.network.1   â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 52 â”‚ embedder.retriever_relation_projector           â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 53 â”‚ embedder.retriever_relation_projector.network   â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 54 â”‚ embedder.retriever_relation_projector.network.0 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 55 â”‚ embedder.retriever_relation_projector.network.1 â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 56 â”‚ embedder.retriever_query_projector              â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 57 â”‚ embedder.retriever_query_projector.network      â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 58 â”‚ embedder.retriever_query_projector.network.0    â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 59 â”‚ embedder.retriever_query_projector.network.1    â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 60 â”‚ estimator                                       â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 61 â”‚ estimator.log_z_head                            â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 62 â”‚ estimator.log_z_head.0                          â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 63 â”‚ estimator.log_z_head.1                          â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 64 â”‚ estimator.log_z_head.2                          â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 65 â”‚ estimator.log_z_head.3                          â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 66 â”‚ estimator.ctx_projector                         â”‚ Sequâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 67 â”‚ estimator.ctx_projector.0                       â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 68 â”‚ estimator.ctx_projector.1                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 69 â”‚ estimator.ctx_projector.2                       â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 70 â”‚ estimator.backward_head                         â”‚ Sequâ€¦ â”‚ 3.2 M â”‚ train â”‚
â”‚ 71 â”‚ estimator.backward_head.0                       â”‚ Layeâ€¦ â”‚ 6.1 K â”‚ train â”‚
â”‚ 72 â”‚ estimator.backward_head.1                       â”‚ Lineâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 73 â”‚ estimator.backward_head.2                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 74 â”‚ estimator.backward_head.3                       â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 75 â”‚ estimator.backward_head.4                       â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 76 â”‚ actor                                           â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 24.2 M                                                        
Non-trainable params: 3.1 M                                                     
Total params: 27.3 M                                                            
Total estimated model params size (MB): 109                                     
Modules in train mode: 65                                                       
Modules in eval mode: 12                                                        
/anaconda3/envs/pog/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 12 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Epoch 56/199 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 31/31 0:00:17 â€¢ 0:00:00 1.77it/s v_num: uqah      
                                                               val/answer_f1:   
                                                               0.166            
                                                               val/path_hit_f1@â€¦
                                                               0.125            
                                                               val/success_mean:
                                                               0.850            
                                                               val/success@20:  
                                                               0.906 train/loss:
                                                               37.583           
                                                               train/rollout_reâ€¦
                                                               0.837            
                                                               train/success_meâ€¦
                                                               0.836            
                                                               train/answer_covâ€¦
                                                               0.578            
                                                               train/length_meaâ€¦
                                                               5.165            
[[36m2025-12-04 13:31:34,186[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting testing![0m
[[36m2025-12-04 13:31:34,837[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_agent.pt: 1113 samples.[0m
Restoring states from the checkpoint path at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0/runs/2025-12-04_13-05-07/checkpoints/epoch_006.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0/runs/2025-12-04_13-05-07/checkpoints/epoch_006.ckpt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ         Test metric         â”ƒ        DataLoader 0         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚    test/answer_coverage     â”‚      0.821488082408905      â”‚
â”‚       test/answer_f1        â”‚     0.34443438053131104     â”‚
â”‚   test/answer_hit_any@10    â”‚     0.9460916519165039      â”‚
â”‚   test/answer_hit_any@20    â”‚     0.9469901323318481      â”‚
â”‚    test/answer_precision    â”‚     0.28287678956985474     â”‚
â”‚     test/answer_recall      â”‚      0.821488082408905      â”‚
â”‚ test/answer_recall_union@10 â”‚     0.8780678510665894      â”‚
â”‚ test/answer_recall_union@20 â”‚     0.8890221118927002      â”‚
â”‚    test/avg_step_entropy    â”‚     2.6229794025421143      â”‚
â”‚  test/fallback_to_system1   â”‚             0.0             â”‚
â”‚     test/gt_path_exists     â”‚             1.0             â”‚
â”‚    test/gt_path_full_hit    â”‚      0.784142017364502      â”‚
â”‚      test/length_mean       â”‚      6.973944187164307      â”‚
â”‚       test/log_reward       â”‚     -0.4164513945579529     â”‚
â”‚   test/log_reward_struct    â”‚     1.8861339092254639      â”‚
â”‚    test/logpf_logr_corr     â”‚    -0.03504839539527893     â”‚
â”‚  test/logpf_logr_spearman   â”‚    -0.012811223976314068    â”‚
â”‚      test/modes_found       â”‚     3.4294698238372803      â”‚
â”‚      test/modes_recall      â”‚     0.8890221118927002      â”‚
â”‚      test/path_exists       â”‚             1.0             â”‚
â”‚   test/path_exists_ratio    â”‚             1.0             â”‚
â”‚    test/path_hit_any@10     â”‚     0.9074573516845703      â”‚
â”‚    test/path_hit_any@20     â”‚     0.9209344387054443      â”‚
â”‚      test/path_hit_f1       â”‚     0.19790303707122803     â”‚
â”‚     test/path_hit_f1@1      â”‚     0.12583108246326447     â”‚
â”‚     test/path_hit_f1@10     â”‚     0.19790303707122803     â”‚
â”‚     test/path_hit_f1@20     â”‚     0.19790303707122803     â”‚
â”‚     test/path_hit_f1@5      â”‚     0.2450733482837677      â”‚
â”‚   test/path_hit_precision   â”‚     0.11370812356472015     â”‚
â”‚  test/path_hit_precision@1  â”‚     0.12583108246326447     â”‚
â”‚ test/path_hit_precision@10  â”‚     0.11370812356472015     â”‚
â”‚ test/path_hit_precision@20  â”‚     0.11370812356472015     â”‚
â”‚  test/path_hit_precision@5  â”‚     0.1475621461868286      â”‚
â”‚    test/path_hit_recall     â”‚      0.784142017364502      â”‚
â”‚   test/path_hit_recall@1    â”‚     0.12583108246326447     â”‚
â”‚   test/path_hit_recall@10   â”‚      0.784142017364502      â”‚
â”‚   test/path_hit_recall@20   â”‚      0.784142017364502      â”‚
â”‚   test/path_hit_recall@5    â”‚     0.7314465045928955      â”‚
â”‚         test/pb_nll         â”‚     1.0226143598556519      â”‚
â”‚         test/pos_f1         â”‚     0.19790303707122803     â”‚
â”‚     test/pos_precision      â”‚     0.11370812356472015     â”‚
â”‚       test/pos_recall       â”‚      0.784142017364502      â”‚
â”‚         test/recall         â”‚      0.821488082408905      â”‚
â”‚  test/reward_connectivity   â”‚      0.821488082408905      â”‚
â”‚    test/reward_path_term    â”‚             1.0             â”‚
â”‚     test/rollout_reward     â”‚     0.9397727251052856      â”‚
â”‚ test/semantic_only_success  â”‚             0.0             â”‚
â”‚     test/semantic_score     â”‚             1.0             â”‚
â”‚ test/struct_phi_answer_div  â”‚      2.255929946899414      â”‚
â”‚     test/struct_phi_gt      â”‚     0.19790303707122803     â”‚
â”‚     test/struct_phi_len     â”‚             0.0             â”‚
â”‚    test/struct_phi_score    â”‚             0.0             â”‚
â”‚       test/success@10       â”‚     0.9460916519165039      â”‚
â”‚       test/success@20       â”‚     0.9469901323318481      â”‚
â”‚      test/success_mean      â”‚      0.939712405204773      â”‚
â”‚        test/tb_loss         â”‚      67.67902374267578      â”‚
â”‚      test/unique_paths      â”‚     19.468103408813477      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Testing â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18/18 0:01:04 â€¢ 0:00:00 0.30it/s 
[[36m2025-12-04 13:32:40,032[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Best ckpt path: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0/runs/2025-12-04_13-05-07/checkpoints/epoch_006.ckpt[0m
[[36m2025-12-04 13:32:40,033[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0/runs/2025-12-04_13-05-07[0m
[[36m2025-12-04 13:32:40,034[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        test/answer_coverage â–
wandb:              test/answer_f1 â–
wandb:      test/answer_hit_any@10 â–
wandb:      test/answer_hit_any@20 â–
wandb:       test/answer_precision â–
wandb:          test/answer_recall â–
wandb: test/answer_recall_union@10 â–
wandb: test/answer_recall_union@20 â–
wandb:       test/avg_step_entropy â–
wandb:    test/fallback_to_system1 â–
wandb:         test/gt_path_exists â–
wandb:       test/gt_path_full_hit â–
wandb:            test/length_mean â–
wandb:             test/log_reward â–
wandb:      test/log_reward_struct â–
wandb:        test/logpf_logr_corr â–
wandb:    test/logpf_logr_spearman â–
wandb:            test/modes_found â–
wandb:           test/modes_recall â–
wandb:            test/path_exists â–
wandb:      test/path_exists_ratio â–
wandb:        test/path_hit_any@10 â–
wandb:        test/path_hit_any@20 â–
wandb:            test/path_hit_f1 â–
wandb:          test/path_hit_f1@1 â–
wandb:         test/path_hit_f1@10 â–
wandb:         test/path_hit_f1@20 â–
wandb:          test/path_hit_f1@5 â–
wandb:     test/path_hit_precision â–
wandb:   test/path_hit_precision@1 â–
wandb:  test/path_hit_precision@10 â–
wandb:  test/path_hit_precision@20 â–
wandb:   test/path_hit_precision@5 â–
wandb:        test/path_hit_recall â–
wandb:      test/path_hit_recall@1 â–
wandb:     test/path_hit_recall@10 â–
wandb:     test/path_hit_recall@20 â–
wandb:      test/path_hit_recall@5 â–
wandb:                 test/pb_nll â–
wandb:                 test/pos_f1 â–
wandb:          test/pos_precision â–
wandb:             test/pos_recall â–
wandb:                 test/recall â–
wandb:    test/reward_connectivity â–
wandb:       test/reward_path_term â–
wandb:         test/rollout_reward â–
wandb:  test/semantic_only_success â–
wandb:         test/semantic_score â–
wandb:  test/struct_phi_answer_div â–
wandb:          test/struct_phi_gt â–
wandb:         test/struct_phi_len â–
wandb:       test/struct_phi_score â–
wandb:             test/success@10 â–
wandb:             test/success@20 â–
wandb:           test/success_mean â–
wandb:                test/tb_loss â–
wandb:           test/unique_paths â–
wandb:       train/answer_coverage â–ˆâ–‡â–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–„â–„â–‚â–…â–…â–„â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–â–
wandb:             train/answer_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–‡â–…â–†â–…â–…â–…â–„â–„â–‚â–„â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚
wandb:      train/answer_precision â–ˆâ–…â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb:         train/answer_recall â–‡â–ˆâ–‡â–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–‚â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–â–‚â–â–ƒâ–
wandb:      train/avg_step_entropy â–â–„â–„â–„â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆ
wandb:   train/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             train/gt_log_pf â–‡â–‡â–ˆâ–‡â–‡â–„â–…â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–â–‚â–â–ƒâ–‚â–ƒâ–‚â–‚
wandb:               train/gt_loss â–â–„â–„â–„â–„â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        train/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/gt_path_full_hit â–‡â–ˆâ–‡â–ˆâ–‡â–†â–†â–†â–†â–†â–†â–„â–ƒâ–…â–‚â–†â–†â–…â–„â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–â–‚â–â–ƒâ–
wandb:           train/length_mean â–â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡
wandb:            train/log_reward â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–†â–„â–‡â–†â–†â–…â–…â–„â–…â–…â–†â–…â–†â–ƒâ–…â–…â–†â–†â–„â–…â–â–„â–‚â–„â–‚
wandb:     train/log_reward_struct â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–†â–ƒâ–‡â–†â–†â–‡â–…â–„â–…â–…â–ƒâ–…â–…â–†â–ƒâ–…â–†â–…â–†â–„â–…â–ƒâ–â–‚â–„â–‚
wandb:                  train/loss â–„â–†â–†â–ˆâ–‡â–‡â–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–ƒâ–ƒâ–…â–ƒâ–„â–„â–‚â–ƒâ–„â–ƒâ–ƒ
wandb:           train/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           train/path_hit_f1 â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚
wandb:    train/path_hit_precision â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–‚
wandb:       train/path_hit_recall â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–„â–…â–‚â–„â–†â–†â–…â–…â–†â–ƒâ–„â–„â–„â–„â–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–‚â–‚
wandb:                train/pb_nll â–ƒâ–ˆâ–‡â–†â–„â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:                train/pos_f1 â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–‚â–‚
wandb:         train/pos_precision â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚
wandb:            train/pos_recall â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–†â–„â–‚â–„â–†â–†â–…â–†â–„â–„â–ƒâ–ƒâ–‚â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–â–ƒâ–‚â–‚
wandb:                train/recall â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–„â–„â–‚â–…â–…â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–â–â–‚â–â–ƒâ–
wandb:   train/reward_connectivity â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–„â–ƒâ–‚â–‚â–…â–…â–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–‚â–â–
wandb:      train/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/rollout_reward â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–„â–‡â–‡â–†â–†â–‡â–„â–„â–„â–„â–ƒâ–…â–…â–‚â–…â–…â–…â–„â–„â–‚â–„â–â–„â–
wandb: train/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train/struct_phi_answer_div â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–‚â–„â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚â–‚
wandb:         train/struct_phi_gt â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚
wandb:        train/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/success_mean â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–ƒâ–†â–ƒâ–‡â–‡â–‡â–‡â–…â–…â–„â–ƒâ–†â–…â–…â–†â–…â–†â–†â–†â–„â–…â–â–ƒâ–â–‚
wandb:               train/tb_loss â–„â–…â–…â–‡â–†â–ˆâ–†â–†â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:         trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:         val/answer_coverage â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–…â–‡â–ƒâ–ƒâ–„â–…â–„â–…â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–…â–‚â–â–„â–‚â–ƒâ–ƒâ–‚â–„â–‚â–‚â–‚â–â–‚â–
wandb:               val/answer_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–…â–…â–…â–…â–…â–…â–„â–„â–ƒâ–â–„â–…â–„â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–â–‚â–‚â–â–
wandb:       val/answer_hit_any@10 â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡â–†â–‡â–†â–‡â–ˆâ–ˆâ–…â–â–ˆâ–†â–†â–ˆâ–†â–‡â–†â–‡â–†â–†â–‡â–†â–ˆâ–â–‚â–†â–…â–‡â–‡â–†â–â–‡â–‚
wandb:       val/answer_hit_any@20 â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–„â–‚â–‡â–ˆâ–…â–‡â–ˆâ–‡â–…â–‡â–‡â–…â–ˆâ–…â–…â–ˆâ–„â–‡â–…â–…â–‡â–‡â–…â–…â–„â–‡â–
wandb:        val/answer_precision â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–„â–…â–…â–„â–„â–‡â–‚â–â–„â–…â–ƒâ–„â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–â–â–‚â–
wandb:           val/answer_recall â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–…â–…â–…â–…â–‡â–ƒâ–ƒâ–…â–…â–„â–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–…â–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–„â–‚â–â–‚â–‚â–ƒâ–
wandb:  val/answer_recall_union@10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–†â–†â–…â–…â–…â–ˆâ–ƒâ–ƒâ–„â–†â–†â–„â–„â–…â–ƒâ–„â–„â–„â–„â–„â–…â–ƒâ–„â–‚â–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–„â–
wandb:  val/answer_recall_union@20 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–ˆâ–ƒâ–‚â–…â–†â–†â–„â–…â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–†â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–ƒâ–â–â–‚â–‚â–â–
wandb:        val/avg_step_entropy â–„â–„â–„â–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–…â–…â–„â–„â–ƒâ–ƒâ–„â–…â–„â–„â–„â–„â–…â–„â–…â–†â–‡â–‡â–…â–†â–‡â–‡â–‡â–‡â–ˆ
wandb:     val/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/gt_path_full_hit â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–‡â–ƒâ–‚â–…â–…â–…â–…â–…â–…â–„â–„â–„â–‚â–„â–ƒâ–…â–ƒâ–‚â–„â–„â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–ƒâ–
wandb:             val/length_mean â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:              val/log_reward â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–†â–ˆâ–ˆâ–„â–ˆâ–ˆâ–‡â–‡â–‡â–„â–†â–‡â–†â–ƒâ–‡â–†â–ˆâ–…â–‡â–‚â–…â–…â–‡â–ƒâ–„â–ƒâ–â–…â–‚
wandb:       val/log_reward_struct â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–„â–‚â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–†â–‡â–„â–‚â–…â–…â–‡â–â–„â–„â–ƒ
wandb:         val/logpf_logr_corr â–„â–„â–„â–„â–…â–„â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–…â–„â–…â–ˆâ–…â–‚â–â–ƒâ–…â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚
wandb:     val/logpf_logr_spearman â–…â–†â–…â–†â–…â–…â–†â–…â–…â–†â–…â–…â–…â–†â–‚â–„â–„â–„â–…â–…â–„â–…â–ƒâ–…â–…â–…â–„â–ˆâ–…â–â–â–„â–†â–‚â–ƒâ–‚â–‚â–â–ƒâ–
wandb:             val/modes_found â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–…â–…â–„â–„â–„â–ˆâ–ƒâ–‚â–„â–…â–…â–„â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–â–ƒâ–
wandb:            val/modes_recall â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–…â–…â–…â–ˆâ–„â–â–†â–†â–…â–…â–…â–ƒâ–„â–„â–„â–„â–†â–ƒâ–‚â–„â–‚â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚
wandb:             val/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       val/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         val/path_hit_any@10 â–‡â–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–…â–†â–†â–…â–†â–†â–„â–…â–‡â–…â–…â–…â–ƒâ–„â–„â–ƒâ–…â–„â–†â–„â–‚â–„â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–‚â–
wandb:         val/path_hit_any@20 â–‡â–‡â–ˆâ–ˆâ–†â–†â–†â–†â–†â–„â–†â–…â–…â–†â–†â–„â–‚â–…â–‡â–…â–…â–ƒâ–ƒâ–„â–ƒâ–…â–„â–…â–‚â–…â–„â–„â–„â–„â–‚â–‚â–ƒâ–ƒâ–„â–
wandb:             val/path_hit_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–ƒâ–â–…â–†â–…â–…â–ƒâ–„â–„â–„â–‚â–„â–ƒâ–‚â–â–„â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–‚â–‚â–
wandb:           val/path_hit_f1@1 â–ˆâ–ˆâ–ˆâ–‡â–†â–‚â–‚â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/path_hit_f1@10 â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–†â–ƒâ–ƒâ–†â–…â–…â–…â–…â–ƒâ–„â–„â–‚â–„â–ƒâ–…â–‚â–â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:          val/path_hit_f1@20 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–…â–‡â–ƒâ–…â–…â–…â–…â–…â–ƒâ–„â–„â–‚â–„â–„â–…â–â–„â–‚â–‚â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–‚â–‚â–
wandb:           val/path_hit_f1@5 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–…â–†â–†â–…â–…â–„â–…â–†â–ƒâ–„â–†â–…â–„â–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–…â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–‚â–â–ƒâ–‚
wandb:      val/path_hit_precision â–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–…â–„â–ƒâ–‚â–…â–…â–…â–…â–…â–…â–„â–„â–„â–‚â–„â–ƒâ–‚â–„â–‚â–‚â–ƒâ–„â–ƒâ–„â–‚â–â–‚â–‚â–‚â–
wandb:    val/path_hit_precision@1 â–ˆâ–ˆâ–ˆâ–‡â–…â–ƒâ–‚â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val/path_hit_precision@10 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–†â–…â–…â–…â–…â–ƒâ–„â–„â–‚â–„â–ƒâ–…â–ƒâ–‚â–„â–‚â–„â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–
wandb:   val/path_hit_precision@20 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–„â–‚â–…â–†â–…â–…â–ƒâ–„â–„â–‚â–„â–…â–ƒâ–‚â–„â–‚â–ƒâ–„â–ƒâ–„â–‚â–â–‚â–‚â–‚â–
wandb:    val/path_hit_precision@5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–…â–…â–†â–…â–…â–„â–„â–…â–ƒâ–ƒâ–‚â–„â–†â–„â–„â–„â–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–
wandb:         val/path_hit_recall â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–…â–†â–ƒâ–…â–†â–…â–…â–…â–ƒâ–„â–„â–„â–„â–ƒâ–…â–‚â–â–‚â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–‚â–‚â–
wandb:       val/path_hit_recall@1 â–ˆâ–ˆâ–†â–†â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      val/path_hit_recall@10 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–ƒâ–‚â–†â–…â–…â–…â–…â–ƒâ–„â–„â–„â–„â–…â–ƒâ–‚â–„â–ƒâ–ƒâ–„â–‚â–â–‚â–‚â–‚â–
wandb:      val/path_hit_recall@20 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–…â–†â–‡â–„â–‚â–†â–…â–…â–…â–…â–ƒâ–„â–„â–„â–‚â–ƒâ–…â–ƒâ–‚â–„â–„â–ƒâ–„â–ƒâ–„â–‚â–â–‚â–‚â–ƒ
wandb:       val/path_hit_recall@5 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–…â–…â–…â–†â–…â–…â–„â–„â–…â–ƒâ–‚â–„â–†â–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚
wandb:                  val/pb_nll â–ˆâ–ˆâ–†â–„â–‚â–‚â–‚â–‚â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–
wandb:                  val/pos_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–…â–†â–‡â–„â–ƒâ–†â–…â–…â–…â–…â–„â–„â–„â–‚â–„â–…â–ƒâ–‚â–„â–‚â–„â–ƒâ–„â–ƒâ–„â–‚â–â–‚â–ƒâ–
wandb:           val/pos_precision â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–†â–…â–‡â–ƒâ–†â–…â–…â–…â–ƒâ–„â–„â–„â–„â–ƒâ–…â–â–‚â–ƒâ–ƒâ–„â–„â–‚â–‚â–‚â–‚â–‚â–
wandb:              val/pos_recall â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–ƒâ–â–†â–…â–…â–…â–…â–„â–„â–„â–‚â–„â–…â–‚â–â–„â–‚â–ƒâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–
wandb:                  val/recall â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–†â–…â–…â–…â–‡â–ƒâ–ƒâ–‚â–†â–…â–…â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–…â–‚â–‚â–„â–‚â–ƒâ–„â–ƒâ–‚â–„â–‚â–â–‚â–‚â–
wandb:     val/reward_connectivity â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–…â–…â–…â–…â–ƒâ–‚â–†â–…â–„â–…â–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–„â–‚â–„â–ƒâ–‚â–„â–‚â–â–‚â–‚â–‚â–
wandb:        val/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/rollout_reward â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–„â–„â–ˆâ–‡â–‡â–‡â–‡â–…â–‡â–†â–„â–‡â–‡â–ˆâ–…â–â–‡â–„â–„â–†â–…â–‡â–„â–„â–„â–‚â–…â–ƒ
wandb:   val/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val/struct_phi_answer_div â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–…â–…â–…â–„â–„â–„â–„â–‡â–„â–„â–…â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–â–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–â–â–
wandb:           val/struct_phi_gt â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–†â–†â–†â–†â–†â–†â–…â–†â–‡â–‚â–…â–†â–…â–…â–…â–ƒâ–„â–„â–‚â–ƒâ–…â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–„â–‚â–â–‚â–‚â–‚
wandb:          val/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val/success@10 â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–ˆâ–‡â–†â–†â–‡â–ˆâ–‡â–…â–ˆâ–†â–‡â–ˆâ–†â–‡â–†â–‡â–†â–†â–‡â–†â–…â–ˆâ–â–‡â–†â–…â–‡â–…â–†â–†â–â–‡â–‚
wandb:              val/success@20 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–„â–‚â–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–…â–‡â–‡â–…â–ˆâ–…â–…â–ˆâ–„â–‚â–…â–‡â–„â–‡â–…â–…â–„â–‡â–
wandb:            val/success_mean â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–„â–‚â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–‡â–‡â–‡â–†â–ˆâ–†â–â–„â–‚â–…â–†â–…â–…â–â–„â–‚â–ƒ
wandb:                 val/tb_loss â–…â–…â–‡â–…â–†â–‡â–…â–‚â–â–‚â–ƒâ–â–ˆâ–‚â–†â–â–…â–ƒâ–‚â–â–ƒâ–„â–‚â–ƒâ–â–ƒâ–…â–‡â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–ƒâ–ƒâ–„â–„â–…â–ƒ
wandb:            val/unique_paths â–ƒâ–„â–„â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–†â–…â–ƒâ–ƒâ–‚â–„â–ˆâ–†â–„â–…â–†â–…â–ƒâ–†â–ˆâ–„â–„â–‚â–â–†â–ƒâ–‚â–†â–‡â–…â–†â–†â–†â–†â–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 57
wandb:        test/answer_coverage 0.82149
wandb:              test/answer_f1 0.34443
wandb:      test/answer_hit_any@10 0.94609
wandb:      test/answer_hit_any@20 0.94699
wandb:       test/answer_precision 0.28288
wandb:          test/answer_recall 0.82149
wandb: test/answer_recall_union@10 0.87807
wandb: test/answer_recall_union@20 0.88902
wandb:       test/avg_step_entropy 2.62298
wandb:    test/fallback_to_system1 0
wandb:         test/gt_path_exists 1
wandb:       test/gt_path_full_hit 0.78414
wandb:            test/length_mean 6.97394
wandb:             test/log_reward -0.41645
wandb:      test/log_reward_struct 1.88613
wandb:        test/logpf_logr_corr -0.03505
wandb:    test/logpf_logr_spearman -0.01281
wandb:            test/modes_found 3.42947
wandb:           test/modes_recall 0.88902
wandb:            test/path_exists 1
wandb:      test/path_exists_ratio 1
wandb:        test/path_hit_any@10 0.90746
wandb:        test/path_hit_any@20 0.92093
wandb:            test/path_hit_f1 0.1979
wandb:          test/path_hit_f1@1 0.12583
wandb:         test/path_hit_f1@10 0.1979
wandb:         test/path_hit_f1@20 0.1979
wandb:          test/path_hit_f1@5 0.24507
wandb:     test/path_hit_precision 0.11371
wandb:   test/path_hit_precision@1 0.12583
wandb:  test/path_hit_precision@10 0.11371
wandb:  test/path_hit_precision@20 0.11371
wandb:   test/path_hit_precision@5 0.14756
wandb:        test/path_hit_recall 0.78414
wandb:      test/path_hit_recall@1 0.12583
wandb:     test/path_hit_recall@10 0.78414
wandb:     test/path_hit_recall@20 0.78414
wandb:      test/path_hit_recall@5 0.73145
wandb:                 test/pb_nll 1.02261
wandb:                 test/pos_f1 0.1979
wandb:          test/pos_precision 0.11371
wandb:             test/pos_recall 0.78414
wandb:                 test/recall 0.82149
wandb:    test/reward_connectivity 0.82149
wandb:       test/reward_path_term 1
wandb:         test/rollout_reward 0.93977
wandb:  test/semantic_only_success 0
wandb:         test/semantic_score 1
wandb:  test/struct_phi_answer_div 2.25593
wandb:          test/struct_phi_gt 0.1979
wandb:         test/struct_phi_len 0
wandb:       test/struct_phi_score 0
wandb:             test/success@10 0.94609
wandb:             test/success@20 0.94699
wandb:           test/success_mean 0.93971
wandb:                test/tb_loss 67.67902
wandb:           test/unique_paths 19.4681
wandb:       train/answer_coverage 0.57792
wandb:             train/answer_f1 0.2721
wandb:      train/answer_precision 0.23299
wandb:         train/answer_recall 0.57792
wandb:      train/avg_step_entropy 7.21078
wandb:   train/fallback_to_system1 0
wandb:             train/gt_log_pf -4.70295
wandb:               train/gt_loss 2.3329
wandb:        train/gt_path_exists 1
wandb:      train/gt_path_full_hit 0.70859
wandb:           train/length_mean 5.16513
wandb:            train/log_reward -1.1301
wandb:     train/log_reward_struct 1.17248
wandb:                  train/loss 37.58288
wandb:           train/path_exists 1
wandb:     train/path_exists_ratio 1
wandb:           train/path_hit_f1 0.40396
wandb:    train/path_hit_precision 0.36008
wandb:       train/path_hit_recall 0.70859
wandb:                train/pb_nll 1.67552
wandb:                train/pos_f1 0.40396
wandb:         train/pos_precision 0.36008
wandb:            train/pos_recall 0.70859
wandb:                train/recall 0.57792
wandb:   train/reward_connectivity 0.57792
wandb:      train/reward_path_term 1
wandb:        train/rollout_reward 0.83656
wandb: train/semantic_only_success 0
wandb:        train/semantic_score 1
wandb: train/struct_phi_answer_div 1.01636
wandb:         train/struct_phi_gt 0.40396
wandb:        train/struct_phi_len 0
wandb:      train/struct_phi_score 0
wandb:          train/success_mean 0.8364
wandb:               train/tb_loss 34.16153
wandb:         trainer/global_step 1767
wandb:         val/answer_coverage 0.52383
wandb:               val/answer_f1 0.16615
wandb:       val/answer_hit_any@10 0.90588
wandb:       val/answer_hit_any@20 0.90588
wandb:        val/answer_precision 0.11439
wandb:           val/answer_recall 0.52383
wandb:  val/answer_recall_union@10 0.71784
wandb:  val/answer_recall_union@20 0.76294
wandb:        val/avg_step_entropy 3.08204
wandb:     val/fallback_to_system1 0
wandb:          val/gt_path_exists 1
wandb:        val/gt_path_full_hit 0.49941
wandb:             val/length_mean 6.98824
wandb:              val/log_reward -1.0382
wandb:       val/log_reward_struct 1.26439
wandb:         val/logpf_logr_corr -0.17973
wandb:     val/logpf_logr_spearman -0.11641
wandb:             val/modes_found 2.19412
wandb:            val/modes_recall 0.76294
wandb:             val/path_exists 1
wandb:       val/path_exists_ratio 1
wandb:         val/path_hit_any@10 0.75294
wandb:         val/path_hit_any@20 0.8
wandb:             val/path_hit_f1 0.12527
wandb:           val/path_hit_f1@1 0.01235
wandb:          val/path_hit_f1@10 0.12527
wandb:          val/path_hit_f1@20 0.12527
wandb:           val/path_hit_f1@5 0.10794
wandb:      val/path_hit_precision 0.07162
wandb:    val/path_hit_precision@1 0.01235
wandb:   val/path_hit_precision@10 0.07162
wandb:   val/path_hit_precision@20 0.07162
wandb:    val/path_hit_precision@5 0.06476
wandb:         val/path_hit_recall 0.49941
wandb:       val/path_hit_recall@1 0.01235
wandb:      val/path_hit_recall@10 0.49941
wandb:      val/path_hit_recall@20 0.49941
wandb:       val/path_hit_recall@5 0.32382
wandb:                  val/pb_nll 0.64759
wandb:                  val/pos_f1 0.12527
wandb:           val/pos_precision 0.07162
wandb:              val/pos_recall 0.49941
wandb:                  val/recall 0.52383
wandb:     val/reward_connectivity 0.52383
wandb:        val/reward_path_term 1
wandb:          val/rollout_reward 0.84986
wandb:   val/semantic_only_success 0
wandb:          val/semantic_score 1
wandb:   val/struct_phi_answer_div 0.91471
wandb:           val/struct_phi_gt 0.12527
wandb:          val/struct_phi_len 0
wandb:        val/struct_phi_score 0
wandb:              val/success@10 0.90588
wandb:              val/success@20 0.90588
wandb:            val/success_mean 0.84971
wandb:                 val/tb_loss 51.93306
wandb:            val/unique_paths 19.62941
wandb: 
wandb: ğŸš€ View run train_gflownet_prior_alpha2_to0 at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/k7o8uqah
wandb: â­ï¸ View project at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/train_gflownet_prior_alpha2_to0/runs/2025-12-04_13-05-07/wandb/run-20251204_130509-k7o8uqah/logs
[[36m2025-12-04 13:32:41,894[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Retrieved metric value! <val/rollout_reward=0.8498561978340149>[0m
==> Running train_gflownet_prior_alpha2_to0p5, logging to logs/prior_ablation/train_gflownet_prior_alpha2_to0p5_20251204_113111.log
[[36m2025-12-04 13:32:47,694[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Enforcing tags! <cfg.extras.enforce_tags=True>[0m
[[36m2025-12-04 13:32:47,697[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] torch.set_float32_matmul_precision(high)[0m
[[36m2025-12-04 13:32:47,697[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Printing config tree with Rich! <cfg.extras.print_config=True>[0m
CONFIG
â”œâ”€â”€ data
â”‚   â””â”€â”€ _target_: src.data.g_agent_datamodule.GAgentDataModule                  
â”‚       cache_paths:                                                            
â”‚         train: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g
â”‚         validation: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/va
â”‚         test: /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_a
â”‚       batch_size: 64                                                          
â”‚       num_workers: 8                                                          
â”‚       pin_memory: true                                                        
â”‚       drop_last: false                                                        
â”‚       persistent_workers: true                                                
â”‚       shuffle_train: true                                                     
â”‚       resources:                                                              
â”‚         vocabulary_path: /mnt/data/retrieval_dataset/webqsp/materialized/vocab
â”‚         embeddings_dir: /mnt/data/retrieval_dataset/webqsp/materialized/embedd
â”‚                                                                               
â”œâ”€â”€ model
â”‚   â””â”€â”€ _target_: src.models.gflownet_module.GFlowNetModule                     
â”‚       _recursive_: false                                                      
â”‚       hidden_dim: 1024                                                        
â”‚       training_cfg:                                                           
â”‚         normalize_log_reward: true                                            
â”‚         gt_replay_ratio: 0.3                                                  
â”‚         learn_pb: true                                                        
â”‚         debug_batches_to_log: 1                                               
â”‚         debug_graphs_to_log: 2                                                
â”‚         retriever_prior_alpha: 2.0                                            
â”‚         retriever_prior_anneal:                                               
â”‚           start: 2.0                                                          
â”‚           end: 0.5                                                            
â”‚           steps: 10000                                                        
â”‚         pb_loss_weight: 1.0                                                   
â”‚         pb_loss_anneal:                                                       
â”‚           start: 1.0                                                          
â”‚           end: 0.0                                                            
â”‚           steps: 5000                                                         
â”‚         gt_loss_weight: 0.15                                                  
â”‚       evaluation_cfg:                                                         
â”‚         num_eval_rollouts:                                                    
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚         path_hit_k:                                                           
â”‚         - 1                                                                   
â”‚         - 5                                                                   
â”‚         - 10                                                                  
â”‚         - 20                                                                  
â”‚       optimizer_cfg:                                                          
â”‚         type: adamw                                                           
â”‚         lr: 0.0001                                                            
â”‚         weight_decay: 0.0001                                                  
â”‚         param_groups:                                                         
â”‚         - params:                                                             
â”‚           - estimator.log_z_head                                              
â”‚           - estimator.log_z_condition                                         
â”‚           lr: 0.001                                                           
â”‚       scheduler_cfg:                                                          
â”‚         type: cosine                                                          
â”‚         t_max: 200                                                            
â”‚         eta_min: 1.0e-06                                                      
â”‚         interval: epoch                                                       
â”‚         monitor: val/reward                                                   
â”‚       logging_cfg:                                                            
â”‚         train_prog_bar:                                                       
â”‚         - rollout_reward                                                      
â”‚         - success_mean                                                        
â”‚         - answer_coverage                                                     
â”‚         - length_mean                                                         
â”‚         eval_prog_bar:                                                        
â”‚         - success_mean                                                        
â”‚         - answer_f1                                                           
â”‚         auto_add_success_at_k: true                                           
â”‚         auto_add_path_hit_f1: true                                            
â”‚         log_on_step_train: false                                              
â”‚       env_cfg:                                                                
â”‚         _target_: src.models.components.gflownet_env.GraphEnv                 
â”‚         mode: subgraph                                                        
â”‚         max_steps: 6                                                          
â”‚         forbid_backtrack: true                                                
â”‚         forbid_revisit: true                                                  
â”‚         bidir_token: false                                                    
â”‚         debug: true                                                           
â”‚         debug_max_resets: 2                                                   
â”‚         debug_max_graphs: 2                                                   
â”‚         debug_max_hits: 4                                                     
â”‚       policy_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_policies.EdgeMLPMixerPolicy  
â”‚         hidden_dim: 1024                                                      
â”‚         dropout: 0.5                                                          
â”‚         num_layers: 2                                                         
â”‚       reward_cfg:                                                             
â”‚         _target_: src.models.components.gflownet_rewards.AnswerOnlyReward     
â”‚         success_reward: 10.0                                                  
â”‚         failure_reward: 0.01                                                  
â”‚         lambda_reach: 0.0                                                     
â”‚         gamma_len: 0.0                                                        
â”‚         gamma_score: 0.0                                                      
â”‚         score_clip_max: 1.0                                                   
â”‚         score_eps: 1.0e-08                                                    
â”‚         gamma_gt: 0.0                                                         
â”‚         gamma_answer_div: 0.0                                                 
â”‚       actor_cfg:                                                              
â”‚         _target_: src.models.components.gflownet_actor.GFlowNetActor          
â”‚         policy_temperature: 1.0                                               
â”‚         eval_policy_temperature: 0.7                                          
â”‚         stop_logit_bias: -1.0                                                 
â”‚         random_action_prob: 0.1                                               
â”‚         debug_actions: false                                                  
â”‚         debug_actions_steps: 0                                                
â”‚       embedder_cfg:                                                           
â”‚         _target_: src.models.components.gflownet_embedder.GraphEmbedder       
â”‚         hidden_dim: 1024                                                      
â”‚         proj_dropout: 0.0                                                     
â”‚         projector_checkpoint: logs/train_retriever_webqsp/runs/2025-12-02_19-2
â”‚         freeze_projectors: true                                               
â”‚         kge_interaction: concat                                               
â”‚         projector_key_prefixes:                                               
â”‚         - retriever.model._orig_mod                                           
â”‚         - retriever.model                                                     
â”‚         - retriever                                                           
â”‚         - model._orig_mod                                                     
â”‚         - model                                                               
â”‚         - ''                                                                  
â”‚         use_gfn_projectors: true                                              
â”‚       estimator_cfg:                                                          
â”‚         _target_: src.models.components.gflownet_estimator.GFlowNetEstimator  
â”‚         hidden_dim: 1024                                                      
â”‚         log_pb_mode: learned                                                  
â”‚         learn_pb: true                                                        
â”‚         pb_entropy_coef: 0.0                                                  
â”‚         pb_l2_reg: 0.0                                                        
â”‚                                                                               
â”œâ”€â”€ callbacks
â”‚   â””â”€â”€ model_checkpoint:                                                       
â”‚         _target_: lightning.pytorch.callbacks.ModelCheckpoint                 
â”‚         dirpath: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_t
â”‚         filename: epoch_{epoch:03d}                                           
â”‚         monitor: val/rollout_reward                                           
â”‚         verbose: false                                                        
â”‚         save_last: true                                                       
â”‚         save_top_k: 1                                                         
â”‚         mode: max                                                             
â”‚         auto_insert_metric_name: false                                        
â”‚         save_weights_only: false                                              
â”‚         every_n_train_steps: null                                             
â”‚         train_time_interval: null                                             
â”‚         every_n_epochs: null                                                  
â”‚         save_on_train_epoch_end: null                                         
â”‚       early_stopping:                                                         
â”‚         _target_: lightning.pytorch.callbacks.EarlyStopping                   
â”‚         monitor: val/rollout_reward                                           
â”‚         min_delta: 0.0                                                        
â”‚         patience: 50                                                          
â”‚         verbose: false                                                        
â”‚         mode: max                                                             
â”‚         strict: true                                                          
â”‚         check_finite: true                                                    
â”‚         stopping_threshold: null                                              
â”‚         divergence_threshold: null                                            
â”‚         check_on_train_epoch_end: null                                        
â”‚       model_summary:                                                          
â”‚         _target_: lightning.pytorch.callbacks.RichModelSummary                
â”‚         max_depth: -1                                                         
â”‚       rich_progress_bar:                                                      
â”‚         _target_: lightning.pytorch.callbacks.RichProgressBar                 
â”‚                                                                               
â”œâ”€â”€ logger
â”‚   â””â”€â”€ wandb:                                                                  
â”‚         _target_: lightning.pytorch.loggers.wandb.WandbLogger                 
â”‚         name: train_gflownet_prior_alpha2_to0p5                               
â”‚         save_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_
â”‚         offline: false                                                        
â”‚         id: null                                                              
â”‚         anonymous: null                                                       
â”‚         project: evi-rag                                                      
â”‚         log_model: false                                                      
â”‚         prefix: ''                                                            
â”‚         entity: null                                                          
â”‚         group: ''                                                             
â”‚         tags: []                                                              
â”‚         job_type: ''                                                          
â”‚                                                                               
â”œâ”€â”€ trainer
â”‚   â””â”€â”€ _target_: lightning.pytorch.trainer.Trainer                             
â”‚       default_root_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_a
â”‚       min_epochs: 50                                                          
â”‚       max_epochs: 200                                                         
â”‚       accelerator: gpu                                                        
â”‚       devices: 1                                                              
â”‚       gradient_clip_val: 1.0                                                  
â”‚       check_val_every_n_epoch: 1                                              
â”‚       log_every_n_steps: 1                                                    
â”‚       deterministic: false                                                    
â”‚                                                                               
â”œâ”€â”€ paths
â”‚   â””â”€â”€ root_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚       data_dir: /mnt/data/retrieval_dataset                                   
â”‚       log_dir: /mnt/wangjingxiong/EVI-RAG/logs/                               
â”‚       debug_log_path: /mnt/wangjingxiong/EVI-RAG/logs//debug.log              
â”‚       output_dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_
â”‚       work_dir: /mnt/wangjingxiong/EVI-RAG                                    
â”‚                                                                               
â”œâ”€â”€ extras
â”‚   â””â”€â”€ ignore_warnings: false                                                  
â”‚       enforce_tags: true                                                      
â”‚       print_config: true                                                      
â”‚       torch_float32_matmul_precision: high                                    
â”‚                                                                               
â”œâ”€â”€ task_name
â”‚   â””â”€â”€ train_gflownet_prior_alpha2_to0p5                                       
â”œâ”€â”€ tags
â”‚   â””â”€â”€ ['ablation', 'prior=2->0.5']                                            
â”œâ”€â”€ train
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ test
â”‚   â””â”€â”€ True                                                                    
â”œâ”€â”€ debug_data_loading
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ test_ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ allow_test_without_checkpoint
â”‚   â””â”€â”€ False                                                                   
â”œâ”€â”€ ckpt_path
â”‚   â””â”€â”€ None                                                                    
â”œâ”€â”€ seed
â”‚   â””â”€â”€ 42                                                                      
â”œâ”€â”€ dataset
â”‚   â””â”€â”€ name: webqsp                                                            
â”‚       kb: freebase                                                            
â”‚       raw_root: /mnt/data/retrieval_dataset/webqsp/raw/data                   
â”‚       out_dir: /mnt/data/retrieval_dataset/webqsp/normalized                  
â”‚       materialized_dir: /mnt/data/retrieval_dataset/webqsp/materialized       
â”‚       paths:                                                                  
â”‚         vocabulary: /mnt/data/retrieval_dataset/webqsp/materialized/vocabulary
â”‚         embeddings: /mnt/data/retrieval_dataset/webqsp/materialized/embeddings
â”‚         processed: /mnt/data/retrieval_dataset/webqsp/materialized/processed  
â”‚       entity_normalization: none                                              
â”‚       undirected_traversal: false                                             
â”‚       hard_negative_k: 4                                                      
â”‚       hard_negative_similarity: cosine                                        
â”‚       column_map:                                                             
â”‚         question_id_field: id                                                 
â”‚         question_field: question                                              
â”‚         answer_text_field: answer                                             
â”‚         q_entity_field: q_entity                                              
â”‚         a_entity_field: a_entity                                              
â”‚         graph_field: graph                                                    
â”‚                                                                               
â”œâ”€â”€ optimized_metric
â”‚   â””â”€â”€ val/rollout_reward                                                      
â”œâ”€â”€ gflownet_debug
â”‚   â””â”€â”€ True                                                                    
â””â”€â”€ env_debug
    â””â”€â”€ True                                                                    
Seed set to 42
[[36m2025-12-04 13:32:47,743[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Resolved run name: train_gflownet_prior_alpha2_to0p5[0m
[[36m2025-12-04 13:32:47,743[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating datamodule <src.data.g_agent_datamodule.GAgentDataModule>[0m
[[36m2025-12-04 13:32:48,241[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating model <src.models.gflownet_module.GFlowNetModule>[0m
[[36m2025-12-04 13:32:48,309[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating callbacks...[0m
[[36m2025-12-04 13:32:48,309[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.ModelCheckpoint>[0m
[[36m2025-12-04 13:32:48,311[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.EarlyStopping>[0m
[[36m2025-12-04 13:32:48,311[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichModelSummary>[0m
[[36m2025-12-04 13:32:48,312[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating callback <lightning.pytorch.callbacks.RichProgressBar>[0m
[[36m2025-12-04 13:32:48,312[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating loggers...[0m
[[36m2025-12-04 13:32:48,312[0m][[34msrc.utils.instantiators[0m][[32mINFO[0m] - [rank: 0] Instantiating logger <lightning.pytorch.loggers.wandb.WandbLogger>[0m
[[36m2025-12-04 13:32:48,314[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Instantiating trainer <lightning.pytorch.trainer.Trainer>[0m
Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
[[36m2025-12-04 13:32:48,350[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Logging hyperparameters![0m
wandb: Currently logged in as: martin1007wang (martin1007wang-wuhan-university) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: creating run
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0p5/runs/2025-12-04_13-32-47/wandb/run-20251204_133249-g73l6pev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run train_gflownet_prior_alpha2_to0p5
wandb: â­ï¸ View project at https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: ğŸš€ View run at https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/g73l6pev
[[36m2025-12-04 13:32:51,433[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting training![0m
[[36m2025-12-04 13:32:52,599[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/train_g_agent.pt: 1956 samples.[0m
[[36m2025-12-04 13:32:52,668[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/validation_g_agent.pt: 170 samples.[0m
[[36m2025-12-04 13:32:52,985[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/entity_embeddings.pt...[0m
[[36m2025-12-04 13:32:53,757[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Loading /mnt/data/retrieval_dataset/webqsp/materialized/embeddings/relation_embeddings.pt...[0m
[[36m2025-12-04 13:32:53,765[0m][[34msrc.data.components.embedding_store[0m][[32mINFO[0m] - Entity embedding rows: 524643 (vocab entities: 1281202). Non-text entities use embedding_id=0; textual entities occupy 1..max_id.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”“
â”ƒ    â”ƒ Name                                            â”ƒ Type  â”ƒ Paraâ€¦ â”ƒ Mode  â”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ policy                                          â”‚ Edgeâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 1  â”‚ policy.type_embeddings                          â”‚ Embeâ€¦ â”‚ 5.1 K â”‚ train â”‚
â”‚ 2  â”‚ policy.graph_norm                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 3  â”‚ policy.q_film                                   â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 4  â”‚ policy.q_film.0                                 â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 5  â”‚ policy.q_film.1                                 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 6  â”‚ policy.q_film.2                                 â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 7  â”‚ policy.edge_mlp                                 â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 8  â”‚ policy.edge_mlp.0                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 9  â”‚ policy.edge_mlp.1                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 10 â”‚ policy.edge_mlp.2                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 11 â”‚ policy.edge_mlp.3                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 12 â”‚ policy.edge_mlp.4                               â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 13 â”‚ policy.edge_mlp.5                               â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 14 â”‚ policy.edge_mlp.6                               â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 15 â”‚ policy.edge_mlp.7                               â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 16 â”‚ policy.lookahead_head                           â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 17 â”‚ policy.lookahead_head.0                         â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 18 â”‚ policy.lookahead_head.1                         â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 19 â”‚ policy.lookahead_head.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 20 â”‚ policy.lookahead_head.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 21 â”‚ policy.lookahead_head.4                         â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 22 â”‚ policy.stop_proj                                â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 23 â”‚ policy.stop_proj.0                              â”‚ Layeâ€¦ â”‚ 4.1 K â”‚ train â”‚
â”‚ 24 â”‚ policy.stop_proj.1                              â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 25 â”‚ policy.stop_proj.2                              â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 26 â”‚ policy.stop_proj.3                              â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 27 â”‚ reward_fn                                       â”‚ Answâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 28 â”‚ env                                             â”‚ Grapâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 29 â”‚ embedder                                        â”‚ Grapâ€¦ â”‚  12.6 â”‚ train â”‚
â”‚    â”‚                                                 â”‚       â”‚     M â”‚       â”‚
â”‚ 30 â”‚ embedder.entity_projector                       â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 31 â”‚ embedder.entity_projector.0                     â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 32 â”‚ embedder.entity_projector.1                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 33 â”‚ embedder.entity_projector.2                     â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 34 â”‚ embedder.entity_projector.3                     â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 35 â”‚ embedder.entity_projector.4                     â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 36 â”‚ embedder.relation_projector                     â”‚ Sequâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 37 â”‚ embedder.relation_projector.0                   â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 38 â”‚ embedder.relation_projector.1                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 39 â”‚ embedder.relation_projector.2                   â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 40 â”‚ embedder.relation_projector.3                   â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 41 â”‚ embedder.relation_projector.4                   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 42 â”‚ embedder.edge_adapter                           â”‚ Sequâ€¦ â”‚ 5.3 M â”‚ train â”‚
â”‚ 43 â”‚ embedder.edge_adapter.0                         â”‚ Layeâ€¦ â”‚ 8.2 K â”‚ train â”‚
â”‚ 44 â”‚ embedder.edge_adapter.1                         â”‚ Lineâ€¦ â”‚ 4.2 M â”‚ train â”‚
â”‚ 45 â”‚ embedder.edge_adapter.2                         â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 46 â”‚ embedder.edge_adapter.3                         â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 47 â”‚ embedder.edge_adapter.4                         â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 48 â”‚ embedder.retriever_entity_projector             â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 49 â”‚ embedder.retriever_entity_projector.network     â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 50 â”‚ embedder.retriever_entity_projector.network.0   â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 51 â”‚ embedder.retriever_entity_projector.network.1   â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 52 â”‚ embedder.retriever_relation_projector           â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 53 â”‚ embedder.retriever_relation_projector.network   â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 54 â”‚ embedder.retriever_relation_projector.network.0 â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 55 â”‚ embedder.retriever_relation_projector.network.1 â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 56 â”‚ embedder.retriever_query_projector              â”‚ Embeâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 57 â”‚ embedder.retriever_query_projector.network      â”‚ Sequâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 58 â”‚ embedder.retriever_query_projector.network.0    â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ eval  â”‚
â”‚ 59 â”‚ embedder.retriever_query_projector.network.1    â”‚ Tanh  â”‚     0 â”‚ eval  â”‚
â”‚ 60 â”‚ estimator                                       â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â”‚ 61 â”‚ estimator.log_z_head                            â”‚ Sequâ€¦ â”‚ 1.1 M â”‚ train â”‚
â”‚ 62 â”‚ estimator.log_z_head.0                          â”‚ Layeâ€¦ â”‚ 2.0 K â”‚ train â”‚
â”‚ 63 â”‚ estimator.log_z_head.1                          â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 64 â”‚ estimator.log_z_head.2                          â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 65 â”‚ estimator.log_z_head.3                          â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 66 â”‚ estimator.ctx_projector                         â”‚ Sequâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 67 â”‚ estimator.ctx_projector.0                       â”‚ Lineâ€¦ â”‚ 2.1 M â”‚ train â”‚
â”‚ 68 â”‚ estimator.ctx_projector.1                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 69 â”‚ estimator.ctx_projector.2                       â”‚ Lineâ€¦ â”‚ 1.0 M â”‚ train â”‚
â”‚ 70 â”‚ estimator.backward_head                         â”‚ Sequâ€¦ â”‚ 3.2 M â”‚ train â”‚
â”‚ 71 â”‚ estimator.backward_head.0                       â”‚ Layeâ€¦ â”‚ 6.1 K â”‚ train â”‚
â”‚ 72 â”‚ estimator.backward_head.1                       â”‚ Lineâ€¦ â”‚ 3.1 M â”‚ train â”‚
â”‚ 73 â”‚ estimator.backward_head.2                       â”‚ GELU  â”‚     0 â”‚ train â”‚
â”‚ 74 â”‚ estimator.backward_head.3                       â”‚ Dropâ€¦ â”‚     0 â”‚ train â”‚
â”‚ 75 â”‚ estimator.backward_head.4                       â”‚ Lineâ€¦ â”‚ 1.0 K â”‚ train â”‚
â”‚ 76 â”‚ actor                                           â”‚ GFloâ€¦ â”‚ 7.4 M â”‚ train â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
Trainable params: 24.2 M                                                        
Non-trainable params: 3.1 M                                                     
Total params: 27.3 M                                                            
Total estimated model params size (MB): 109                                     
Modules in train mode: 65                                                       
Modules in eval mode: 12                                                        
/anaconda3/envs/pog/lib/python3.11/site-packages/lightning/pytorch/loops/fit_loop.py:527: Found 12 module(s) in eval mode at the start of training. This may lead to unexpected behavior during training. If this is intentional, you can ignore this warning.
Epoch 97/199 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 31/31 0:00:17 â€¢ 0:00:00 1.78it/s v_num: 6pev      
                                                               val/answer_f1:   
                                                               0.201            
                                                               val/path_hit_f1@â€¦
                                                               0.141            
                                                               val/success_mean:
                                                               0.900            
                                                               val/success@20:  
                                                               0.929 train/loss:
                                                               40.426           
                                                               train/rollout_reâ€¦
                                                               0.855            
                                                               train/success_meâ€¦
                                                               0.855            
                                                               train/answer_covâ€¦
                                                               0.597            
                                                               train/length_meaâ€¦
                                                               5.148            
[[36m2025-12-04 14:18:04,551[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Starting testing![0m
[[36m2025-12-04 14:18:04,977[0m][[34msrc.data.g_agent_dataset[0m][[32mINFO[0m] - Loaded g_agent cache /mnt/data/retrieval_dataset/webqsp/materialized/g_agent/test_g_agent.pt: 1113 samples.[0m
Restoring states from the checkpoint path at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0p5/runs/2025-12-04_13-32-47/checkpoints/epoch_047.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
Loaded model weights from the checkpoint at /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0p5/runs/2025-12-04_13-32-47/checkpoints/epoch_047.ckpt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ         Test metric         â”ƒ        DataLoader 0         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚    test/answer_coverage     â”‚     0.7062397599220276      â”‚
â”‚       test/answer_f1        â”‚     0.2699875235557556      â”‚
â”‚   test/answer_hit_any@10    â”‚      0.942497730255127      â”‚
â”‚   test/answer_hit_any@20    â”‚     0.9433962106704712      â”‚
â”‚    test/answer_precision    â”‚     0.21938087046146393     â”‚
â”‚     test/answer_recall      â”‚     0.7062397599220276      â”‚
â”‚ test/answer_recall_union@10 â”‚     0.8242788314819336      â”‚
â”‚ test/answer_recall_union@20 â”‚     0.8455337882041931      â”‚
â”‚    test/avg_step_entropy    â”‚     3.1198477745056152      â”‚
â”‚  test/fallback_to_system1   â”‚             0.0             â”‚
â”‚     test/gt_path_exists     â”‚             1.0             â”‚
â”‚    test/gt_path_full_hit    â”‚     0.6890386343002319      â”‚
â”‚      test/length_mean       â”‚      6.973629951477051      â”‚
â”‚       test/log_reward       â”‚     -0.4518280327320099     â”‚
â”‚   test/log_reward_struct    â”‚     1.8507572412490845      â”‚
â”‚    test/logpf_logr_corr     â”‚    -0.050674766302108765    â”‚
â”‚  test/logpf_logr_spearman   â”‚    -0.02104700170457363     â”‚
â”‚      test/modes_found       â”‚     3.0664870738983154      â”‚
â”‚      test/modes_recall      â”‚     0.8455337882041931      â”‚
â”‚      test/path_exists       â”‚             1.0             â”‚
â”‚   test/path_exists_ratio    â”‚             1.0             â”‚
â”‚    test/path_hit_any@10     â”‚     0.8589398264884949      â”‚
â”‚    test/path_hit_any@20     â”‚     0.8831985592842102      â”‚
â”‚      test/path_hit_f1       â”‚     0.1741330921649933      â”‚
â”‚     test/path_hit_f1@1      â”‚     0.0876460149884224      â”‚
â”‚     test/path_hit_f1@10     â”‚     0.1741330921649933      â”‚
â”‚     test/path_hit_f1@20     â”‚     0.1741330921649933      â”‚
â”‚     test/path_hit_f1@5      â”‚     0.20395006239414215     â”‚
â”‚   test/path_hit_precision   â”‚     0.10011765360832214     â”‚
â”‚  test/path_hit_precision@1  â”‚     0.0876460149884224      â”‚
â”‚ test/path_hit_precision@10  â”‚     0.10011765360832214     â”‚
â”‚ test/path_hit_precision@20  â”‚     0.10011765360832214     â”‚
â”‚  test/path_hit_precision@5  â”‚     0.12288560718297958     â”‚
â”‚    test/path_hit_recall     â”‚     0.6891734004020691      â”‚
â”‚   test/path_hit_recall@1    â”‚     0.0876460149884224      â”‚
â”‚   test/path_hit_recall@10   â”‚     0.6891734004020691      â”‚
â”‚   test/path_hit_recall@20   â”‚     0.6891734004020691      â”‚
â”‚   test/path_hit_recall@5    â”‚     0.6081086993217468      â”‚
â”‚         test/pb_nll         â”‚     1.1834661960601807      â”‚
â”‚         test/pos_f1         â”‚     0.1741330921649933      â”‚
â”‚     test/pos_precision      â”‚     0.10011765360832214     â”‚
â”‚       test/pos_recall       â”‚     0.6891734004020691      â”‚
â”‚         test/recall         â”‚     0.7062397599220276      â”‚
â”‚  test/reward_connectivity   â”‚     0.7062397599220276      â”‚
â”‚    test/reward_path_term    â”‚             1.0             â”‚
â”‚     test/rollout_reward     â”‚     0.9346567392349243      â”‚
â”‚ test/semantic_only_success  â”‚             0.0             â”‚
â”‚     test/semantic_score     â”‚             1.0             â”‚
â”‚ test/struct_phi_answer_div  â”‚     1.7483826875686646      â”‚
â”‚     test/struct_phi_gt      â”‚     0.1741330921649933      â”‚
â”‚     test/struct_phi_len     â”‚             0.0             â”‚
â”‚    test/struct_phi_score    â”‚             0.0             â”‚
â”‚       test/success@10       â”‚      0.942497730255127      â”‚
â”‚       test/success@20       â”‚     0.9433962106704712      â”‚
â”‚      test/success_mean      â”‚     0.9345912337303162      â”‚
â”‚        test/tb_loss         â”‚      63.56990432739258      â”‚
â”‚      test/unique_paths      â”‚     19.588499069213867      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Testing â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 18/18 0:01:04 â€¢ 0:00:00 0.30it/s 
[[36m2025-12-04 14:19:10,280[0m][[34m__main__[0m][[32mINFO[0m] - [rank: 0] Best ckpt path: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0p5/runs/2025-12-04_13-32-47/checkpoints/epoch_047.ckpt[0m
[[36m2025-12-04 14:19:10,281[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Output dir: /mnt/wangjingxiong/EVI-RAG/logs/train_gflownet_prior_alpha2_to0p5/runs/2025-12-04_13-32-47[0m
[[36m2025-12-04 14:19:10,281[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Closing wandb![0m
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb:                                                                                
wandb: 
wandb: Run history:
wandb:                       epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:        test/answer_coverage â–
wandb:              test/answer_f1 â–
wandb:      test/answer_hit_any@10 â–
wandb:      test/answer_hit_any@20 â–
wandb:       test/answer_precision â–
wandb:          test/answer_recall â–
wandb: test/answer_recall_union@10 â–
wandb: test/answer_recall_union@20 â–
wandb:       test/avg_step_entropy â–
wandb:    test/fallback_to_system1 â–
wandb:         test/gt_path_exists â–
wandb:       test/gt_path_full_hit â–
wandb:            test/length_mean â–
wandb:             test/log_reward â–
wandb:      test/log_reward_struct â–
wandb:        test/logpf_logr_corr â–
wandb:    test/logpf_logr_spearman â–
wandb:            test/modes_found â–
wandb:           test/modes_recall â–
wandb:            test/path_exists â–
wandb:      test/path_exists_ratio â–
wandb:        test/path_hit_any@10 â–
wandb:        test/path_hit_any@20 â–
wandb:            test/path_hit_f1 â–
wandb:          test/path_hit_f1@1 â–
wandb:         test/path_hit_f1@10 â–
wandb:         test/path_hit_f1@20 â–
wandb:          test/path_hit_f1@5 â–
wandb:     test/path_hit_precision â–
wandb:   test/path_hit_precision@1 â–
wandb:  test/path_hit_precision@10 â–
wandb:  test/path_hit_precision@20 â–
wandb:   test/path_hit_precision@5 â–
wandb:        test/path_hit_recall â–
wandb:      test/path_hit_recall@1 â–
wandb:     test/path_hit_recall@10 â–
wandb:     test/path_hit_recall@20 â–
wandb:      test/path_hit_recall@5 â–
wandb:                 test/pb_nll â–
wandb:                 test/pos_f1 â–
wandb:          test/pos_precision â–
wandb:             test/pos_recall â–
wandb:                 test/recall â–
wandb:    test/reward_connectivity â–
wandb:       test/reward_path_term â–
wandb:         test/rollout_reward â–
wandb:  test/semantic_only_success â–
wandb:         test/semantic_score â–
wandb:  test/struct_phi_answer_div â–
wandb:          test/struct_phi_gt â–
wandb:         test/struct_phi_len â–
wandb:       test/struct_phi_score â–
wandb:             test/success@10 â–
wandb:             test/success@20 â–
wandb:           test/success_mean â–
wandb:                test/tb_loss â–
wandb:           test/unique_paths â–
wandb:       train/answer_coverage â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–…â–„â–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–„â–‚â–â–„â–ˆâ–ƒâ–‚â–â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚
wandb:             train/answer_f1 â–ˆâ–…â–…â–…â–…â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–…â–‚â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚
wandb:      train/answer_precision â–ˆâ–…â–…â–…â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–ƒâ–„â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚
wandb:         train/answer_recall â–ˆâ–‡â–ˆâ–‡â–„â–…â–…â–„â–ƒâ–„â–‚â–ƒâ–‚â–‚â–„â–‚â–ƒâ–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–‚â–„â–†â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–„â–ƒâ–ƒâ–â–‚â–‚â–‚
wandb:      train/avg_step_entropy â–â–„â–„â–„â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–…â–„â–†â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆ
wandb:   train/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:             train/gt_log_pf â–ˆâ–‡â–…â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–‚â–‚â–ƒâ–„â–‚â–ƒâ–‚â–â–â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:               train/gt_loss â–â–„â–„â–„â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–…â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:        train/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/gt_path_full_hit â–ˆâ–ˆâ–ˆâ–‡â–…â–ƒâ–…â–…â–â–ƒâ–…â–ƒâ–„â–„â–‚â–‚â–â–ƒâ–„â–†â–„â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–â–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚
wandb:           train/length_mean â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–‡â–…â–ƒâ–„â–…â–„â–†â–„â–†â–†â–†â–‚â–‚â–ˆâ–ƒâ–…â–‚â–‚â–ƒâ–„â–†â–â–‚â–†â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–…â–ƒâ–ƒ
wandb:            train/log_reward â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–„â–‡â–‡â–…â–†â–…â–„â–ƒâ–ƒâ–„â–ƒâ–„â–…â–†â–…â–‚â–†â–‡â–…â–â–„â–ƒâ–‚â–â–ƒâ–†â–…â–†â–‚â–â–…â–„â–„
wandb:     train/log_reward_struct â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–†â–†â–â–„â–†â–…â–ƒâ–‡â–†â–„â–…â–…â–ƒâ–…â–†â–‡â–‡â–‡â–…â–„â–„â–‚â–„â–„â–‚â–„â–†â–‚â–ƒâ–ƒâ–…â–„â–„
wandb:                  train/loss â–†â–ˆâ–ˆâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–„â–„â–„â–â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–‚â–ƒ
wandb:           train/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:     train/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:           train/path_hit_f1 â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–
wandb:    train/path_hit_precision â–…â–†â–…â–ƒâ–‚â–â–‡â–ƒâ–ƒâ–…â–„â–‚â–ƒâ–‚â–ƒâ–…â–…â–‡â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–‡â–…â–…â–„â–â–…â–ƒâ–ƒâ–…â–†â–„â–ƒâ–‚â–â–â–„â–ƒ
wandb:       train/path_hit_recall â–‡â–ˆâ–ˆâ–ˆâ–‡â–„â–„â–…â–…â–â–…â–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–„â–„â–‚â–ƒâ–â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–â–„â–ƒâ–‚â–ƒâ–‚â–‚
wandb:                train/pb_nll â–ƒâ–ˆâ–‡â–†â–„â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–â–…â–ˆâ–„â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–
wandb:                train/pos_f1 â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–â–â–â–‚â–‚â–‚â–â–â–â–‚
wandb:         train/pos_precision â–ˆâ–†â–‡â–„â–‚â–„â–ƒâ–‚â–‡â–…â–†â–‚â–ƒâ–…â–‚â–†â–„â–†â–…â–ƒâ–…â–ƒâ–‚â–†â–‡â–ƒâ–â–„â–„â–ƒâ–„â–…â–…â–…â–„â–‚â–„â–‚â–â–ƒ
wandb:            train/pos_recall â–‡â–ˆâ–ˆâ–ˆâ–‡â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–„â–„â–…â–ƒâ–â–†â–‡â–†â–ƒâ–â–‚â–‚â–â–â–‚â–‚â–ƒâ–‚
wandb:                train/recall â–ˆâ–†â–…â–…â–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–„â–„â–…â–…â–ƒâ–ƒâ–‚â–â–‚â–†â–ƒâ–ƒâ–‚â–â–â–‚â–„â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:   train/reward_connectivity â–‡â–ˆâ–ˆâ–‡â–…â–…â–„â–â–‚â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–„â–‚â–„â–†â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–â–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–‚â–ƒâ–‚
wandb:      train/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/rollout_reward â–ˆâ–‡â–‡â–†â–†â–…â–…â–†â–†â–„â–…â–ƒâ–†â–ƒâ–…â–ƒâ–…â–†â–…â–‡â–‡â–…â–‚â–â–ƒâ–ˆâ–‚â–ƒâ–„â–„â–„â–‚â–ƒâ–‚â–ƒâ–…â–â–ƒâ–ƒâ–ƒ
wandb: train/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        train/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train/struct_phi_answer_div â–ˆâ–‡â–‡â–‡â–†â–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–ˆâ–†â–‚â–ƒâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train/struct_phi_gt â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚
wandb:        train/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:      train/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          train/success_mean â–‡â–ˆâ–ˆâ–ˆâ–‡â–„â–†â–‚â–‡â–‡â–†â–…â–„â–ƒâ–ƒâ–…â–†â–†â–‡â–‡â–ƒâ–‚â–ƒâ–‡â–â–„â–ƒâ–ƒâ–‚â–‚â–â–„â–†â–…â–†â–„â–‚â–‚â–„â–ƒ
wandb:               train/tb_loss â–†â–†â–ˆâ–†â–„â–„â–‚â–‚â–ƒâ–„â–â–‚â–‚â–â–‚â–ƒâ–â–â–„â–ƒâ–â–â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–â–ƒ
wandb:         trainer/global_step â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:         val/answer_coverage â–ˆâ–ˆâ–†â–…â–„â–…â–ƒâ–ƒâ–„â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–†â–†â–…â–„â–ƒâ–ƒâ–„â–…â–â–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:               val/answer_f1 â–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–â–„â–…â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–â–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒ
wandb:       val/answer_hit_any@10 â–ˆâ–‡â–ˆâ–ˆâ–‡â–â–‡â–‡â–†â–†â–‡â–‚â–ˆâ–ˆâ–‡â–†â–†â–ˆâ–‡â–†â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–…â–†â–‡â–†â–‡â–ˆâ–ˆâ–…â–ˆâ–†â–‡â–‡â–‡
wandb:       val/answer_hit_any@20 â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–„â–„â–â–ˆâ–ˆâ–ˆâ–„â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–‡â–ˆâ–‡â–ˆ
wandb:        val/answer_precision â–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–†â–„â–„â–„â–…â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–…â–‚â–‚â–‚â–ƒ
wandb:           val/answer_recall â–ˆâ–ˆâ–ˆâ–†â–†â–„â–ƒâ–†â–†â–…â–„â–„â–…â–„â–„â–…â–†â–†â–…â–…â–„â–„â–„â–â–â–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–…â–…â–ƒâ–„â–„â–„â–„â–„
wandb:  val/answer_recall_union@10 â–ˆâ–ˆâ–ˆâ–†â–…â–â–…â–…â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–„â–‡â–…â–…â–„â–ˆâ–„â–‚â–„â–ƒâ–…â–ƒâ–„â–…â–„â–ƒâ–„â–„â–„â–„â–„
wandb:  val/answer_recall_union@20 â–ˆâ–ˆâ–ˆâ–‡â–„â–†â–†â–†â–…â–†â–…â–†â–†â–…â–…â–†â–†â–…â–†â–…â–†â–‡â–†â–…â–†â–â–†â–„â–†â–…â–…â–†â–†â–†â–†â–…â–…â–†â–†â–†
wandb:        val/avg_step_entropy â–ƒâ–ƒâ–‚â–â–‚â–„â–…â–…â–„â–„â–ƒâ–â–…â–…â–†â–„â–…â–…â–…â–…â–ƒâ–…â–†â–â–†â–…â–„â–ƒâ–…â–„â–†â–†â–…â–‡â–‡â–‚â–‡â–†â–†â–ˆ
wandb:     val/fallback_to_system1 â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/gt_path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/gt_path_full_hit â–ˆâ–ˆâ–‡â–†â–†â–„â–ƒâ–…â–…â–„â–…â–„â–„â–„â–ƒâ–…â–ƒâ–…â–„â–ƒâ–„â–„â–„â–†â–†â–ƒâ–…â–ˆâ–â–…â–„â–‚â–„â–„â–ƒâ–„â–ƒâ–„â–„â–„
wandb:             val/length_mean â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‚â–ˆâ–ˆâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–…â–ˆâ–„â–„â–…â–„â–ˆ
wandb:              val/log_reward â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–…â–‡â–ˆâ–‡â–‡â–‡â–‡â–†â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆâ–ˆâ–â–‚â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:       val/log_reward_struct â–ˆâ–ˆâ–ˆâ–ˆâ–‚â–â–†â–†â–‡â–‡â–‡â–†â–…â–…â–‡â–‡â–…â–†â–†â–†â–ˆâ–‡â–†â–‡â–‡â–†â–‚â–†â–…â–‡â–„â–†â–‡â–‡â–ˆâ–‡â–†â–†â–†â–‡
wandb:         val/logpf_logr_corr â–…â–…â–†â–…â–…â–‚â–ƒâ–…â–ƒâ–‚â–…â–‚â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–ˆâ–†â–„â–…â–…â–…â–…â–â–‚â–„â–ƒâ–„â–„â–ƒâ–„â–…â–†â–†â–…â–†
wandb:     val/logpf_logr_spearman â–†â–†â–‡â–‡â–‡â–…â–ƒâ–…â–„â–ˆâ–‚â–†â–„â–ƒâ–„â–„â–„â–ƒâ–„â–ƒâ–‡â–‡â–…â–†â–†â–…â–‚â–…â–„â–â–ƒâ–„â–ƒâ–†â–‡â–†â–†â–‡â–…â–†
wandb:             val/modes_found â–ˆâ–ˆâ–‡â–‡â–‡â–„â–‚â–‚â–…â–ƒâ–„â–…â–ƒâ–ƒâ–…â–ƒâ–„â–„â–„â–ƒâ–†â–…â–…â–…â–…â–ˆâ–ˆâ–â–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–„
wandb:            val/modes_recall â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ƒâ–‚â–…â–„â–â–†â–„â–…â–†â–…â–†â–…â–…â–…â–‡â–†â–†â–…â–…â–…â–†â–ˆâ–â–…â–…â–…â–„â–…â–†â–‡â–„â–…â–…â–…â–…
wandb:             val/path_exists â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:       val/path_exists_ratio â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         val/path_hit_any@10 â–ˆâ–‡â–‚â–ƒâ–â–†â–…â–…â–„â–…â–…â–…â–„â–„â–…â–ƒâ–…â–„â–†â–†â–†â–†â–„â–„â–ƒâ–ˆâ–„â–„â–â–„â–„â–ƒâ–„â–…â–…â–„â–„â–‚â–…â–…
wandb:         val/path_hit_any@20 â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ƒâ–ƒâ–…â–„â–…â–†â–…â–†â–…â–†â–…â–†â–†â–‡â–„â–†â–†â–â–†â–†â–ƒâ–…â–…â–†â–‡â–…â–‡â–„â–†â–†â–†â–…â–†â–†
wandb:             val/path_hit_f1 â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–ƒâ–…â–…â–…â–†â–…â–„â–„â–…â–…â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–„â–†â–„â–…â–â–…â–„â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–„â–„â–„
wandb:           val/path_hit_f1@1 â–ˆâ–ˆâ–…â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–ˆâ–â–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:          val/path_hit_f1@10 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–„â–‚â–„â–…â–†â–…â–„â–†â–…â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–…â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–„â–ƒâ–„â–ƒâ–„â–„â–ƒ
wandb:          val/path_hit_f1@20 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–„â–„â–ƒâ–…â–„â–…â–†â–…â–„â–†â–…â–„â–„â–„â–ƒâ–…â–…â–ƒâ–„â–ˆâ–â–â–‚â–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–ƒâ–„â–„
wandb:           val/path_hit_f1@5 â–ˆâ–ˆâ–‡â–†â–…â–‚â–…â–„â–â–…â–„â–„â–…â–…â–…â–…â–„â–„â–…â–…â–„â–…â–†â–…â–…â–ƒâ–„â–‚â–â–„â–„â–„â–…â–ƒâ–„â–…â–‚â–…â–…â–„
wandb:      val/path_hit_precision â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–„â–„â–†â–†â–…â–„â–„â–„â–ƒâ–„â–„â–ƒâ–†â–†â–†â–…â–„â–„â–„â–ƒâ–â–„â–‚â–ƒâ–…â–„â–„â–„â–…â–ƒâ–„â–ƒâ–ƒâ–„
wandb:    val/path_hit_precision@1 â–ˆâ–†â–„â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:   val/path_hit_precision@10 â–ˆâ–ˆâ–ˆâ–‡â–…â–„â–…â–„â–„â–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–„â–„â–†â–†â–…â–„â–„â–„â–…â–ˆâ–â–‚â–ƒâ–„â–ƒâ–…â–„â–„â–ƒâ–„â–„â–„â–„â–„
wandb:   val/path_hit_precision@20 â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–ƒâ–…â–…â–‚â–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–†â–†â–…â–„â–„â–ˆâ–â–â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–„
wandb:    val/path_hit_precision@5 â–ˆâ–ˆâ–…â–„â–‚â–…â–„â–â–…â–„â–…â–…â–„â–…â–…â–„â–…â–„â–„â–†â–…â–ˆâ–ˆâ–‚â–„â–…â–„â–„â–„â–„â–„â–…â–„â–…â–‚â–„â–„â–„â–„â–„
wandb:         val/path_hit_recall â–ˆâ–ˆâ–ˆâ–â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–„â–†â–…â–ƒâ–ˆâ–ˆâ–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒ
wandb:       val/path_hit_recall@1 â–ˆâ–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–ˆâ–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:      val/path_hit_recall@10 â–ˆâ–‡â–†â–…â–ƒâ–ƒâ–…â–†â–…â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–…â–„â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–„â–„â–ƒâ–…â–‚â–‚â–ƒâ–‚â–ƒ
wandb:      val/path_hit_recall@20 â–ˆâ–ˆâ–ˆâ–‡â–†â–…â–â–…â–…â–…â–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–†â–†â–…â–„â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–„â–ƒâ–…â–‚â–‚â–ƒâ–„â–ƒâ–ƒ
wandb:       val/path_hit_recall@5 â–ˆâ–ˆâ–‡â–†â–…â–„â–„â–…â–…â–„â–„â–„â–„â–„â–‚â–„â–…â–„â–…â–†â–…â–ƒâ–ƒâ–ƒâ–…â–â–„â–„â–„â–ƒâ–ƒâ–„â–„â–…â–‚â–„â–„â–ƒâ–ƒâ–„
wandb:                  val/pb_nll â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–ˆâ–‡â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:                  val/pos_f1 â–ˆâ–ˆâ–ˆâ–‡â–†â–ƒâ–â–„â–„â–ƒâ–…â–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–†â–„â–ƒâ–‚â–„â–…â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:           val/pos_precision â–ˆâ–‡â–‡â–†â–„â–…â–…â–„â–…â–„â–…â–†â–„â–ƒâ–…â–„â–„â–„â–ƒâ–„â–†â–†â–…â–…â–…â–ˆâ–â–„â–‚â–„â–ƒâ–ƒâ–„â–…â–„â–…â–ƒâ–ƒâ–„â–„
wandb:              val/pos_recall â–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–ƒâ–ƒâ–‚â–ƒâ–…â–ˆâ–„â–‚â–ƒâ–â–‚â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:                  val/recall â–ˆâ–ˆâ–†â–ƒâ–„â–„â–…â–†â–…â–„â–†â–„â–„â–ƒâ–…â–ƒâ–„â–„â–„â–„â–…â–…â–„â–„â–ƒâ–â–„â–ƒâ–ƒâ–„â–ƒâ–„â–…â–„â–…â–…â–„â–„â–„â–„
wandb:     val/reward_connectivity â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–„â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–…â–ƒâ–„â–†â–…â–…â–…â–„â–ƒâ–„â–…â–ˆâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–…â–„â–ƒâ–„
wandb:        val/reward_path_term â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/rollout_reward â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–„â–‡â–…â–‡â–‚â–„â–ˆâ–…â–…â–‡â–†â–‡â–†â–†â–†â–ˆâ–ˆâ–‡â–†â–…â–…â–‡â–ˆâ–„â–ƒâ–…â–…â–…â–‡â–„â–†â–…â–†â–†
wandb:   val/semantic_only_success â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:          val/semantic_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:   val/struct_phi_answer_div â–ˆâ–ˆâ–ˆâ–ˆâ–„â–‚â–â–…â–ƒâ–„â–…â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–ƒâ–„â–ƒâ–…â–ˆâ–ˆâ–‚â–â–â–â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚
wandb:           val/struct_phi_gt â–ˆâ–ˆâ–‡â–†â–…â–‚â–…â–†â–†â–„â–„â–ƒâ–„â–…â–„â–ƒâ–„â–„â–†â–†â–„â–ƒâ–ƒâ–…â–ˆâ–â–ƒâ–„â–‚â–ƒâ–ƒâ–…â–„â–…â–„â–ƒâ–„â–ƒâ–„â–„
wandb:          val/struct_phi_len â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        val/struct_phi_score â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:              val/success@10 â–‡â–ˆâ–‡â–†â–ƒâ–â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‡â–‡â–†â–†â–‡â–‡â–ˆâ–†â–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‡â–†â–‚â–‡â–‡â–‡â–†â–…â–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:              val/success@20 â–ˆâ–ˆâ–ˆâ–†â–‡â–ˆâ–ˆâ–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–ˆâ–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:            val/success_mean â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–ƒâ–ƒâ–„â–‡â–†â–„â–„â–ƒâ–†â–…â–…â–…â–ƒâ–‡â–‡â–‡â–„â–„â–ˆâ–‚â–…â–†â–â–â–ƒâ–„â–‡â–„â–†â–ƒâ–‚â–…â–…â–…
wandb:                 val/tb_loss â–„â–…â–…â–†â–ˆâ–„â–„â–‚â–…â–„â–„â–…â–„â–‡â–â–„â–„â–†â–„â–â–â–‚â–â–ƒâ–„â–ƒâ–‚â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:            val/unique_paths â–„â–…â–„â–„â–…â–…â–â–†â–ƒâ–„â–†â–…â–‡â–†â–ˆâ–‡â–†â–†â–‚â–†â–…â–†â–†â–…â–†â–‡â–„â–„â–†â–†â–†â–†â–ˆâ–‡â–ˆâ–â–†â–„â–…â–‡
wandb: 
wandb: Run summary:
wandb:                       epoch 98
wandb:        test/answer_coverage 0.70624
wandb:              test/answer_f1 0.26999
wandb:      test/answer_hit_any@10 0.9425
wandb:      test/answer_hit_any@20 0.9434
wandb:       test/answer_precision 0.21938
wandb:          test/answer_recall 0.70624
wandb: test/answer_recall_union@10 0.82428
wandb: test/answer_recall_union@20 0.84553
wandb:       test/avg_step_entropy 3.11985
wandb:    test/fallback_to_system1 0
wandb:         test/gt_path_exists 1
wandb:       test/gt_path_full_hit 0.68904
wandb:            test/length_mean 6.97363
wandb:             test/log_reward -0.45183
wandb:      test/log_reward_struct 1.85076
wandb:        test/logpf_logr_corr -0.05067
wandb:    test/logpf_logr_spearman -0.02105
wandb:            test/modes_found 3.06649
wandb:           test/modes_recall 0.84553
wandb:            test/path_exists 1
wandb:      test/path_exists_ratio 1
wandb:        test/path_hit_any@10 0.85894
wandb:        test/path_hit_any@20 0.8832
wandb:            test/path_hit_f1 0.17413
wandb:          test/path_hit_f1@1 0.08765
wandb:         test/path_hit_f1@10 0.17413
wandb:         test/path_hit_f1@20 0.17413
wandb:          test/path_hit_f1@5 0.20395
wandb:     test/path_hit_precision 0.10012
wandb:   test/path_hit_precision@1 0.08765
wandb:  test/path_hit_precision@10 0.10012
wandb:  test/path_hit_precision@20 0.10012
wandb:   test/path_hit_precision@5 0.12289
wandb:        test/path_hit_recall 0.68917
wandb:      test/path_hit_recall@1 0.08765
wandb:     test/path_hit_recall@10 0.68917
wandb:     test/path_hit_recall@20 0.68917
wandb:      test/path_hit_recall@5 0.60811
wandb:                 test/pb_nll 1.18347
wandb:                 test/pos_f1 0.17413
wandb:          test/pos_precision 0.10012
wandb:             test/pos_recall 0.68917
wandb:                 test/recall 0.70624
wandb:    test/reward_connectivity 0.70624
wandb:       test/reward_path_term 1
wandb:         test/rollout_reward 0.93466
wandb:  test/semantic_only_success 0
wandb:         test/semantic_score 1
wandb:  test/struct_phi_answer_div 1.74838
wandb:          test/struct_phi_gt 0.17413
wandb:         test/struct_phi_len 0
wandb:       test/struct_phi_score 0
wandb:             test/success@10 0.9425
wandb:             test/success@20 0.9434
wandb:           test/success_mean 0.93459
wandb:                test/tb_loss 63.5699
wandb:           test/unique_paths 19.5885
wandb:       train/answer_coverage 0.59722
wandb:             train/answer_f1 0.28116
wandb:      train/answer_precision 0.24585
wandb:         train/answer_recall 0.59722
wandb:      train/avg_step_entropy 7.3568
wandb:   train/fallback_to_system1 0
wandb:             train/gt_log_pf -4.70413
wandb:               train/gt_loss 2.31873
wandb:        train/gt_path_exists 1
wandb:      train/gt_path_full_hit 0.72904
wandb:           train/length_mean 5.14826
wandb:            train/log_reward -1.00297
wandb:     train/log_reward_struct 1.29962
wandb:                  train/loss 40.42617
wandb:           train/path_exists 1
wandb:     train/path_exists_ratio 1
wandb:           train/path_hit_f1 0.41126
wandb:    train/path_hit_precision 0.36566
wandb:       train/path_hit_recall 0.72904
wandb:                train/pb_nll 1.7644
wandb:                train/pos_f1 0.41126
wandb:         train/pos_precision 0.36566
wandb:            train/pos_recall 0.72904
wandb:                train/recall 0.59722
wandb:   train/reward_connectivity 0.59722
wandb:      train/reward_path_term 1
wandb:        train/rollout_reward 0.85495
wandb: train/semantic_only_success 0
wandb:        train/semantic_score 1
wandb: train/struct_phi_answer_div 1.10532
wandb:         train/struct_phi_gt 0.41126
wandb:        train/struct_phi_len 0
wandb:      train/struct_phi_score 0
wandb:          train/success_mean 0.85481
wandb:               train/tb_loss 37.40956
wandb:         trainer/global_step 3038
wandb:         val/answer_coverage 0.5742
wandb:               val/answer_f1 0.20133
wandb:       val/answer_hit_any@10 0.92941
wandb:       val/answer_hit_any@20 0.92941
wandb:        val/answer_precision 0.15258
wandb:           val/answer_recall 0.5742
wandb:  val/answer_recall_union@10 0.77072
wandb:  val/answer_recall_union@20 0.79511
wandb:        val/avg_step_entropy 3.29638
wandb:     val/fallback_to_system1 0
wandb:          val/gt_path_exists 1
wandb:        val/gt_path_full_hit 0.56235
wandb:             val/length_mean 6.98824
wandb:              val/log_reward -0.69281
wandb:       val/log_reward_struct 1.60978
wandb:         val/logpf_logr_corr -0.09608
wandb:     val/logpf_logr_spearman -0.04855
wandb:             val/modes_found 2.57647
wandb:            val/modes_recall 0.79511
wandb:             val/path_exists 1
wandb:       val/path_exists_ratio 1
wandb:         val/path_hit_any@10 0.83529
wandb:         val/path_hit_any@20 0.87647
wandb:             val/path_hit_f1 0.14101
wandb:           val/path_hit_f1@1 0.02647
wandb:          val/path_hit_f1@10 0.14101
wandb:          val/path_hit_f1@20 0.14101
wandb:           val/path_hit_f1@5 0.14275
wandb:      val/path_hit_precision 0.08062
wandb:    val/path_hit_precision@1 0.02647
wandb:   val/path_hit_precision@10 0.08062
wandb:   val/path_hit_precision@20 0.08062
wandb:    val/path_hit_precision@5 0.08565
wandb:         val/path_hit_recall 0.56235
wandb:       val/path_hit_recall@1 0.02647
wandb:      val/path_hit_recall@10 0.56235
wandb:      val/path_hit_recall@20 0.56235
wandb:       val/path_hit_recall@5 0.42824
wandb:                  val/pb_nll 0.99791
wandb:                  val/pos_f1 0.14101
wandb:           val/pos_precision 0.08062
wandb:              val/pos_recall 0.56235
wandb:                  val/recall 0.5742
wandb:     val/reward_connectivity 0.5742
wandb:        val/reward_path_term 1
wandb:          val/rollout_reward 0.89981
wandb:   val/semantic_only_success 0
wandb:          val/semantic_score 1
wandb:   val/struct_phi_answer_div 1.22029
wandb:           val/struct_phi_gt 0.14101
wandb:          val/struct_phi_len 0
wandb:        val/struct_phi_score 0
wandb:              val/success@10 0.92941
wandb:              val/success@20 0.92941
wandb:            val/success_mean 0.89971
wandb:                 val/tb_loss 51.06264
wandb:            val/unique_paths 19.70588
wandb: 
wandb: ğŸš€ View run train_gflownet_prior_alpha2_to0p5 at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag/runs/g73l6pev
wandb: â­ï¸ View project at: https://wandb.ai/martin1007wang-wuhan-university/evi-rag
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./logs/train_gflownet_prior_alpha2_to0p5/runs/2025-12-04_13-32-47/wandb/run-20251204_133249-g73l6pev/logs
[[36m2025-12-04 14:19:12,071[0m][[34msrc.utils.utils[0m][[32mINFO[0m] - [rank: 0] Retrieved metric value! <val/rollout_reward=0.8998061418533325>[0m
